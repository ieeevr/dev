id;BoothID;Authors;Abstract;Title;PosterCategory;VideoLink
1;TBD;"Ana David: Instituto Superior Técnico, University of Lisbon; Daniele Giunchi: University College London; Stuart James: University College London (UCL); Anthony Steed: University College London; Augusto Esteves: Instituto Superior Técnico, University of Lisbon";We describe the development of PaintBranch, a virtual reality prototype designed to support asynchronous collaborative art. By incorporating version control (VC), PaintBranch aims to promote creative idea generation and reduce conflicts during collaboration. In a user study, eight participants were organized into four pairs and worked asynchronously for a week, with each participant having four painting sessions. We analyzed the emerging collaboration patterns and uses. Results indicated that experienced artists used these features effectively to meet collaborative and personal goals.;PaintBranch: Asynchronous Collaborative Art in Virtual Reality;Collaboration, Virtual Humans and Social Applications ;OJYIdEBWYzo
2;TBD;"Anjela Mayer: Karlsruhe Institute of Technology; Ines Miguel-Alonso: University of Burgos; Jean-Rémy Chardonnet: Arts et Metiers Institute of Technology; Andrés Bustillo: Universidad de Burgos; Jivka Ovtcharova: Institute for Information Management in Engineering";This study investigates baseline modalities for evaluating Augmented Reality (AR) avatar guidance in asynchronous collaboration on spatially complex tasks. A formative study with three participants compared smartphone video, HoloLens video, and AR avatars across usability, collaboration, learning, and spatial awareness. Results suggest smartphone video as a reliable baseline due to usability and familiarity. Avatars showed potential for enhancing spatial awareness, task engagement, and learning outcomes but require interface improvements. Despite the small sample size, this study offers insights into immersive technologies for industrial training and collaboration.;Enhancing Asynchronous Learning in immersive Environments: Exploring Baseline Modalities for Avatar-Based MR Guidance;Collaboration, Virtual Humans and Social Applications ;Mor4dodEsrk
3;TBD;"Jiayi Zhao: Beijing Institute of Technology; Nan Gao: Institute of Automation, Chinese Academy of Sciences; Dongdong Weng: Beijing Institute of Technology; Yihua Bao: Beijing Institute of Technology; Xiaoqiang Liu: Kuaishou Technology ; Yan Zhou: Kuaishou Technology ";Co-speech motion generation is a challenging task requiring alignment between motion, speech rhythm, and semantics. To improve adaptability, style control mechanisms, including emotion perception and personalized motion generation, are needed. We propose a hybrid emotion-aware personalized co-speech motion generation system, consisting of an emotion-aware module based on LLM and a rhythm motion generation module based on diffusion, ensuring consistency between motion and speech emotion. Additionally, we introduce a style transfer module to adapt the generated motions to the speaker’s style. Experimental results show the system generates stylized and emotionally consistent motions, enhancing the realism and stylization of virtual humans.;Emotion-Aware Personalized Co-Speech Motion Generation;Collaboration, Virtual Humans and Social Applications ;rOaTSNFhXFQ
4;TBD;"Marie Michael Morita: Ritsumeikan University; Yuji Fujihara: Ritsumeikan University; Tetsuro Nakamura: Ritsumeikan University; Miki Matsumuro: Cornell University; Fumihisa Shibata: Ritsumeikan University; Asako Kimura: Ritsumeikan Univ.; Norimichi Kitagawa: Ritsumeikan University";When two individuals control a virtual avatar simultaneously (virtual co-embodiment), their  movement performance can, somewhat surprisingly, improve compared to when they control an avatar alone. This study investigated whether movement performance is affected by how individuals' movements embody into an avatar: by averaging the positions of body parts of each individual or by summing the movement vector of each individual's body parts. The experiment, in which participants reached a target with the avatar’s hand in these two types of co-embodiment, showed that the vector summation was more efficient in improving body movements than the position average.;Comparison of  Calculation Modes for Virtual Co-embodiment: Movement Average and Vector Summation;Collaboration, Virtual Humans and Social Applications ;sgoAUQ2gnPs
5;TBD;"Xiaofeng Dou: ShanghaiTech University; Jiahe Dong: ShanghaiTech University; Shuhao Zhang: ShanghaiTech University; Qian Zhu: The Hong Kong University of Science and Technology; Quan Li: ShanghaiTech University";With the evolution of social interaction needs, danmaku comments on 2D screens have emerged in Asia, offering users a virtual co-viewing experience. With advancements in virtual reality (VR) technology, there is an increasing demand for similar co-viewing experiences in VR settings. In this study, we designed the Danmaku Avatar System to explore the adaptation of danmaku into VR environments to enhance shared viewing experiences. Comparative experiments showed that danmaku avatars substantially improved social presence and increased the desire for communication. These findings lay the groundwork for further refining danmaku representations in VR, advancing virtual social interactions and immersive viewing experiences.;Danmaku Avatar: Enabling Co-viewing Experiences in Virtual Reality via Danmaku;Collaboration, Virtual Humans and Social Applications ;K44ZLTiqz_s
6;TBD;"Kilian L. Krause: Fraunhofer HHI; Wieland Morgenstern: Fraunhofer HHI; Anna Hilsmann: Fraunhofer HHI; Peter Eisert: Fraunhofer HHI";Digitizing the humans and scenes around us is a challenging research topic, with results finding new and more widespread implementation in modern applications. This paper addresses the challenge of real-time rendering of dynamic 3D scenes. The proposed approach utilizes Instant Neural Graphics Primitives (iNGP), training a radiance field for each individual frame. To achieve playback rates suitable for interactive VR experiences, we developed efficient data storage and loading methods. We present a modular framework for playing real-time free-viewpoint videos on a conventional Desktop PC, to showcase research advancements of dynamic radiance fields.;Realtime-Rendering of Dynamic Scenes with Neural Radiance Fields;Collaboration, Virtual Humans and Social Applications ;jRcIBDoLIgk
7;TBD;"Xiaofeng Yong: Carleton Univeristy; Ali Arya: Carleton University; Monique Manatch: Indigenous Culture and Media Innovations; Danielle Victoria Cole: Carleton University; Tyler Compton: Indigenous Culture and Media Innovations; Alexandra Antle: Freelance";This paper builds on the Indigenous Technology Empowerment Model (ITEM) by investigating how Indigenous 2D artists can collaborate with 3D content developers to create Virtual Reality (VR) experiences. We analyze collaborations between Indigenous artists, technical developers, and community members to validate and enhance ITEM. Our preliminary findings reveal novel aspects of technical-cultural integration, knowledge exchange requirements, and process effectiveness in empowering communities in VR development. The findings demonstrate how structured community involvement, combined with appropriate training and protocol observation, can lead to more inclusive and effective technology development.;Community-Collaborative VR Content Development;Collaboration, Virtual Humans and Social Applications ;yu-ccpdozK8
8;TBD;"Talya Maness: Reichman University; Anat Klomek Brunstein: Reichman University; Doron Friedman: Reichman University";We introduce AI-enhanced virtual humans to address the shortage of human professionals in mental health. Specifically, we allow for automatically learning and practicing resilience skills by assisting a distressed virtual human, utilizing the established Resilience Plan Intervention (RPI). One hundred participants underwent a brief training session in the RPI and then applied their newly acquired resilience strategies in simulated interactions with a distressed individual, conducted through either VR or traditional role-playing. The results revealed significant enhancements in reported resilience for both groups, accompanied by significant increases in reported levels of cognitive flexibility, emotion regulation, and help-seeking abilities.;Enhancing Resilience through AI-Driven Virtual Reality;Collaboration, Virtual Humans and Social Applications ;PE0dX5Yn4N4
9;TBD;"Alice Guth: Davidson College; Tabitha C. Peck: Davidson College";Avatars in virtual spaces often serve as extensions of users. Avatar choice depends on context, with users typically selecting avatars they identify with. Race and gender can influence avatar selection. This study explores avatar choice when a gender-race-matched avatar is unavailable. We examine whether participants are more likely to choose a race-matched or gender-matched avatar in the absence of a gender-race-matched option. Results show that all participants select avatars matching at least one aspect of their identity. When forced to choose, participants favored gender-matched avatars over race-matched ones, suggesting gender may be more central to one's identity during avatar selection.;Who Will They Choose?: Avatar Selection Without a Gender-Race-Match;Collaboration, Virtual Humans and Social Applications ;k89e1laVmWc
10;TBD;"Taeyeon kim: Pusan National University ; Hyeongil Nam: University of Calgary; Ahmad A Fouad: University of Calgary; Kangsoo Kim: University of Calgary; Myungho Lee: Pusan National University";As Artificial Intelligence and Virtual Reality evolve, intelligent virtual agents are shifting from mere information retrieval to significantly influencing users’ cognition and decision-making processes as social actors. This study examines the impact of dominance, a critical element of social interaction, by incorporating it into agents through verbal and non-verbal cues.  We present our preliminary research framework, which includes both the experimental design and the development of the agent system. The findings of this study are anticipated to offer valuable insights into the dynamics of user interactions with virtual agents and their broader implications.;Exploring the Effects of Embodied Agents' Verbal and Nonverbal Dominance on Decision-Making: A Study Design;Collaboration, Virtual Humans and Social Applications ;lXvAaHc0F4c
11;TBD;"Inas Redjem: Univ Rennes; Julien Cagnoncle: Univ. Rennes; Arnaud Huaulmé: Univ Rennes; Alexandre Audinot: Univ Rennes; Florian Nouviale: Univ Rennes; Mathieu Risy: Univ Rennes; Valérie Gouranton: Univ Rennes; Estelle Michinov: Univ Rennes; Pierre Jannin: Univ Rennes";As simulation advances in healthcare training, understanding how body-only signals convey emotions in virtual environments is crucial, particularly with masked virtual agents. This study involved 41 nursing students evaluating 16 faceless fear and surprise postures to assess their realism and the emotion conveyed. While well-recognized in 2D human representations, only three of 16 postures were correctly identified by more than 50% of participants in a 3D virtual agent. These results highlight the impact of virtual agent design on emotional recognition and the need for rigorous testing and refinement to improve emotional expressiveness and realism.;When Faces Are Masked: Exploring Emotional Expression Through Body Postures in Virtual Reality;Collaboration, Virtual Humans and Social Applications ;dCiVxbvJaps
12;TBD;"Shihui XU: Waseda Univiersity; Like WU: Waseda University; Wenjie Liao: Waseda University; Shigeru Fujimura: Waseda University";Telepresence using drones is a promising technology. This paper presents a user study within a simulated Virtual Reality (VR) remote collaboration system to shed light on users' perceived safety and trust regarding telepresence drones. We manipulated drone operation variables, including failure of drone, speed of flying, and distance restriction, to assess their impact on user perceptions. Quantitative and qualitative analysis shows that drone failures significantly reduce safety and trust for both local and remote users. Flying speed affects safety and trust for local workers but only impacts safety for remote experts. Distance restrictions enhance both safety and trust.;Exploring Human Reactions to Telepresence Drones: A User Study on Safety and Trust Using A Simulated Drone in a VR Environment;Collaboration, Virtual Humans and Social Applications ;yohV-IvWXZA
13;TBD;"Junhee Lee: Kwangwoon University; Hwanjo Heo: ETRI; Seungwon Woo: ETRI; Minseok Kim: Kwangwoon University; Jongseop Kim: Kwangwoon University; Jinwoo Kim: Kwangwoon University";Social Virtual Reality (VR) platforms have surged in popularity, yet their security risks remain underexplored. This paper presents four novel UI attacks that covertly manipulate users into performing harmful actions through deceptive virtual content. Implemented on VRChat and validated in an IRB-approved study with 30 participants, these attacks demonstrate how deceptive elements can mislead users into malicious actions without their awareness. To address these vulnerabilities, we propose MetaScanner, a proactive countermeasure that rapidly analyzes objects and scripts in virtual worlds, detecting suspicious elements within seconds.;Illusion Worlds: Deceptive UI Attacks in Social VR;Collaboration, Virtual Humans and Social Applications ;xbSog4EBrI4
14;TBD;"Jaejoon Jeong: Chonnam National University; Hwaryung Lee: Chonnam National University; Ji-eun Shin: Chonnam National University; Daeun Kim: Chonnam National University; Sei Kang: Chonnam National University; Gun A. Lee: University of South Australia; Soo-Hyung Kim: Chonnam National University; Hyung-Jeong Yang: Chonnam National University; Seungwon Kim: Chonnam National University";This study examined whether individuals with richer real-world social resources exhibit a greater willingness to interact with social avatars in Virtual Environment (VE). Employing a psychological approach, we assessed willingness to interact by measuring response times for pulling or pushing avatars. The results revealed that participants with richer social resources performed faster pulling actions toward social avatars, indicating a heightened willingness to engage. Notably, these effects were specific to social targets (i.e., avatars) and were not observed with non-social targets (i.e., a flag).;Willingness to Interact: Social Resources Facilitate Pulling Actions toward Social Avatars in Virtual Reality;Collaboration, Virtual Humans and Social Applications ;#NAME?
15;TBD;"Shuxian Li: Lenovo Research; Tianyue Wang: Lenovo Research; Yiqiang Yan: Lenovo Reaserch; Chris Twombly: Lenovo Research";Real-time facial avatar animation is widely used in entertainment, office, business and other fields, where blendshapes have become a common industry animation solution. We independently developed an accurate blendshape prediction system for low-power VR applications using a webcam. First, feature vectors are extracted through affine transformation and segmentation. Using further transformation and regression analysis, we created statistical models with significant predictive power. Post-processing was used to further improve response stability, including smoothing, filtering and nonlinear transformations. We achieved accuracy similar to ARKit 6. Our model has low requirements with a consistent, accurate and smooth visual experience.;Statistical Blendshape Calculation and Analysis for Graphics Applications;Collaboration, Virtual Humans and Social Applications ;ZjfjnpXmlpg
16;TBD;"Yasas Sri Wickramasinghe: University of Canterbury; Heide Lukosch: University of Canterbury; James Everett: Niantic Aotearoa NZ; Stephan Lukosch: University of Canterbury";This paper presents a study on the impact of enabling remote gameplay via Augmented Reality (AR) on spatial decision-making and player experience in a hide-and-seek game. We designed a remote multiplayer handheld-based AR game and evaluated how it influences players’ spatial decision-making strategies, engagement, and gameplay experience. In a study with 60 participants, we compared remote gameplay in our AR game to traditional hide-and-seek. Our findings show that AR enhances gameplay by improving spatial interactions, decision-making, and collaboration. Despite navigation challenges, AR has the potential to foster player engagement and social interaction, contributing to the design of future AR games and beyond.;Augmented Hide-and-Seek: Evaluating Spatial Decision-Making and Player Experience in a Multiplayer Location-based Game;Collaboration, Virtual Humans and Social Applications ;sJTn7yiinlI
17;TBD;"Lauren Gold: Arizona State University; Flemming Laursen: Arizona State University; Krutik Pandya: Arizona State University; Kathryn E Powell: Arizona State University; Robert LiKamWa: Arizona State University";"Virtual Reality (VR) and desktop users struggle to coordinate due to scale differences when analyzing geospatial data. This work explores multiscale workspace awareness techniques in geospatial analysis scenarios, such as scale-responsive cursors and vistas. A study (n = 16) compared Common Ground to current collaboration tools. The results reveal that 34% of users struggle to maintain awareness of their collaborator's focus, which drops to 9% with Common Ground; and 32% of users struggle to know precisely what features their collaborator referenced, decreasing to 15% with Common Ground. A follow-up with 12 geospatial practitioners provided insights into real-world applications of our system.";Common Ground: Establishing Group Awareness for Cross-Virtuality Collaborative Geospatial Analysis;Collaboration, Virtual Humans and Social Applications ;ib9z5ey-rBM
18;TBD;"Shuto Takashita: The University of Tokyo; Taiga Suzuki: Information Somatics Lab, The University of Tokyo; Naoki Tanaka: Information Somatics Lab, The University of Tokyo; Masahiko Inami: Information Somatics Lab, The University of Tokyo";We present the concept of an “Editable Body,” enabling users to modify their avatar’s structure and control scheme in real time. In our VR game, users embody a robot avatar whose mapping to their real limbs can be freely edited and whose structure can be augmented with a third arm. We investigated how this system affects participants’ perceptions of body identity, body-related expression, and impressions of body-editing technologies. Our findings indicate that real-time, user-driven body editing leads to greater acceptance of identity expression through non-innate bodies, fosters a more fluid view of the body, and increases openness to body modification technologies.;Editable Body: Interactive Adaptation of Avatar Control Schemes and Body Structures;Collaboration, Virtual Humans and Social Applications ;v73k5VJmUnc
19;TBD;"Clarence Chi San Cheung: Hong Kong University of Science and Technology; Ahmad Alhilal: Aalto University; Kriti Agrawal: Birla Institute of Technology and Science, Pilani; Zhizhuo Yin: The Hong Kong University of Science and Technology  (Guangzhou); Reza Hadi Mogavi: University of Waterloo; Pan Hui: The Hong Kong University of Science and Technology";Trust is a key element in human relationships and is vital for the success of any interaction. Establishing trust in the Social VR is important for promoting collaboration, communication, and social interaction. In our research, we investigate the perception and feasibility of using lie detection techniques in virtual reality to build trust. Our findings suggest that it is possible to detect deception in virtual reality using sensor-detected cues, and there is general desirabiilty of the feature. Using random forest, gaze-based features by themselves could reach an 87\% accuracy in detecting lies.  We also propose design considerations for future research.;Lie Detection in Social VR Using Multimodal Data;Collaboration, Virtual Humans and Social Applications ;SW7V--4edpI
20;TBD;"Junyeong Kum: Pusan National University; Myungho Lee: Pusan National University";Embodied conversational agents (ECAs) capable of nonverbal behaviors have been developed to address the limitations of voice-only assistants. Research has explored their use in augmented reality (AR), suggesting they may soon interact with us more naturally in physical spaces. However, the question of how they should enter the user's space when summoned remains under-explored. In this paper, we focused on the plausibility of ECAs' entering action into the user's field of view in AR. We analyzed its impact on users' perceived social presence and functionality of the agent. Our results indicated that the plausibility of the action significantly affected social presence and had a marginal effect on perceived functionality.;How Embodied Conversational Agents Should Enter Your Space?;Collaboration, Virtual Humans and Social Applications ;UqpuRf-KJKY
21;TBD;"Linjing SUN: University of Nottingham Ningbo China; Boon Giin Lee: University of Nottingham Ningbo China; Matthew Pike: University of Nottingham Ningbo China; David Chieng PhD: University of Nottingham Ningbo; Sen Yang: University of Nottingham Ningbo China";Pedagogical agents (PAs) have been extensively employed in immersive virtual reality (IVR) educational settings, yet their specific attributes are not thoroughly investigated. This study explores the impact of PA appearance and knowledge delivery methods on student learning in IVR environments. The findings reveal that the flying robot PA is regarded as the most credible, while cute creature PAs increase motivation but cause some distraction. The integrated text and audio multi-modality approach resulted in the best knowledge retention, though some participants experienced a slower learning pace. These insights are significant for designing and using PAs in IVR educational settings.;From Robots to Creatures: The Influence of Pedagogical Agent Design on Student Motivation and Learning in IVR Education;Collaboration, Virtual Humans and Social Applications ;vBw5QHVeA74
22;TBD;"Jack F Brophy: Keio University; Dunya Chen: KMD, Keio University; Tanner Person: Keio University Graduate School of Media Design; Kouta Minamizawa: Keio University Graduate School of Media Design; Giulia Barbareschi: Keio University";Increasing global migration has led to the rapid growth of interactions between organizations, groups, and individuals from various cultures. As such, knowing how to decode communication involving conversational partners from other cultures is essential in avoiding misunderstandings and needless conflicts. We present SentioScape, a Mixed Reality (MR) system for aiding emotional expression and understanding to foster more effective cross-cultural communication. 20 participants took part in an experiment to evaluate the system, with preliminary results revealing some positive trends that suggest the system has potential as a tool for creating more effective emotional communication between high- and low-context communicators.;SentioScape: Facilitating Effective Cross-Cultural Communication through Emotional Mixed Reality;Collaboration, Virtual Humans and Social Applications ;j6sao2PuYik
23;TBD;"Ulrike Kulzer: Saarland University, Saarland Informatics Campus; André Zenner: Saarland University, Saarland Informatics Campus; Donald Degraen: University of Canterbury";We developed a wind-based wearable haptic feedback device called winDirect to investigate if multimodal stimuli can be used to disguise hand redirection (HR) by increasing corresponding perceptual detection thresholds (DTs) in users. Our investigation was motivated by the findings of two previous works, which showed multimodal stimuli to increase presence, and indicated an increased feeling of embodiment to increase the DTs of HR. In contrast to our expectations, we found that the integration of multimodal stimuli did not guarantee increased HR DTs, even when increasing presence - highlighting the need to study correlations between presence and HR more deeply.;winDirect: Studying the Effect of a Wind-Based Haptic Bracelet on Presence and the Detectability of Hand Redirection;Locomotion, Navigation and Redirection;sy2GlV95GDA
24;TBD;"Hyuntaek Park: Daegok Middle School; Hyunwoo Cho: University of South Australia; Sang-Min Choi: Gyeongsang National University; Suwon Lee: Gyeongsang National University";Traditional VR locomotion systems often rely on costly treadmills or sophisticated motion capture technologies, limiting accessibility for broader audiences. This study introduces a highly affordable do-it-yourself walk-in-place interface for VR applications. The proposed interface is built using widely available materials, such as cardboard and aluminum foil, integrated with touch sensors and Bluetooth communication. The interface supports 16 directions of movement and can be constructed for approximately $50. This study demonstrates the potential of budget-friendly solutions to enhance VR. The proposed approach broadens access to immersive VR experiences and bridges the gap between functionality and affordability of VR systems.;Low-cost DIY 16 Directions of Movement Walk-in-Place Interface for VR Applications;Locomotion, Navigation and Redirection;uUCEzcBsF7Q
25;TBD;"Pedro A. Ferreira: NOVA School of Science and Technology; Ana Rita Rebelo: NOVA LINCS, NOVA School of Science and Technology; Rui Nóbrega: Universidade Nova de Lisboa, Lisboa, Portugal";Virtual Reality (VR) is widely used in museums to offer unique exhibition experiences. Navigation in virtual museums is typically achieved through teleportation. While teleportation bypasses physical space limitations, this technique differs from natural walking in the real world. Walking provides more immersive experiences but usually requires a large physical area. To address this, we present a space exploration VR museum where users can walk through the history of humanity's space exploration within just a 2.5 x 2.5 m physical space by employing overlapping spaces. This approach enables immersive storytelling and accessible virtual museum experiences, with preliminary results supporting its effectiveness.;Walking in Space: Immersive Storytelling in Space Exploration VR Museum;Locomotion, Navigation and Redirection;tPb2iINGTbo
26;TBD;"zhe xie: Beijing Engineering Research Center of Mixed Reality and Advanced Display，School of Optics and Photonics，Beijing Institute of Technology; Yue Liu: Beijing Engineering Research Center of Mixed Reality and Advanced Display，School of Optics and Photonics，Beijing Institute of Technology; Dong Li: Beijing Engineering Research Center of Mixed Reality and Advanced Display，School of Optics and Photonics，Beijing Institute of Technology";Localization in large-scale environment is fundamental for high-degree- of-freedom augmented reality (AR) and virtual reality (VR) applications. However, achieving stable and cost-effective wide-area tracking remains challenging, as existing methods often increase system cost and complexity when scaled to large spaces. This paper proposes a vision-based tracking system that encodes spatial relationships between markers to generate a planar layout. We propose a BiLSTM-based network for efficient marker recognition and introduce a robust rematching algorithm to enhance recognition accuracy. The proposed approach scales effectively with sparse markers while maintaining a high recognition rate.;Vision-Based Tracking System via Sparse Artificial Marker;Locomotion, Navigation and Redirection;0-Zq-3YA8tg
27;TBD;"Yuto Ohashi: Graduate School of Science and Technology, Nara Institute of Science and Technology; Keigo Matsumoto: The University of Tokyo; Yutaro Hirao: Nara Institute of Science and Technology; Monica Perusquia-Hernandez: Nara Institute of Science and Technology; Nobuchika Sakata: Ryukoku University; Hideaki Uchiyama: Nara Institute of Science and Technology; Kiyoshi Kiyokawa: Nara Institute of Science and Technology";We propose a walker-type system designed to enhance visual gain in redirected walking within virtual reality(VR) by providing dynamic haptic feedback through a rotating circular handrail.Two experiments were conducted to investigate whether haptic feedback in Redirected Walking(RDW) can expand the range of visual gain.This represents an approximately 23% increase in the visual gain threshold when the slide gain was set to 2.69, and a 21% increase when the slide gain was set to 1.00, highlighting the influence of haptic feedback. The results demonstrate that this device can enhance the user’s perception of movement in VR by coupling visual and haptic cues.;Friction Sensation in Redirected Walking Using a Rotating Handrail;Locomotion, Navigation and Redirection;2HcxQbZKcaU
28;TBD;"Razeen Hussain: University of Genoa; Manuela Chessa: University of Genoa; Fabio Solari: University of Genoa";Accurately perceiving distances in virtual reality (VR) remains a challenge due to discrepancies between real-world and VR spatial experiences. This study compares four VR locomotion methods—Teleport, Joystick, Arms Swinging, and Real Walking—by evaluating distance perception, spatial orientation, and user experience. In an exploratory within-subject study, participants navigated a virtual environment, estimated distances, and completed various questionnaires (SSQ, IPQ, SUS, NASA TLX, and a comparison questionnaire). Results showed a mismatch between user preference and performance: while Arms Swinging was the least preferred method, it provided the most accurate distance estimation and spatial orientation.;A Comparative Study on Locomotion Methods and Distance Perception in Immersive Virtual Reality;Locomotion, Navigation and Redirection;iv0fj__Jm-U
29;TBD;"Ripan Kumar Kundu: University of Missouri-Columbia; Khaza Anuarul Hoque: University of Missouri";Existing ML/DL methods for predicting VR cybersickness require massive amounts of high-quality data for effective training, extended training times, and lack of transferability capability to new VR environments. To address this, we propose a novel approach using zero-shot and few-shot learning mechanisms to leverage the knowledge of pre-trained large foundation models (TimeGPT and Chronos). Validated on two open-source VR cybersickness datasets, Simulations 2021 and APAL Head 2019, our fine-tuned TimeGPT model outperforms traditional DL models, achieving superior accuracy and significantly reduced training times compared to the trained-from-scratch Transformer models.;Advancing Cybersickness Prediction in Immersive Virtual Reality Using Pre-Trained Large Foundation Models;Locomotion, Navigation and Redirection;ZPz9zKQ2CJ8
30;TBD;"Zubin Datta Choudhary: University of Central Florida; Ferran Argelaguet Sanz: Inria; Gerd Bruder: University of Central Florida; Greg Welch: University of Central Florida";"Virtual Reality (VR) users often turn their bodies during experiences. Virtual navigation techniques use rotations and forward translation to simulate movement. Despite being designed for stationary use, these techniques can cause Unintentional Positional Drift (UPD), impacting user safety and VR experiences. We conducted an human-subject study, approved by our university ethics board, with 20 participants performing repetitive rotation tasks. Our study focused on intentionally inducing UPD via physical rotations by adding an offset to the VR camera's roll angle, creating a visual illusion of ""leaning"" or ""banking."" Our results show that camera roll offsets induced UPD along participants' initial left-right axis under specific conditions.";Inducing Unintentional Positional Drift (UPD) in Virtual Reality via Physical Rotations and the Illusion of Leaning;Locomotion, Navigation and Redirection;6tfTjkIMzJw
31;TBD;"Yuan Yue: Shandong University; Chao Zhou: Institute of Software Chinese Acadamy of Sciences; Tangjun Qu: Shandong University; Baiqiao Zhang: Shandong University; Juan Liu: School of Mechanical, Electrical & Information Engineering; Junhao Wang: Peking University; Tianren Luo: Institute of Software; Yulong Bian: Shandong University";"This paper introduces a method to reduce motion sickness (MS) during passive motion in virtual reality (VR), like virtual driving. The method improves users' sense of embodiment (SoE) by simulating airflow to align vestibular, visual, auditory, and tactile cues. We developed a Wind Simulation Helmet to provide airflow around the head and created a virtual motorcycle driving environment with matching visual and auditory cues. A preliminary experiment helped determine helmet parameters, followed by a formal experiment to test the effect of wind sensation on motion sickness. Results show that wind simulation can effectively: 1) improves proprioception and SoE of participants; 2) reduces motion sickness risk during passive driving.";Multi-sensory Simulation of Wind Sensation (MSSWS): An Approach of Reducing Motion Sickness in Passive Virtual Driving;Locomotion, Navigation and Redirection;fhA4hv8pLVQ
32;TBD;"Omar Khan: University of Calgary; Hyeongil Nam: University of Calgary; Kangsoo Kim: University of Calgary";As virtual reality (VR) continues to expand, particularly in social VR platforms and immersive gaming, understanding the factors that shape user experience is becoming increasingly important.  Avatars and locomotion methods both play central roles in influencing user experience in VR. However, little is known about the impact of congruence between these two factors. We conducted a user study with 30 participants, employing two avatar types (human and gorilla) and two locomotion methods (human-like arm-swing and gorilla-like arm-roll), to assess the effects of avatar-locomotion congruence. Our results indicate that congruent avatar-locomotion conditions enhance avatar identification and user experience.;“I look like a gorilla, but don’t move like one!”: Impact of Avatar-Locomotion Congruence in Virtual Reality;Locomotion, Navigation and Redirection;0BDhfM-3El0
33;TBD;"Liuyang Chen: NetEase (Hangzhou) Network Co., Ltd; Gaoqi He: East China Normal University; Changbo Wang: School of Computer Science and Technology";We propose Jumping-At-Air, where the avatar jumps in the virtual world and lands at a higher air while the user jumps in the real world, then jumps again from the air. The core idea is to first create a pair of pressure-sensing shoes based on the ESP32 chip, equipped with pressure sensors in the soles, to accurately detect the jumping stage. Then, through a carefully designed equation with two adjustable parameters, the user's jump trajectory in the real world is redirected to drive the jumps of the avatar in the virtual world. The redirected jumping curve is differentiable and continuous throughout its domain and conforms to the definition of a parabola.;Jumping-At-Air : Jumping without Touching the Ground in Virtual Reality;Locomotion, Navigation and Redirection;7PYBbndpOzQ
34;TBD;"Jennifer Brade: Professorship Production Systems and Processes; Alexander Kögel: Professorship of Ergonomics and Innovation Management; Franziska Klimant: Professorship Production Systems and Processes; Martin Dix: Professorship Production Systems and Processes";This study examined two input methods—real bicycle and gaming controller—in a virtual bike tour. Participants engaged in a virtual bike tour using both methods while assessing presence and user experience. The bicycle method notably enhanced sense of physical space, engagement, and ecological validity, resulting in a more immersive experience. While pragmatic qualities showed no significant differences, the bicycle method excelled in hedonic qualities. The findings indicate that realistic physical interaction boosts presence and appeal, suggesting future research on different movement types.;Pedaling into Presence: Evaluating Presence and User Experience in VR Cycling vs. Controller Use;User Experience and Presence;DqHE7t66QdY
35;TBD;"Ye-Seom Jin: Konkuk University; BoYu Gao: Jinan University; HyungSeok Kim: Konkuk University";Motion sickness is regarded as one of important limitations in Virtual Reality (VR) applications. This study investigates the effects of vertical vibrations and additional rotational vestibular stimulation on alleviating discomfort and enhancing immersion. We conducted pilot and main studies to examine the threshold of stimulation intensity to reduce motion sickness. Experimental results revealed that the effect of vestibular stimuli varied based on user characteristics such as gender, age, and vision, highlighting the need for personalized stimulation. The initial findings offer suggestion for developing more comfortable and immersive VR experiences.;Exploring User-Specific Variations in Vestibular Stimulation to Reduce Motion Sickness in VR;User Experience and Presence;f15HtWfo5p8
36;TBD;"Shi Qiu: CUHK; Binzhu Xie: The Chinese University of Hong Kong; Qixuan Liu: CUHK; Pheng Ann Heng: The Chinese University of Hong Kong";3D Gaussian Splatting (3DGS) has recently emerged as an innovative and efficient 3D representation technique. While its potential for extended reality (XR) applications is frequently highlighted, its practical effectiveness remains underexplored. In this work, we examine three distinct 3DGS-based approaches for virtual environment (VE) creation, leveraging their unique strengths for efficient and visually compelling scene representation. By conducting a comparable study, we evaluate the feasibility of 3DGS in creating immersive VEs, identify its limitations in XR applications, and discuss future research and development opportunities.;Creating Virtual Environments with 3D Gaussian Splatting: A Comparative Study;User Experience and Presence;XR3GzmpCdlE
37;TBD;"Damla Welti: ETH Zurich; Mathieu Lutfallah: ETH Zurich; Long Cheng: Innovation Center Virtual Reality; Andreas Kunz: ETH Zurich";Visualization of complex architectural and interior design proposals demands spatial comprehension. Mixed Reality (MR) is particularly effective in architectural visualization because it overlays virtual models onto already existing real environments. However, this approach alone restricts users to the physical constraints of their surroundings. We developed two approaches to augment MR with additional perspectives from physically inaccessible viewpoints: the World-in-Miniature (WIM) solution and the Cross Reality (CR) solution. The WIM solution provides a scaled-down 3D replica of the virtual environment, whereas the CR solution enables users to switch to Virtual Reality and allows them to teleport to physically inaccessible viewpoints.;Towards Cross Reality: A Comparison of World-in-Miniature and Virtual Reality Switch;User Experience and Presence;CPu87SfOhv8
38;TBD;"Alexander Marquardt: Institute of Visual Computing; Marvin Lehnort: Institute of Visual Computing; Melissa Steininger: University Hospital Bonn; Ernst Kruijff: Bonn-Rhein-Sieg University of Applied Sciences ; Kiyoshi Kiyokawa: Nara Institute of Science and Technology; Monica Perusquia-Hernandez: Nara Institute of Science and Technology";This work explores how thermal feedback can enhance awe experiences in virtual reality (VR). We developed a custom thermal feedback system integrated into a VR headset that delivers temperature sensations to the user's face while viewing vast scenes of snow-covered mountains and desert canyons. Our results show that thermal feedback significantly enhanced presence measures while influencing specific components of awe experiences, specifically those related to physical sensations.;Temperature Matters: Thermal Feedback for Awe Experiences in VR;User Experience and Presence;Yqj_wCPEwO8
39;TBD;"ByeongSun Hong: DeepXRLab; Qimeng Zhang: Korea University; Gerard Jounghyun Kim: Korea University; Jun Ryu: Korea University";Difficulty arises in virtual reality (VR) due to cybersickness. The discrepancy in motion information between the visual and vestibular feedback causes sensory conflict, a widely accepted cause for cyber-sickness. Previous research has shown reduced VR sickness by augmenting the content with motion patterns in the opposite direction of the virtual motion. However, it can also cause significant content intrusion. This poster aims to mitigate the latter by applying content-aware textured motion patterns vs. simple white animated feature points. Positive results were obtained with a higher preference for the proposed visualization while showing a similar degree of sickness reduction.;The Effects of Content-Aware Textured Reverse Motion Flow on Cybersickness and User Experience;User Experience and Presence;4jE7CdHKWXU
40;TBD;"Bibek Khattri: Birmingham City University; Paweenuch Chantratita: Birmingham City University; Maite Frutos-Pascual: Birmingham City University; Ian Williams: Birmingham City University";Sentiment analysis is a common method for evaluating the meaning of text. While commonplace, the application of sentiment analysis for assessing collaborative teamwork is limited. We present an exploratory study of sentiment analysis as a useful companion to established metrics of user collaboration in VR. We present results of paired users (N=14, Npairs = 7) completing a VR brainstorming task, and sentiment analysis on their conversation. We report on how the sentiment process maps to the Team Workload Questionnaire (TWLQ) and illustrate how this could be a valuable metric for supporting an enriched evaluation of collaborative VR.;I’ve Got a Feeling: Sentiment analysis for collaborative performance in VR;User Experience and Presence;L3fvj5xGAbQ
41;TBD;"Yasufumi Nakata: Keio University; Mayuka Otsuki: Keio University; Miki Nagai: Keio University; Ryosuke Yamamoto: Keio University; Minori Sakai: Keio University; Atsushi Aoyama: Keio University";VR offers immersive experiences but often causes cybersickness, hindering application. Here, we analyzed electroencephalographic (EEG) data for VR-induced discomfort associated with display parameters. Increased discomfort correlates with higher low-frequency and lower mid-frequency EEG signal power, indicating changes in autonomic activity and cognition. Previous studies have not thoroughly examined the neural impact of individual display settings. Our findings reveal the complex interplay between the display settings and EEG patterns. Optimizing the settings can mitigate discomfort and improve VR experiences, promoting wider application of VR technology.;Exploring Display Parameters Associated with Cybersickness Using Electroencephalography;User Experience and Presence;1LE-EbZ5lGo
42;TBD;Gang Li: University of Bath;Among 41 participants, two males exhibited no motion sickness (MS) at all during a VR-based cognitive discrimination task. The first, a judo practitioner with 16 years of mid-air balance control training, and the second, a commuter accustomed to reading while commuting, showed suppressed beta activity between cognitive and sensorimotor domains in our EEG analysis, associated with better cognitive behavioral performance. The judo practitioner demonstrated stronger suppression and superior cognitive behavioral performance. These findings raise whether beta activity suppression between cognitive and sensorimotor cortical domains reflects compensatory reticular neuron activation in the deep brainstem under a proposed MS habituation mechanism.;Case Studies of Remarkable VR Motion Sickness Resistance: A Judo Practitioner and a Commuter;User Experience and Presence;uMdbq6ky9Nk
43;TBD;"Francesco Vona: University of Applied Sciences Hamm-Lippstadt; Julia Schorlemmer: Immersive Reality Lab, University of Applied Sciences Hamm-Lippstadt ; Michael Stern: University of Applied Sciences Hamm-Lippstadt; Navid Ashrafi: University of Applied Sciences Hamm-Lippstadt; Maurizio Vergari: Technische Universität Berlin; Tanja Kojic: Technische Universität Berlin; Jan-Niklas Voigt-Antons: Hamm-Lippstadt University of Applied Sciences";In extended reality, “pass-through” enables users to view their real-world surroundings via cameras on the headset, displaying live video inside the device. This study compared the pass-through quality of three devices: Apple Vision Pro, Meta Quest 3, and Varjo XR-3. Thirty-one participants performed two tasks—reading a text and solving a puzzle—while using each headset with the pass-through feature activated. Participants then rated their experiences, focusing on workload and cybersickness. Results showed that the Apple Vision Pro outperformed the Meta Quest 3 and Varjo XR-3, receiving the highest ratings for pass-through quality.;Comparing Pass-Through Quality of Mixed Reality Devices: A User Experience Study During Real-World Tasks;User Experience and Presence;ctFcUCNSOTo
44;TBD;"Isaac Taylor: Ontario Tech University; Hamed Tadayyoni: Ontario Tech University; Fabian Gualdron: Ontario Tech University; Alvaro Quevedo: Ontario Tech University; Pejman Mirza-Babaei: University of Ontario Institute of Technology";The adoption of virtual reality (VR) in education, training, and health care, among others, has resulted in non-VR users exposed to immersive experiences. While VR provides immersion with various degrees of realism, several tasks are not properly represented due to the technology's limitations. For example, multiple actions require game controllers that fail to represent real-world actions. This paper evaluates the effects of onboarding techniques on usability, cognitive load, and presence on commercial video games and serious games developed for research. Our preliminary results highlight different impacts caused by the freedom and proper representation of tasks in the tutorials.;Evaluating Usability, Cognitive Load, and Presence in VR Tutorials: A Preliminary Study;User Experience and Presence;AsVZoVwBmOQ
45;TBD;"Md Jahirul Islam: Kennesaw State University; Rifatul Islam: Kennesaw State University";Cybersickness (CS) is a major problem that is induced around 60-95% users due to immersive VR exposure, creates an obstacle for comfortable experiences. Deep learning models can predict CS, but require powerful resources, which is unsuitable for computationally constrained standalone VR (SVR) headsets. Using external computing resources can increase complexity. To address these gaps, we developed a framework for SVR devices where we trained deep learning models using physiological data, optimized the model, and deployed in the SVR headset to predict CS in real-time (during immersion) with minimum inference time. Our findings introduce future directions for real-time cybersickness prediction on SVR devices.;Towards Optimized Real-time Cybersickness Detection framework Using Deep Learning for Standalone Virtual Reality Headsets;User Experience and Presence;qfZad11Ckic
46;TBD;"Andrew J. Jones anjones1@davidson.edu: Davidson College; Raghuram Ramanujan: Davidson College; Tabitha C. Peck: Davidson College";Phone-based head mounted displays (HMDs) make participation in virtual reality (VR) easily accessible. However, phone-based HMDs can only track the user's head orientation, excluding head position. This not only stifles the user's immersion in the virtual environment, but also risks simulator sickness. To mitigate this limitation, we propose a fully-connected neural network that predicts the user's head position given the head orientation history and other information about the user's movement that can be tracked from phone sensors. To analyze performance, the model iterates over the test dataset, predicting the entirety of the dataset's positional displacement history.;A Machine Learning Approach to Expanding the Degrees of Freedom on Phone-Based Head Mounted Displays;User Experience and Presence;fqEDEDF1Lvs
47;TBD;"Qi Wu: Communication University of China; Di Zhang: Communication University of China; Vincent Nourrit: IMT Atlantique; Jean-Louis de Bougrenet: IMT Atlantique; Long Ye: Communication University of China";Flow is a key indicator of deep immersion, but existing detection methods rely on intrusive physiological devices, limiting real-time analysis. To overcome this, we used Tobii eye-tracking glasses to record eye movement data during gaming sessions, identifying patterns correlated with flow states. We developed a non-intrusive system with a custom algorithm to detect flow in real time, achieving 85.3% accuracy and a 412 ms detection delay. This system provides valuable insights into the relationship between flow and game design, enhancing the understanding of flow's biophysical mechanisms.;Real-Time Flow State Analysis in Game: A Non-Intrusive System Based on Eye Feature Detection;User Experience and Presence;X3JCw8VMcwI
48;TBD;"Tomokazu Ishikawa: Toyo University; Takaaki Ueno: Toyo University";This study investigated unconscious visual effects in VR for enhancing concentration. Four peripheral vision effects (blur, chromatic aberration, mosaic, peripheral vignetting) were examined through two experiments. Twenty participants determined detection thresholds, then 15 tested concentration effects via typing tasks. Results showed blur and peripheral vignetting significantly improved typing accuracy and reduced keystroke intervals. Subjective evaluations supported these findings, indicating subtle visual modifications can enhance concentration without conscious awareness. The research demonstrates potential for strategically designed visual interventions in VR that optimize cognitive performance.;A Research on Unconscious Visual Effects for Enhancing Concentration in Virtual Reality;User Experience and Presence;9tTVdBZ1Vk0
49;TBD;"Íris Peixoto: Instituto Politécnico de Setúbal; Joana Silva Cerqueira: Universidade NOVA de Lisboa - Faculdade de Ciências e Tecnologias ; André Antunes: NOVA University of Lisbon; Anna Letournel: Setúbal Polytechnic University; Rui Neves Madeira: NOVA University of Lisbon";Innovative therapeutic tools are essential for conditions like anxiety and food aversion. This study integrates EEG and ECG signals with a VR-based serious game for exposure therapy. Preliminary results show consistent detection of EEG biomarkers, such as N200, during VR tasks and evidence of neural habituation. Despite challenges with ECG artifacts, the successful integration of EEG and VR highlights the feasibility of real-time neurofeedback. Our approach shows auspicious results towards personalized therapeutic interventions by combining VR’s immersive qualities with the potential of neurofeedback-driven adaptability, advancing exposure therapy based on physiological feedback.;Leveraging Real-Time EEG Neurofeedback in VR for Personalized Interventions in Exposure Therapy;User Experience and Presence;fxRjQWELpBk
50;TBD;"guotao wang: Beihang University; Chenglizhao Chen: China University of Petroleum; Aimin Hao: Beihang University";Personalized 360° content generation faces significant challenges due to the lack of adaptation to user preferences during interaction. Traditional methods rely on static content or post-session analysis, which limits dynamic engagement. In this paper, we propose a novel approach that integrates gaze tracking with dynamic content generation to create personalized 360° experiences. By analyzing gaze trajectories and user preferences, our approach adjusts content based on the user’s visual focus, leading to a more immersive experience. Experimental results show that our approach enhances content relevance and user engagement compared to existing methods, demonstrating the potential of gaze-driven personalized content in VR.;Eye-Tracking Driven Personalized 360° Panorama Content Generation;User Experience and Presence;eT23W394Pko
51;TBD;"Rui Neves Madeira: Instituto Politécnico de Setúbal; Pedro Albuquerque Santos: Lisbon School of Engineering (ISEL), Politécnico de Lisboa (IPL); Diogo Pinto: Polytechnic University of Setubal";Parkinson’s Disease (PD) is a neurodegenerative disorder where physical exercise is crucial for symptom management and quality of life. This paper presents prototypes supporting therapeutic exercises for PD patients: the Wall Game, utilizing Kinect, and the Object Sorting Game, using Meta Quest. These prototypes target motor coordination, balance, and cognitive engagement by integrating physiotherapy exercises into game scenarios. A user study with 30 participants evaluated usability, cognitive demand, and therapeutic potential. Results showed high usability and low workload scores, confirming these games' feasibility as therapeutic tools. Future work will validate them with PD patients and refine gameplay based on feedback.;Prototyping Therapeutic Gaming: from Semi-Immersive to Fully Immersive Games for Parkinson’s Disease;User Experience and Presence;xM_3vjnilHE
52;TBD;"Paweł Jemioło: AGH University of Krakow; Adrian Kuśmierek: AGH University of Krakow";This study explores affective computing in virtual reality (VR) gaming, focusing on adapting gameplay to players' arousal levels. By utilizing real-time physiological signals, such as heart rate and electrodermal activity, the VR game HeartFortress dynamically adjusts its mechanics. Observations suggest that the adaptive version of the game may enhance flow - a state of deep involvement in an activity - and increase physiological responsiveness, indicating heightened arousal. While preliminary, these findings highlight the potential of affective-driven adaptations in interactive systems, offering insights for gaming, training, and therapeutic applications.;HeartFortress - an Affective VR Game Adapting to Player Emotions;User Experience and Presence;YyOJpdvrZSc
53;TBD;"Raquel T. Cabrera-Araya: Texas A&M University ; Siyu Huang: Purdue University; Mohammad Nadim: Texas A&M University - Central Texas; Edgar Javier Rojas-Muñoz: Texas A&M University; Anitha Chennamaneni: Texas A & M University Central Texas; Walter Murphy: Texas A&M University-Central Texas; Voicu Popescu: Purdue University";Study groups are crucial in education to foster collaboration and motivation. Remote students, at greater risk of isolation, often miss this peer-driven environment. This paper presents Buenas, an Extended Reality (XR) system enabling remote students to participate in on-campus study groups seamlessly. Local students interact with projected representations of remote peers seated at a conference table, while remote students use XR headsets to integrate the group into their physical surroundings. A user study comparing Buenas to conventional videoconferencing showed significant improvements in engagement, presence, connectedness, and rapport through both objective and subjective measures.;Buenas: Giving Everyone a Seat at the Study Group Table;User Experience and Presence;3YeXHCDKK74
54;TBD;"Teresa Matos: FEUP; Daniel Mendes: FEUP/INESCTEC; João Tiago Jacob: FEUP; A. Augusto Sousa: FEUP/INESCTEC; Rui Rodrigues: FEUP/INESC TEC";Virtual Reality allows users to experience realistic environments in an immersive and controlled manner, particularly beneficial for contexts where the real scenario is not easily or safely accessible. The choice between 360º content and 3D models impacts outcomes such as perceived quality and computational cost, but can also affect user attention. This study explores how attention manifests in VR using a 3D model or a 360º image rendered from said model during visuospatial tasks. User tests revealed no significant difference in workload or cybersickness between these types of content, while sense of presence was reportedly higher in the 3D environment.;Do We Need 3D to See? Impact of Dimensionality of the Virtual Environment on User Attention;User Experience and Presence;_c66Y-Tc1vA
55;TBD;"Julia Hertel: University of Hamburg; Jan Nicolai Synwoldt: Universität Hamburg; Frank Steinicke: Universität Hamburg";Currently, optical see-through augmented reality HMDs (OST AR HMDs) still have significant display limitations. This work presents a user study conducted with an OST AR HMD to investigate how two of these limitations - a small field of view and low resolution - affect task performance, user experience, workload, and simulator sickness in the context of immersive analytics. The Magic Leap 2 was used to simulate the display properties of other commonly used HMDs. The results suggest that a limited field of view negatively impacts user experience and workload, with the difference between the Magic Leap 2's field of view and that of the two generations of the Microsoft HoloLens being particularly striking.;Investigating the Effects of Limited Field of View and Resolution in Optical See-Through Augmented Reality in the Context of Immersive Analytics;User Experience and Presence;ckDrDFftfjE
