Paper ID,Status,Title,Contact Name,Contact Email,Note,Decision,Overall Score,Comments to Authors,Camera-Ready Extended Abstract (2 pages),Camera-Ready Extended Abstract (2 pages) pages,Camera-Ready Extended Abstract (2 pages) paper size,Camera-Ready Extended Abstract (2 pages) last update,Promotional Image,Presenting author,Abstract,Video URL (3-5 min),Video URL (30 sec),Author 1 - id,Author 1 - prefix,Author 1 - first,Author 1 - middle,Author 1 - last,Author 1 - suffix,Author 1 - email,Author 1 - dept/school/lab 1,Author 1 - institution 1,Author 1 - city 1,Author 1 - state/prov 1,Author 1 - country 1,Author 1 - dept/school/lab 2,Author 1 - institution 2,Author 1 - city 2,Author 1 - state/prov 2,Author 1 - country 2,Author 2 - id,Author 2 - prefix,Author 2 - first,Author 2 - middle,Author 2 - last,Author 2 - suffix,Author 2 - email,Author 2 - dept/school/lab 1,Author 2 - institution 1,Author 2 - city 1,Author 2 - state/prov 1,Author 2 - country 1,Author 2 - dept/school/lab 2,Author 2 - institution 2,Author 2 - city 2,Author 2 - state/prov 2,Author 2 - country 2,Author 3 - id,Author 3 - prefix,Author 3 - first,Author 3 - middle,Author 3 - last,Author 3 - suffix,Author 3 - email,Author 3 - dept/school/lab 1,Author 3 - institution 1,Author 3 - city 1,Author 3 - state/prov 1,Author 3 - country 1,Author 3 - dept/school/lab 2,Author 3 - institution 2,Author 3 - city 2,Author 3 - state/prov 2,Author 3 - country 2,Author 4 - id,Author 4 - prefix,Author 4 - first,Author 4 - middle,Author 4 - last,Author 4 - suffix,Author 4 - email,Author 4 - dept/school/lab 1,Author 4 - institution 1,Author 4 - city 1,Author 4 - state/prov 1,Author 4 - country 1,Author 4 - dept/school/lab 2,Author 4 - institution 2,Author 4 - city 2,Author 4 - state/prov 2,Author 4 - country 2,Author 5 - id,Author 5 - prefix,Author 5 - first,Author 5 - middle,Author 5 - last,Author 5 - suffix,Author 5 - email,Author 5 - dept/school/lab 1,Author 5 - institution 1,Author 5 - city 1,Author 5 - state/prov 1,Author 5 - country 1,Author 5 - dept/school/lab 2,Author 5 - institution 2,Author 5 - city 2,Author 5 - state/prov 2,Author 5 - country 2,Author 6 - id,Author 6 - prefix,Author 6 - first,Author 6 - middle,Author 6 - last,Author 6 - suffix,Author 6 - email,Author 6 - dept/school/lab 1,Author 6 - institution 1,Author 6 - city 1,Author 6 - state/prov 1,Author 6 - country 1,Author 6 - dept/school/lab 2,Author 6 - institution 2,Author 6 - city 2,Author 6 - state/prov 2,Author 6 - country 2,Author 7 - id,Author 7 - prefix,Author 7 - first,Author 7 - middle,Author 7 - last,Author 7 - suffix,Author 7 - email,Author 7 - dept/school/lab 1,Author 7 - institution 1,Author 7 - city 1,Author 7 - state/prov 1,Author 7 - country 1,Author 7 - dept/school/lab 2,Author 7 - institution 2,Author 7 - city 2,Author 7 - state/prov 2,Author 7 - country 2,Author 8 - id,Author 8 - prefix,Author 8 - first,Author 8 - middle,Author 8 - last,Author 8 - suffix,Author 8 - email,Author 8 - dept/school/lab 1,Author 8 - institution 1,Author 8 - city 1,Author 8 - state/prov 1,Author 8 - country 1,Author 8 - dept/school/lab 2,Author 8 - institution 2,Author 8 - city 2,Author 8 - state/prov 2,Author 8 - country 2,Author 9 - id,Author 9 - prefix,Author 9 - first,Author 9 - middle,Author 9 - last,Author 9 - suffix,Author 9 - email,Author 9 - dept/school/lab 1,Author 9 - institution 1,Author 9 - city 1,Author 9 - state/prov 1,Author 9 - country 1,Author 9 - dept/school/lab 2,Author 9 - institution 2,Author 9 - city 2,Author 9 - state/prov 2,Author 9 - country 2,Author 10 - id,Author 10 - prefix,Author 10 - first,Author 10 - middle,Author 10 - last,Author 10 - suffix,Author 10 - email,Author 10 - dept/school/lab 1,Author 10 - institution 1,Author 10 - city 1,Author 10 - state/prov 1,Author 10 - country 1,Author 10 - dept/school/lab 2,Author 10 - institution 2,Author 10 - city 2,Author 10 - state/prov 2,Author 10 - country 2,Author 11 - id,Author 11 - prefix,Author 11 - first,Author 11 - middle,Author 11 - last,Author 11 - suffix,Author 11 - email,Author 11 - dept/school/lab 1,Author 11 - institution 1,Author 11 - city 1,Author 11 - state/prov 1,Author 11 - country 1,Author 11 - dept/school/lab 2,Author 11 - institution 2,Author 11 - city 2,Author 11 - state/prov 2,Author 11 - country 2,Author 12 - id,Author 12 - prefix,Author 12 - first,Author 12 - middle,Author 12 - last,Author 12 - suffix,Author 12 - email,Author 12 - dept/school/lab 1,Author 12 - institution 1,Author 12 - city 1,Author 12 - state/prov 1,Author 12 - country 1,Author 12 - dept/school/lab 2,Author 12 - institution 2,Author 12 - city 2,Author 12 - state/prov 2,Author 12 - country 2,ACM Author Affiliations,"ACM Author Emails, excluding contact email"
PO1063,complete,Demonstration of Petting Interaction with Breathing Cat Using Mid-Air Ultrasound Haptic Feedback,Juro Hosoi,jhosoi@s.h.k.u-tokyo.ac.jp,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1063-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=e6e071cbfd632960f59f1fc9e8a6c74a4cab9b45c54f2f65e0f9cf3a9b84b6ff,2,letter,2025-01-27 7:56,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1063-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=293919ce39f6131e80be7440b3a95a87ad761d25b3abde89f9b16029bbba7100,Juro Hosoi,"This study introduces a petting interaction system with a virtual breathing cat, utilizing mid-air ultrasound haptic feedback to enhance the realism of pet experiences in virtual reality (VR). Previous research has focused mainly on the tactile presentation of the fur texture, and interaction with realistic virtual animals has not been fully investigated. Therefore, based on the prior work, the proposed system employs airborne ultrasound tactile displays (AUTDs) and a hand tracking camera to deliver real-time, non-contact haptic feedback simulating not only the soft fur texture but also the breathing motion. By dynamically controlling the ultrasound focal point’s position and intensity, the system reproduces the tactile sensations of fur stroking and rhythmic respiratory motion. The visual component features a 3D cat model synchronized with breathing cycles, situated in a familiar domestic setting. User experience design focused on creating a calming interaction, with tactile feedback adjusting based on hand movement patterns.",https://youtu.be/oQrccIH301Y,,u9VW3yTLUCD1dhH-E_IBdfw,,Juro,,Hosoi,,jhosoi@s.h.k.u-tokyo.ac.jp,The Graduate School of Frontier Sciences,The University of Tokyo,Chiba,,Japan,,,,,,udnlKV10-6jTVMQTXEoIVrg,,Yuki,,Ban,,ban@edu.k.u-tokyo.ac.jp,,The University of Tokyo,Kashiwanoha,Chiba,Japan,,,,,,urXj8nWGIFv3Y8CtfzJAQeg,Professor,Shinichi,,Warisawa,,warisawa@edu.k.u-tokyo.ac.jp,,The University of Tokyo,Kashiwa,,Japan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Juro Hosoi: The University of Tokyo; Yuki Ban: The University of Tokyo; Shinichi Warisawa: The University of Tokyo,ban@edu.k.u-tokyo.ac.jp; warisawa@edu.k.u-tokyo.ac.jp
PO1084,complete,Demonstration of Directional Force Feedback in Virtual Reality Tennis using Dual-Flywheel Haptics,Jasmine Roberts,jar053@ucsd.edu,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1084-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=8cfc8994627c5783fb949758208f38e7fa606e6cc8ef0b90d7f2844b36971725,2,letter,2025-01-31 16:22,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1084-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=1e4880c2d823b8a855abba1fb38d234fc46be52a5cacae5dd39ae5129da0fe05,Jasmine Roberts,"This demo introduces a haptic feedback device for tennis simulation, designed to provide realistic physical sensations of ball impact through interaction with a virtual racket model. The system integrates with a Unity-based virtual setup where users are visually immersed in a virtual tennis court environment. Unlike previous systems, this device incorporates a mechanical interface that replicates the sensation of a tennis ball striking the racket using a dual flywheel system. This approach follows a one-controller, one-function paradigm, where each input device is dedicated to a specific function rather than serving as a general-purpose controller. This targeted design enhances realism and improves user immersion by providing precise, specialized feedback rather than distributing multiple functionalities across a single device. Furthermore, this system aligns with augmented virtuality, as it brings physical sensations into an otherwise fully virtual environment, reinforcing the sense of realism and presence.",https://youtu.be/sBvCS_lmmE0,,uV0dC_UQr_AuMDAZVJ4UYFQ,,Allyson,E,Chen,,aechen@ucsd.edu,,"University of California, San Diego",La Jolla,California,United States,,,,,,uPZK1eg_b7klY1Rhxshz1tQ,,Xuan,,Gedney,,xgedney@ucsd.edu,,University of California San Diego ,La Jolla ,California,United States,,,,,,ukJVZvMvrrME6EMFwh0Uc-Q,,Jasmine,,Roberts,,jar053@ucsd.edu,,"University of California, San Digo ",La Jolla ,California,United States,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Allyson E Chen: University of California, San Diego; Xuan Gedney: University of California San Diego ; Jasmine Roberts: University of California, San Digo ",aechen@ucsd.edu; xgedney@ucsd.edu
PO1080,complete,FirstModulAR: Open Source Modular Augmented Reality Interfaces for First Responders,Regis Kopper,kopper@iastate.edu,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1080-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=04d08340c69429b3868bce4204a3e56c7eaa04d448f4ab9e25e0479c85ac2a3d,2,letter,2025-01-29 0:25,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1080-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=4e74f77bd2cb800ec73411c789471fab57d9d7434c4a58ad9753dd2512e7a38c,Regis Kopper,"First responders operate in high-pressure environments where decisions must be made quickly and accurately. However, the increasing availability of real-time data presents a double-edged sword; while potentially valuable, the sheer volume of information can lead to cognitive overload, compromising situational awareness and performance. The FirstModulAR project seeks to address these challenges by developing modular Augmented Reality (AR) interfaces specifically tailored to public safety. By working closely with first responders, the project focuses on creating reusable AR modules that improve situational awareness and decision-making across diverse scenarios. This paper provides an overview of the system architecture, the modular design approach, and the integration of AR solutions into realistic public safety scenarios.",https://drive.google.com/file/d/1ShRMSL9gtKB-2o49o7LP1_u5karlGcvk/view?usp=share_link,,ul06o78T_Y7tH8JaOMZt1qQ,,Regis,,Kopper,,kopper@iastate.edu,Department of Computer Science,Iowa State University,Ames,Iowa,United States,,,,,,uBLiRxXnEkqm0n8Gv_2Wwpw,,Jeronimo,,Grandi,,jgrandi@augusta.edu,Computer & Cyber Sciences,Augusta University,Augusta,Georgia,United States,,,,,,uHAA817rE8NUHh_cP3hnMhA,,Erin,,Argo,,dargo@augusta.edu,,Augusta University,Augusta,Georgia,United States,,,,,,u3Jf2ey1IaR159bGJh4xi9w,,Jason,,Jerald,,jason@nextgeninteractions.com,,NextGen Interactions,Raleigh,North Carolina,United States,,,,,,uTGJDe0ug6pvcBteUCsToQQ,,Rich,,Bennett,,rich@nextgeninteractions.com,,NextGen Interactions,Raleigh,North Carolina,United States,,,,,,u0UaHSehz0FmWdxx47uIdlQ,,Connor,,Shipway,,connor@nextgeninteractions.com,,NextGen Interactions,Raleigh,North Carolina,United States,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Regis Kopper: Iowa State University; Jeronimo Grandi: Augusta University; Erin Argo: Augusta University; Jason Jerald: NextGen Interactions; Rich Bennett: NextGen Interactions; Connor Shipway: NextGen Interactions,jgrandi@augusta.edu; dargo@augusta.edu; jason@nextgeninteractions.com; rich@nextgeninteractions.com; connor@nextgeninteractions.com
PO1029,complete,"StimulHeat: a Clip-On, Low-Energy and Wireless Device for Thermal Feedback when Grasping in VR",Sophie Villenave,sophie.villenave@ec-lyon.fr,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1029-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=fa7629ae717f247b6473052dd5f3a9a80f8781d2ca2446b76726658fa0fa7a48,2,letter,2025-01-24 13:31,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1029-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=1b3456e0d4995b6554988a1ba71fcc2db9ff00c340055df5ac69d462cc98df6c,Matthieu Mesnage,"Adding thermal feedback to Virtual Reality (VR) experience enhances user immersion and the resulting feeling of presence. Our device, StimulHeat, provides a wireless, low-power and easy-to-use solution for delivering hot and cold sensations in VR, particularly when grasping objects. This demonstration highlights its integration with Valve Index Controllers, though it can be adapted to various controllers or tangible interfaces for both augmented and mixed reality experiences.",https://youtu.be/_0hOmilWdRA,,u1aVc2Q3oAE_bGJKxgoHuAw,,Matthieu,,Mesnage,,matthieu.mesnage@insa-lyon.fr,,"INSA Lyon, Ecole Centrale Lyon, Universite Claude Bernard Lyon 1, CPE Lyon, CNRS, INL UMR 5270, 69100",Villeurbanne,,France,,,,,,u5YW5_eEJ0hyRzWze2I9qoA,,Sophie,,Villenave,,sophie.villenave@ec-lyon.fr,,"Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE",Saint-Etienne,,France,,,,,,ucB1dUXQDZTcHcCivsHBO-g,,Pierre,,Raimbaud,,pierre.raimbaud.pr@gmail.com,,"Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE",Saint Etienne,,France,,,,,,uMmAJOBHKgts2TGlYEJXE4Q,,Guillaume,,Lavoué,,glavoue@liris.cnrs.fr,,"Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE",Saint-Etienne,,France,,,,,,u5k43MYcClNkIPf_i7NlSDA,Dr,Bertrand,,Massot,,bertrand.massot@insa-lyon.fr,,"INSA Lyon, Ecole Centrale Lyon, Universite Claude Bernard Lyon 1, CPE Lyon, CNRS, INL UMR 5270",Villeurbanne,,France,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Matthieu Mesnage: INSA Lyon, Ecole Centrale Lyon, Universite Claude Bernard Lyon 1, CPE Lyon, CNRS, INL UMR 5270, 69100; Sophie Villenave: Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE; Pierre Raimbaud: Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE; Guillaume Lavoué: Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE; Bertrand Massot: INSA Lyon, Ecole Centrale Lyon, Universite Claude Bernard Lyon 1, CPE Lyon, CNRS, INL UMR 5270",matthieu.mesnage@insa-lyon.fr; sophie.villenave@liris.cnrs.fr; pierre.raimbaud.pr@gmail.com; glavoue@liris.cnrs.fr; bertrand.massot@insa-lyon.fr
PO1016,complete,RAGatar: Enhancing LLM-driven Avatars with RAG for Knowledge-Adaptive Conversations in Virtual Reality,Alexander Marquardt,marquardt@ieee.org,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1016-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=1a501cc1d6b000c32f406f23fb36dae99ee030cd409d85aa4cc33a955731f5f0,2,letter,2025-01-23 10:03,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1016-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=a7504720e05d86470a44703fa3268af27904ef3ddefdb50e11558df318a10dd7,Alexander Marquardt,"We present a virtual reality system that enables users to seamlessly switch between general conversations and domain-specific knowledge retrieval through natural interactions with AI-driven avatars. By combining MetaHuman technology with self-hosted large language models and retrieval-augmented generation, our system demonstrates how immersive AI interactions can enhance learning and training applications where both general communication and expert knowledge are required.",https://youtu.be/yMbhFWAVFew,,uW6We8kgprFzyJsJ-_3qEIQ,,Alexander,,Marquardt,,marquardt@ieee.org,Bonn-Rhein-Sieg University of Applied Sciences,Institute of Visual Computing,Sankt Augustin,,Germany,,VAGO Solutions,Hennef (Sieg),,Germany,uVGSXAYvS67VFIQ3hLtSJMA,,David,,Golchinfar,,david.golchinfar@h-brs.de,,University of Applied Sciences Bonn-Rhein-Sieg,Sankt Augustin,,Germany,,VAGO Solutions,Hennef (Sieg),,Germany,u1mi0up-VPpayjakEnYBQow,Dr.,Daryoush,Daniel,Vaziri,,daryoush.vaziri@h-brs.de,Business Informatics,University of Applied Sciences,Sankt Augustin,,Germany,,VAGO Solutions,Hennef (Sieg),,Germany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Alexander Marquardt: Institute of Visual Computing; David Golchinfar: University of Applied Sciences Bonn-Rhein-Sieg; Daryoush Daniel Vaziri: University of Applied Sciences,david.golchinfar@h-brs.de; daryoush.vaziri@h-brs.de
PO1121,complete,Demo: Automated Multiparty Conversations Analysis in VR Massive Multiplayer Online Games Environments,Dr Elio Salvadori,esalvadori@fbk.eu,,A,4.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1121-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=408fc7c76b00335719fa5669a5924c759c70273311084855fd89df0f93665e54,2,letter,2025-01-27 14:32,,Riccardo Calcagno,"The study of social interactions in Massively Multiplayer Online Games (MMOGs) has largely focused on chat communication and speech content analysis. This paper introduces a novel tool designed to analyze social interactions among MMOG players by leveraging Conversation Analysis methodologies to systematically assess multi-party interactions during 6DOF Virtual Reality sessions. The Multiparty Conversation Analysis (MCA) tool can be applied in several MMOG contexts where social analysis is needed. In this demo paper, we present a specific application of the tool focusing on VR MMOG-based therapy for autistic teens. A video demo can be seen in: https://www.youtube.com/watch?v=U4A4vkjUrvM",https://www.youtube.com/watch?v=U4A4vkjUrvM,,u78E6Yc2ELdkyYz2VApx0cg,,Riccardo,,Calcagno,,riccardocalc7@gmail.com,,Fondazione Bruno Kessler,Trento,TN,Italy,,,,,,uHAeE5gnT3P2DHeqASh3PSA,Dr,Elio,,Salvadori,,esalvadori@fbk.eu,,Fondazione Bruno Kessler,Trento,,Italy,,,,,,uPEEKBruR8SUkafvZ08vLzA,,Oscar,,Mayora,,omayora@fbk.eu,,Fondazione Bruno Kessler Research Institute,Trento,,Italy,,,,,,uOC7D9zCrQCVDKiQAgE64TA,,Giovanna,,Varni,,giovannapaola.varni@unitn.it,DISI,University of Trento,Povo,,Italy,,,,,,um_YPwpQG-0iAFTi7kFsONQ,Dr.,Luca,,Turchet,,luca.turchet@unitn.it,Department of Information Engineering and Computer Science,University of Trento,Trento,,Italy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Riccardo Calcagno: Fondazione Bruno Kessler; Elio Salvadori: Fondazione Bruno Kessler; Oscar Mayora: Fondazione Bruno Kessler Research Institute; Giovanna Varni: University of Trento; Luca Turchet: University of Trento,rcalcagno@fbk.eu; omayora@fbk.eu; giovannapaola.varni@unitn.it; luca.turchet@unitn.it
PO1132,complete,Demo: Out-Of-Body Experience induced after Virtual Embodiment,Pierre Bourdin-Kreitz,pbourdin@uoc.edu,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1132-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=7a22b9cb07fadea53a5d169e00bce1300c5f2bca4be2ecd65080012adb2d4e05,2,letter,2025-01-29 23:21,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1132-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=05a6e51776c0ca184aa7a6e737388157666eea1753deac6c33d17240a612bcde,Pierre Bourdin-Kreitz and Andreu Castaño Jiménez,"Out-of-body experiences (OBEs), where individuals perceive themselves as separated from their physical bodies, hold significant potential for research in psychology and neuroscience. We present a demonstration of a system designed to induce OBEs through immersive technology and virtual body ownership illusions (VBOI). Our approach uses personalized avatars, synchronized visuomotor and visuotactile stimulation, and real-time interaction to create strong VBOI, followed by the induction of OBEs via controlled camera movements. The system is lightweight, user-friendly, and offers better ecological validity, opening new avenues for studying mind-body relationships in controlled environments. Applications include advancing research on self-consciousness, embodiment, and disembodiment, as well as exploring therapeutic interventions for conditions such as PTSD and anxiety. In future research, we wish to explore virtual OBEs in more realistic contexts, such as VR car crash scenarios.",https://youtu.be/f8Wh0VrtS4k,,uaMMBezmRhye8wAUE5F9icw,,Pierre,,Bourdin-Kreitz,,pbourdin@uoc.edu,,Universitat Oberta de Catalunya,Barcelona,,Spain,XR-Lab,Universitat Oberta de Catalunya,Barcelona,Catalunya,Spain,uyh3eneNetfCuu4wVVKvWsw,,Andreu,,Castaño Jiménez,,andreu.c.j99@gmail.com,,Universitat Pompeu Fabra,Barcelona,,Spain,XR-Lab,Universitat Oberta de Catalunya,Barcelona,Catalunya,Spain,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Pierre Bourdin-Kreitz: Universitat Oberta de Catalunya; Andreu Castaño Jiménez: Universitat Pompeu Fabra,andreu.c.j99@gmail.com
PO1044,complete,Endomersion: An Immersive Remote Guidance and Feedback System for Robot-Assisted Minimally Invasive Surgery,Mats Ole Ellenberg,mats_ole.ellenberg@tu-dresden.de,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1044-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=514e4e0b5358acef4aaa0349816f09b9594af28c4a81701c6571b7b30fd49ef9,2,letter,2025-01-27 8:07,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1044-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=3d1f2f9f780a7a4b2f490e53c7a07353d82b8a3ade89941b4760b62dee8689e3,Mats Ole Ellenberg,"The current practice of surgical telementoring involves remote experts providing guidance via telephone or video conferences. Especially in minimally invasive surgery (MIS), this greatly limits their insight into the procedure and inhibits effective deictic referencing. To address this, we present Endomersion, an immersive remote guidance and feedback system that allows verbal and non-verbal communication through audio chat, pointing and telestration, enables remote control of the endoscope camera, and offers an immersive 3D workspace supporting remote expert's understanding of the on-site operation. The system was developed with feedback from surgeons and tested in actual operating room settings. In this demonstration, users take over the role of the remote expert, communicating with the on-site surgeon and remotely controlling the endoscopic camera attached to a robot arm.",https://youtu.be/FIxNry4hf3M,,uKuSDsKzWYA86_eJ5dH55fw,,Mats,Ole,Ellenberg,,mats_ole.ellenberg@tu-dresden.de,Interactive Media Lab Dresden,TUD Dresden University of Technology,Dresden,,Germany,Centre for Tactile Internet with Human-in-the-Loop (CeTI),TUD Dresden University of Technology,Dresden,,Germany,u-uI_5c8rvBaoqDLvFvmGrQ,,Katja,,Krug,,katja.krug@tu-dresden.de,Interactive Media Lab Dresden,TUD Dresden University of Technology,Dresden,,Germany,Centre for Tactile Internet with Human-in-the-Loop (CeTI),TUD Dresden University of Technology,Dresden,,Germany,u9wVm1dE14uiQSHZ2RFvQqQ,,Yichen,,Fan,,yichen.fan@tu-dresden.de,Chair of Industrial Design Engineering,TUD Dresden University of Technology,Dresden,Saxony,Germany,,,,,,urFdubfI8KYO3ZUHpP241dQ,Prof.,Jens,,Krzywinski,,jens.krzywinski@tu-dresden.de,Chair for Industrial Design Engineering,Technische Universität Dresden,Dresden,,Germany,Centre for Tactile Internet with Human-in-the-Loop (CeTI),Technische Universität Dresden,Dresden,,Germany,uJbI2DapunIz2hJutpftOkw,,Raimund,,Dachselt,,dachselt@acm.org,Interactive Media Lab Dresden,TUD Dresden University of Technology,Dresden,,Germany,Centre for Tactile Internet with Human-in-the-Loop (CeTI),TUD Dresden University of Technology,Dresden,,Germany,ua86B2knKO6bFdOpDHs97mA,,Rayan,,Younis,,rayan.younis@ukdd.de,"Department of Visceral, Thoracic and Vascular Surgery","Medical Faculty and University Hospital Carl Gustav Carus, TUD Dresden University of Technology",Dresden ,,Germany,Centre for Tactile Internet with Human-in-the-Loop (CeTI),TUD Dresden University of Technology ,Dresden,,Germany,uhM1WVto9ljQI9zFcVk2ruA,Prof. Dr. med.,Martin,,Wagner,,martin.wagner@ukdd.de,"Department of Visceral, Thoracic and Vascular Surgery, Medical Faculty and University Hospital Carl Gustav Carus",TUD Dresden University of Technology,Dresden,,Germany,,,,,,uKGBIawqqEoGX038I-irQjA,Prof. Dr. med.,Juergen,,Weitz,,juergen.weitz@ukdd.de,"Department of Visceral, Thoracic and Vascular Surgery, Medical Faculty and University Hospital Carl Gustav Carus",TUD Dresden University of Technology,Dresden,,Germany,,,,,,uPj9eXN7ZbY2htpD4diI7ig,,Ariel,,Rodriguez,,ariel.rodriguezjimenez@nct-dresden.de,,NCT Dresden,Dresden,,Germany,,,,,,udd0tBY5G9WOQXuKojMV87w,,Gregor,,Just,,gregor.just@nct-dresden.de,Translational Surgical Oncology,"NCT/UCC, Carl Gustav Carus Faculty of Medicine, TU Dresden",Dresden,,Germany,,,,,,uusX7LdQyC5J4x7Zagjgzbg,,Sebastian,,Bodenstedt,,sebastian.bodenstedt@nct-dresden.de,Translational Surgical Oncology,NCT Dresden,Dresden,,Germany,,,,,,ur4EaRt8AkmLHeC_vcffPxA,,Stefanie,,Speidel,,stefanie.speidel@nct-dresden.de,Translational Surgical Oncology,National Center for Tumor Diseases (NCT),Dresden,,Germany,,,,,,"Mats Ole Ellenberg: TUD Dresden University of Technology; Katja Krug: TUD Dresden University of Technology; Yichen Fan: TUD Dresden University of Technology; Jens Krzywinski: Technische Universität Dresden; Raimund Dachselt: TUD Dresden University of Technology; Rayan Younis: Medical Faculty and University Hospital Carl Gustav Carus, TUD Dresden University of Technology; Martin Wagner: TUD Dresden University of Technology; Juergen Weitz: TUD Dresden University of Technology; Ariel Rodriguez: NCT Dresden; Gregor Just: NCT/UCC, Carl Gustav Carus Faculty of Medicine, TU Dresden; Sebastian Bodenstedt: NCT Dresden; Stefanie Speidel: National Center for Tumor Diseases (NCT)",katja.krug@tu-dresden.de; yichen.fan@tu-dresden.de; jens.krzywinski@tu-dresden.de; dachselt@acm.org; rayan.younis@ukdd.de; martin.wagner@ukdd.de; juergen.weitz@ukdd.de; ariel.rodriguezjimenez@nct-dresden.de; gregor.just@nct-dresden.de; sebastian.bodenstedt@nct-dresden.de; stefanie.speidel@nct-dresden.de
PO1091,complete,P.E.T.R.A: Persuasive Environment for Tracking and Regulating Arousal and Valence in Virtual Reality,Fabio Vito Papapicco,fabiopapapicco2002@gmail.com,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1091-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=75a5348f9fad83cd28be5380daba0a9225809cd7dfa4d8b6409b834d61a2eaff,2,letter,2025-01-29 11:43,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1091-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=ec688859f0286f89590d2e08b30ec2f687b38f23f0b9e0f127ea94696be7ff78,Fabio Vito Papapicco,"The rising prevalence of gambling, particularly in digital formats, demands innovative approaches to understanding and mitigating Gambling Disorder (GD). Virtual Reality (VR), with its immersive and interactive potential, offers a unique platform to explore the complex interplay of psychological and environmental factors contributing to impulsive gambling behaviors. This research introduces P.E.T.R.A. (Persuasive Environment for Tracking and Regulating Arousal), a novel VR-based environment designed asan amusement park simulation. P.E.T.R.A combines elements inspired by electronic gambling machines (EGMs) with gamification mechanics to study and modulate emotional arousal and valence. Using the Circumplex Model of Emotion, P.E.T.R.A. tracks and analyzes affective states in real time, providing insights into impulsive decision-making. Preliminary results validate P.E.T.R.A.’s capability to evoke realistic emotional responses and inform future interventions, particularly for cognitive behavioral therapy (CBT). This work aims at demonstrating the potential of VR technologies for GD research, prevention, and therapeutic applications.",https://youtu.be/Gd1B3QXYGE4,,u3_qAvTZ-aYO9Y2EaFGU0Uw,,Fabio Vito,,Papapicco,,fabiopapapicco2002@gmail.com,,Università degli Studi di Bari Aldo Moro,Bari,,Italy,,,,,,u-T-DquvXDkL0sUG5RdUb-A,,Francesca,,Cuzzo,,fracuzzo2@gmail.com,,Università degli Studi di Bari Aldo Moro,Bari,,Italy,,,,,,uDT5t9LWDl2HVkyNMsMga6g,,Veronica,,Rossano,,veronica.rossano@uniba.it,Dept. of Computer Science,University of Bari,Bari,,Italy,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Fabio Vito Papapicco: Università degli Studi di Bari Aldo Moro; Francesca Cuzzo: Università degli Studi di Bari Aldo Moro; Veronica Rossano: University of Bari,fracuzzo2@gmail.com; veronica.rossano@uniba.it
PO1095,complete,Power wheelchair driving: a multisensory simulator using VR to learn inrehabilitation centers,Fabien Grzeskowiak,fabien.grzeskowiak@inria.fr,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1095-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=96b0767ec3346261d705aefe1c9eb5a26db902d6ff5b4943fc2a62b54542faae,2,letter,2025-01-30 10:38,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1095-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=1c22c4a48574e66d4abe11045dcef4cbb18bf249cd0d943f21ff067149d9456c,Fabien Grzeskowiak,"Power wheelchairs (PWCs) significantly enhance mobility for individuals with disabilities but are often challenging to master, requiring extensive training. Traditional training methods can be risky, resource-intensive, and difficult to implement. Virtual reality (VR) offers a safer, customizable, and effective alternative, as demonstrated in rehabilitation contexts. We developed a multisensory VR simulator incorporating vestibular feedback to enhance the sense of presence and mitigate cybersickness. Our studies show effective skill transfer from the virtual environment to real-world PWC use, validated with actual users in clinical trials. This demonstration highlights the capabilities of our mechanical simulator, featuring navigation scenes from previous trials and ongoing work with virtual agents. The simulator's immersive and adaptive design addresses the challenges of PWC training, offering a practical and innovative solution for clinicians and users alike.",https://youtu.be/H8hpIWWUtFw,,uY4XEcwGwh8t_LoHfEWdIFw,,Fabien,,Grzeskowiak,,fabien.grzeskowiak@inria.fr,,Inria Centre Bretagne Atlantique,Rennes,,France,,,,,,uEaAbQYBwIjuYg1hM5M7pkQ,,Emilie,,Leblong,,emilie.leblong@pole-sthelier.com,,"Pôle Saint Hélier, rehabilitation center",Rennes,,France,,,,,,u8HFlWw4ZgYuoKh2vWGhdUQ,,Sébastien,,THOMAS,,sebastien.thomas@inria.fr,,INRIA,Rennes,,France,,,,,,uQWyEfrCyTvFfLSl1hUsjWw,,Francois,,Pasteau,,francois.pasteau@insa-rennes.fr,,"Univ Rennes, INSA",Rennes,,France,,,,,,u8qMB082Q3yDbxp14dzB0HA,Dr,Louise,,Devigne,,louise.devigne@insa-rennes.fr,"CNRS, Inria",Irisa-UMR6074,Rennes,,France,,,,,,uGt9A4f6BCJsMNgp0j08NeA,,Sylvain,,GUEGAN,,sylvain.guegan@insa-rennes.fr,,"Univ Rennes, INSA Rennes, LGCGM",Rennes,,France,,,,,,uhYrjktLGL6YgmxUTOLaIKg,,Marie,,Babel,,marie.babel@insa-rennes.fr,,"Univ Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Fabien Grzeskowiak: Inria Centre Bretagne Atlantique; Emilie Leblong: Pôle Saint Hélier, rehabilitation center; Sébastien THOMAS: INRIA; Francois Pasteau: Univ Rennes, INSA; Louise Devigne: Irisa-UMR6074; Sylvain GUEGAN: Univ Rennes, INSA Rennes, LGCGM; Marie Babel: Univ Rennes, INSA Rennes, Inria, CNRS, IRISA",emilie.leblong@pole-sthelier.com; sebastien.thomas@inria.fr; francois.pasteau@insa-rennes.fr; louise.devigne@insa-rennes.fr; sylvain.guegan@insa-rennes.fr; marie.babel@insa-rennes.fr
PO1023,complete,Real-Time Decoder and Player for  MPEG V-DMC Dynamic Meshes,Aleksei Martemianov,aleksei.martemianov@nokia.com,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1023-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=b9c4467ef11a9468e644248e825b0eeee233fe0f08fb8f0af8bf7e45108fc896,2,letter,2025-01-29 11:49,,Aleksei Martemianov,"This paper presents a real-time decoder and player for 3D dynamic meshes, compressed using the MPEG V-DMC standard (Video-based Dynamic Mesh Coding). MPEG V-DMC efficiently compresses dynamic 3D meshes, enabling smooth playback of high-resolution meshes with minimal latency. We demonstrate that the V-DMC standard is highly effective for representing dynamic meshes, offering significant data compression while maintaining high visual quality. Our implementation further shows that MPEG V-DMC can be successfully deployed on simple, resource-constrained devices, making it ideal for a wide range of applications, including volumetric media streaming, augmented reality (AR), and virtual reality (VR). By leveraging modern web technologies, we provide a platform-independent solution that broadens the accessibility of high-quality XR content.",https://youtu.be/uF9LEaF3PvM,,uejhpbxy8Myc6BH9Wjt6LrQ,,Aleksei,,Martemianov,,aleksei.martemianov@nokia.com,,Nokia Technologies,Tampere,,Finland,,,,,,uamqfuULKXg1In4DQ1ANfKg,,Emre,,Aksu,,emre.aksu@nokia.com,,Nokia,Tampere,,Finland,,,,,,u-BCNrqvc2UYFf2QspgB2zg,,Lauri,,Ilola,,lauri.ilola@nokia.com,,Nokia Technologies,Tampere,,Finland,,,,,,ubBtas2ibsqlm4pQDvBGGoQ,,Lukasz,,Kondrad,,lukasz.kondrad@nokia.com,,Nokia ,Munich,,Germany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Aleksei Martemianov: Nokia Technologies; Emre Aksu: Nokia; Lauri Ilola: Nokia Technologies; Lukasz Kondrad: Nokia ,emre.aksu@nokia.com; peter.fasogbon89@gmail.com; lukasz.kondrad@nokia.com
PO1052,complete,Beaming AR: A Compact Environment-Based Display System for Battery-Free Augmented Reality,Hiroto Aoki,aoki-hiroto633@g.ecc.u-tokyo.ac.jp,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1052-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=446f18551e4935e7223c52bb7d1cb29646fbda43c908f4770b02f229237546f8,2,letter,2025-01-27 14:27,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1052-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=75d8b4e13466c5653459e57d90c8aad1e226d50d8d02388e9bc717716a6d9e04,Hiroto Aoki,"Beaming AR demonstrates a new approach to augmented reality (AR) that fundamentally rethinks the conventional all-in-one head-mounted display (HMD) paradigm. Instead of integrating power-hungry components into headwear, our system relocates projectors, processors, and power sources to a compact environment-mounted unit, allowing users to wear only lightweight, battery-free glasses. Our demonstration features a 300mm × 300mm bench-top setup that combines steerable laser projection with co-axial infrared marker tracking. The tracking system uses retroreflective markers and follows the same optical path as the display beam, enabling precise alignment between real-world motion and projected AR content. Conference attendees can experience this technology firsthand by wearing passive eyewear and observing AR content in free space. This proof-of-concept implementation shows how environmental hardware offloading could lead to more practical and comfortable AR displays for extended use.",https://youtu.be/ZCFGA2QN0og,,uYzSG4z_7dKrJayjUMvyZmg,,Hiroto,,Aoki,,aoki-hiroto633@g.ecc.u-tokyo.ac.jp,,The University of Tokyo,Tokyo,,Japan,,,,,,usOkR5JgAXE10F_J04vk-QA,,Yuta,,Itoh,,yuta.itoh@iii.u-tokyo.ac.jp,,The University of Tokyo,Tokyo,,Japan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Hiroto Aoki: The University of Tokyo; Yuta Itoh: The University of Tokyo,yuta.itoh@iii.u-tokyo.ac.jp
PO1046,complete,Conversational Virtual Agent and Immersive Visualizations for Robotic Ultrasound,Tianyu Song,tianyu.song@tum.de,,A,4.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1046-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=d2bc65c0fe08a467848e97067373e5182810867aa2020dcd69e5e818fa2db550,2,letter,2025-01-27 16:46,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1046-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=821bb46b5a4f9c80acccda66cb768ee43ef1f57212539f13f844a52fa47ab0d7,Tianyu Song,"Robotic ultrasound systems offer significant potential for improving diagnostic precision but face challenges in patient acceptance due to the lack of human interaction. We present a novel system that integrates a conversational virtual agent, powered by a large language model, with two immersive visualization modalities—augmented reality (AR) and virtual reality (VR). The virtual agent engages patients through natural dialogue, utilizing real-time speech-to-text and text-to-speech systems to provide clear guidance and reassurance throughout the procedure. The AR visualization allows patients to remain aware of the robot while interacting with the virtual assistant, whereas the VR visualization fully immerses patients in a virtual environment where the robot is hidden, offering a more relaxed experience. This demo showcases how combining adaptive communication with immersive environments can bridge the gap between robotic automation and patient-centered care in medical procedures. A video of this demo can be found here: https://www.youtube.com/watch?v=88axBCUFsLM",https://www.youtube.com/watch?v=88axBCUFsLM,,uXuQdxJGc9SgfW5P9xBEq8Q,,Tianyu,,Song,,tianyu.song@tum.de, Chair for Computer Aided Medical Procedures,Technical University of Munich,Munich,,Germany,,,,,,uF73-rXCbx7V3RIfZvNsSUQ,,Felix,,Pabst,,felix.pabst@tum.de,,Technical University of Munich,Munich,,Germany,,,,,,u-jRUbBXmd0CG2nVDd5-RWA,Dr.,Ulrich,,Eck,,ulricheck@gmail.com,Chair for Computer Aided Medical Procedures,Technical University of Munich,Munich,,Germany,,,,,,ugb9oP1xe3ubWZRidc4IwjQ,Prof.,Nassir,,Navab,,nassir.navab@tum.de,"Chair for Computer Aided Medical Procedures and Augmented Reality, Fakultät für Informatik",Technische Universität München,Garching bei München,,Germany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Tianyu Song: Technical University of Munich; Felix Pabst: Technical University of Munich; Ulrich Eck: Technical University of Munich; Nassir Navab: Technische Universität München,felix.pabst@tum.de; ulricheck@gmail.com; nassir.navab@tum.de
PO1058,complete,Immersive AI-Powered Language Learning Experience in Virtual Reality: A Gamified Environment for Japanese Learning,Qingzhu Zhang,rachelscarletzqz@gmail.com,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1058-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=67b2ccefc7f7888955202850099efbd86e359e337a67f27658472b881993dd84,2,letter,2025-01-29 9:28,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1058-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=18cd7884bc78aad694f8b5cbed9e40004a1313738b08287994c79d82724215ec,Qingzhu Zhang,"This work presents an AI-driven language learning system that combines immersive VR technology and gamification to explore alternative approaches in language education. Developed for Japanese language learners, the system creates a simulated Tokyo environment where learners engage with AI-powered virtual characters to complete tasks, such as purchasing items at convenience stores and seeking directions. It provides dynamic vocabulary assistance and adaptive feedback to support practical communication skills through authentic interactions. The system adjusts task complexity and vocabulary difficulty according to user performance, while reinforcing language acquisition through contextualized conversations. The implementation explores how the integration of artificial intelligence with virtual environments may contribute to computer-assisted language learning.",https://youtu.be/2EOdvnkhlUs,,us2qmRv00U6pndHpx_UVl-Q,,Qingzhu,,Zhang,,rachelscarletzqz@gmail.com,,"University of California, Berkeley",Berkeley,California,United States,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Qingzhu Zhang: University of California, Berkeley",rachel-qingzhuzhang@berkeley.edu
PO1113,complete,Demonstration of Visual Presentation Method for Paranormal Phenomena Through Binocular Rivalry Induced by Dichoptic Color Differences,Kai Guo,a1037736871@icloud.com,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1113-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=13d377fa6300a0af7bd4846cce3847c40b1b13f570558071ad6defaec28fcbba,2,letter,2025-01-28 4:40,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1113-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=c261fdbf033119c9e7d94c546b08d6627c09cae2703bcc909fc6618ec1ad3f81,Kai Guo,"Paranormal visual effects, such as spirits and miracles, are frequently depicted in visual games and media design. However, current methods do not express paranormal experiences as aspects of the sixth sense. We propose utilizing binocular rivalry to provide a new visual presentation method by displaying different images in each eye. In this study, we developed a color selection method based on experimentally gathered data to choose a secondary color to display to the other eye when given an initial input color. We then applied this method to create two demonstrations. Our approach aims to deliver a more realistic visual experience of paranormal phenomena, thereby enhancing user satisfaction while simultaneously simplifying the design process for designers who utilize our proposed method.",https://www.youtube.com/watch?v=aNYycILmFlE,,uqPhhyIT8z_JUejv1YFoPCg,,Kai,,Guo,,a1037736871@icloud.com,The University of Tokyo,Graduate School of Frontier Sciences,Kashiwa,Chiba,Japan,,,,,,u9VW3yTLUCD1dhH-E_IBdfw,,Juro,,Hosoi,,jhosoi@s.h.k.u-tokyo.ac.jp,The Graduate School of Frontier Sciences,The University of Tokyo,Chiba,,Japan,,,,,,uZu_jdFXykkGALHdBpBelqQ,,Yuki,,Shimomura,,shimomurayuki@lelab.t.u-tokyo.ac.jp,,The University of Tokyo,Tokyo,,Japan,,,,,,udnlKV10-6jTVMQTXEoIVrg,,Yuki,,Ban,,ban@edu.k.u-tokyo.ac.jp,,The University of Tokyo,Kashiwanoha,Chiba,Japan,,,,,,urXj8nWGIFv3Y8CtfzJAQeg,Professor,Shinichi,,Warisawa,,warisawa@edu.k.u-tokyo.ac.jp,,The University of Tokyo,Kashiwa,,Japan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Kai Guo: Graduate School of Frontier Sciences; Juro Hosoi: The University of Tokyo; Yuki Shimomura: The University of Tokyo; Yuki Ban: The University of Tokyo; Shinichi Warisawa: The University of Tokyo,guo-kai@g.ecc.u-tokyo.ac.jp; jhosoi@s.h.k.u-tokyo.ac.jp; shimomurayuki@lelab.t.u-tokyo.ac.jp; ban@edu.k.u-tokyo.ac.jp; warisawa@edu.k.u-tokyo.ac.jp
PO1122,complete,Virtual Reality Antarctic Weather Station Repair for Informal STEM Learning,Ross Tredinnick,rdtredinnick@wisc.edu,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1122-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=ee0b0a946e473acfe563c446b92c446fe742a11b7a7af5bf9b0a14492effde48,2,letter,2025-01-28 3:09,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1122-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=fbe315845ea8a15e5538c2f1d8d3d29805be4d6873a81ef99b4aade0844bcbb1,Ross Tredinnick,"Developed in collaboration with polar science experts, this virtual reality game immerses users in the life of a scientist maintaining weather stations in Antarctica. Designed for the Meta Quest 3, the game challenges players to complete realistic repair tasks reimagined as engaging tactile puzzles. As players tackle these challenges, a virtual assistant provides guidance, not only assisting with gameplay mechanics but also offering valuable insights into the real-world science behind their actions. This interactive experience aims to captivate players aged ten and above, offering a unique blend of education and entertainment.  A preview of the experience can be found at https://www.youtube.com/watch?v=cQpikAcYwek.",https://www.youtube.com/watch?v=cQpikAcYwek,,uS5rwzxVxvZPan1XFAvnSww,,Kevin,,Ponto,,kbponto@wisc.edu,Wisconsin Institute for Discovery,University of Wisconsin - Madison,Madison,Wisconsin,United States,,,,,,uNIg4evYpuRR060KvkHbFmg,,Ross,,Tredinnick,,rdtredinnick@wisc.edu,Wisconsin Institute for Discovery,University of Wisconsin - Madison,Madison,Wisconsin,United States,,,,,,uxjHCq8VuApVHokS0ZEIDkQ,M.,Sarah,J,Gagnon,,gagnon3@wisc.edu,Field Day Lab,"University of Wisconsin, Madison",Madison,Wisconsin,United States,,,,,,u0pTEgsdfuDJHF6TN7LmJeQ,,David,,Gagnon,,djgagnon@wisc.edu,Field Day Lab,University of Wisconsin,Madison,Wisconsin,United States,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Kevin Ponto: University of Wisconsin - Madison; Ross Tredinnick: University of Wisconsin - Madison; Sarah J Gagnon: University of Wisconsin, Madison; David Gagnon: University of Wisconsin",kbponto@wisc.edu; gagnon3@wisc.edu; djgagnon@wisc.edu
PO1134,complete,Drawn Together: A Collocated Mixed Reality Sketching and Annotation Experience,Andrew Rukangu,amr07618@uga.edu,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1134-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=13bc93a619f2de5352b9836cb0df83591bc635ba75545dc5a119a8557d20e32b,2,letter,2025-01-27 20:18,,Andrew Rukangu,"We present Drawn Together, a 3D immersive mixed-reality sketching and annotation tool designed for collaboration research.  The system supports a variety of 3D content creation ranging from mid-air, free-form line drawing to voxel-based drawings and mannequins that can be flexibly posed.   Groups of users can engage in synchronous, collocated design, education, art, and play aligned against a pass-through video backdrop to afford physical references and annotations.  A number of input options are also presented, including standard motion controllers, a tracked stylus, and ring-augmented hand tracking.",https://youtu.be/gTKL5lChgao,,udVp31KwdAfTiJLJau_JJww,,Andrew,,Rukangu,,amr07618@uga.edu,School of Electrical and Computer Engineering,University of Georgia,Athens,Georgia,United States,,,,,,uoWrjPtkqBCZua_VekRhVQw,,Ethan,C,Bowmar,,ecb78379@uga.edu,College of Engineering,University of Georgia,Athens,Georgia,United States,,,,,,uC2tXD85mpgXSs3zliToD8Q,,Sun Joo (Grace),,Ahn,,sjahn@uga.edu,Grady College of Journalism and Mass Communication,University of Georgia,Athens,Georgia,United States,,,,,,ul3O5sLehJcKCSSCOqkEMgQ,,Beshoy,,Morkos,,bmorkos@uga.edu,College of Engineering,University of Georgia,Athens,Georgia,United States,,,,,,uHhCHlbXtl7LWc9qc-H671w,,Kyle,,Johnsen,,kjohnsen@uga.edu,School of Electrical and Computer Engineering,University of Georgia,Athens,Georgia,United States,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Andrew Rukangu: University of Georgia; Ethan C Bowmar: University of Georgia; Sun Joo (Grace) Ahn: University of Georgia; Beshoy Morkos: University of Georgia; Kyle Johnsen: University of Georgia,ecb78379@uga.edu; sjahn@uga.edu; bmorkos@uga.edu; kjohnsen@uga.edu
PO1064,complete,LLM-powered Text Entry in Virtual Reality,Yan Ma,yanma1@cs.stonybrook.edu,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1064-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=7e7a57d8a5dda5612e709158cd9465ca9a60d7d56206418b2d84d5f2c78ee188,2,letter,2025-01-25 4:23,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1064-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=ce77d4137f711d7d418be7cd9ca69adee31ce9e0aa044e74d4335ce6af5b1d19,Tony Li,"Large language models (LLMs) have demonstrated exceptional performance across various language-related tasks, offering significant potential for enhancing text entry in Virtual Reality (VR). We introduce an LLM-powered text entry system for VR, which integrates multiple input modalities and utilizes a fine-tuned LLM as a keyboard decoder. The LLM-based decoder achieved 93.1% top-1 decoding accuracy on a word gesture typing dataset and 95.4% on tap typing, highlighting its potential for VR text entry applications. Our demonstration shows how LLMs can support tap typing and word-gesture typing through raycasting and joystick-based inputs, potentially accommodating various user preferences and enhancing the adaptability of VR text input methods.",https://www.youtube.com/watch?v=YMORsSqYLtU,,uQLuZHdrvdM9y0gGSk-pZyQ,,Yan,,Ma,,yanma1@cs.stonybrook.edu,Computer Science Department,Stony Brook University,Stony Brook,New York,United States,,,,,,uO7xengAO5ekrnGjLvMrBDg,,Tony,,Li,,haolili@cs.stonybrook.edu,Department of Computer Science,Stony Brook University,Stony Brook,New York,United States,,,,,,uzuhOkA1AlSRPreaZ7fK1eQ,,Zhi,,Li,,zhili3@cs.stonybrook.edu,Department of Computer Science,Stony Brook University,Stony Brook,New York,United States,,,,,,uAZWfQJ4jhasJTzfH7Mo74g,,Xiaojun,,Bi,,xiaojun@cs.stonybrook.edu,Department of Computer Science,Stony Brook University,Stony Brook,New York,United States,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yan Ma: Stony Brook University; Tony Li: Stony Brook University; Zhi Li: Stony Brook University; Xiaojun Bi: Stony Brook University,haolili@cs.stonybrook.edu; zhili3@cs.stonybrook.edu; xiaojun@cs.stonybrook.edu
PO1074,complete,From 2D to 3D: Redesigning the Desktop Metaphor in Virtual Reality,Mingzhu Cui,chlaudwn93@yonsei.ac.kr,,A,4.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1074-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=38a1a409071937d0639bb10cab0c794fce3508746b1b4c8a23d5a95d794a2784,2,letter,2025-01-27 7:12,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1074-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=7f6e0abc5cdc43782c32e8456c286cc45a60735941ffeeeefe2d6c52b39acef4,Mingzhu Cui,"Since the 1980s, scholars have proposed Natural User Interfaces (NUI) as the future of interaction, with VR HMD technology making 3D environments and hand gestures feasible. However, much of today’s VR research focuses on algorithms or conceptual ideas, and industry solutions often extend traditional 2D WIMP GUIs. In response, this study presents a new VR desktop paradigm incorporating object, metaphor, physics, embodiment, spatial context, and magic. A prototype featuring a music player and calculator demonstrated high usability and immersion.Moreover, workspace customization emerges as a valuable feature for personalization, yielding positive outcomes in terms of spatial memory and task re-immersion. This underscores the potential of VR interfaces to offer not only novel interaction techniques but also enhanced cognitive and experiential benefits for users, suggesting avenues for future research on broader applications.",https://youtu.be/lPk4ShbOXrI,,urwZDO3WElmhP2CBQPA25Xw,,Mingzhu,,Cui,,chlaudwn93@yonsei.ac.kr,,Yonsei University,Seoul,,"Korea, Republic of"," Department of Human Environment & Design,  Department of Human Life & Innovation Design",Yonsei University,Seoul,,"Korea, Republic of",uHlbqF-lCVngSAokykRjI4Q,,Sangwon,,Lee,,sangwon.lee@yonsei.ac.kr,,Yonsei University,Seoul,,"Korea, Republic of",,,,,,uIuliOmEXm8sPFrgFri57uA,,Junyoung,,Kim,,jykim0418@yonsei.ac.kr,,Yonsei University,Seoul,,"Korea, Republic of",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Mingzhu Cui: Yonsei University; Sangwon Lee: Yonsei University; Junyoung Kim: Yonsei University,sangwon.lee@yonsei.ac.kr; jykim0418@yonsei.ac.kr
PO1116,complete,Room Connection Techniques in Virtual Reality for Walking in Impossible Spaces,Ana Rita Rebelo,ar.rebelo@campus.fct.unl.pt,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1116-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=3e36bb72f5eaf9edf3938a5a3a2c98d9723060368ca00fdc9c59969f4706f541,2,letter,2025-01-28 11:05,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1116-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=c47bd9ca78ffeb385b4fb6abbc018128d6a00c938dd7938643b71baed1e8e36d,Ana Rita Rebelo,"This work demonstrates three room-connection techniques – portals, corridors, and central hubs – that can be used in virtual environments to create ""impossible spaces"". These spaces use overlapping areas to maximize available physical space, enabling walking even in constrained spaces. In this experiment, a user can navigate through a five-room apartment of about 106.25 m² by walking within a physical play area of about 6.25 m² (2.5 x 2.5 meters).  The primary contribution of this work is demonstrating how these room-connection techniques can be applied to dynamically adapt virtual environments to fit small physical spaces, such as those commonly available to VR users at home. A video showcasing this demo can be found at the following link: https://youtu.be/a_4kcC0VOuY.",https://youtu.be/a_4kcC0VOuY,,uZlojOwr0EcHdrGANxPknJA,,Ana,Rita,Rebelo,,ar.rebelo@campus.fct.unl.pt,,"NOVA LINCS, NOVA School of Science and Technology",Lisbon,,Portugal,,,,,,uZw9TyrUgk5qlrG0VNfP3-A,,Pedro A.,,Ferreira,,pan.ferreira@campus.fct.unl.pt,NOVA LINCS,NOVA School of Science and Technology,Lisbon,,Portugal,,,,,,ul00qgNqyxDhr8ocdP_-Ndw,,Rui,,Nóbrega,,rui.nobrega@fct.unl.pt,"NOVA-LINCS, DI","Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa",Caparica,,Portugal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Ana Rita Rebelo: NOVA LINCS, NOVA School of Science and Technology; Pedro A. Ferreira: NOVA School of Science and Technology; Rui Nóbrega: Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa",pan.ferreira@campus.fct.unl.pt; rui.nobrega@fct.unl.pt
PO1114,complete,Interoperable and Open Source Solution for Anchoring Augmented Reality Content to the Real World,Jérémy Lacoche,jeremy.lacoche@orange.com,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1114-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=b4999e8c6cfaeea9998cd6cb48b6bea12c2cd22f0b180cf9d83b4a28b3e6d483,2,letter,2025-01-27 16:42,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1114-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=a6e593d071b515bfe418e7da28d2bffcc9899134c109723272c5988ee96dd6d2,Jérémy Lacoche,"This research demonstration presents an open source end-to-end solution for facilitating the anchoring of virtual content in the real world based on various platforms thanks to the interoperable specifications of the ETSI Augmented Reality Framework (ARF) Industry Specification Group (ISG). The solution relies on authoring tools developed for Unity and the created AR applications can be deployed on platforms such as iOS, Android and VisionOS. A validation scenario for data center maintenance is detailed to illustrate the solution. Various examples based on the glTF format are also provided to show the potential of this novel architecture.",https://www.youtube.com/watch?v=wxqSAIa4mVg,,unLHJFxvoOuFyH2Xsg6uXsA,,Sylvain,,Buche,,buche.sylvain@gmail.com,,Orange Labs,Rennes,,France,,,,,,utOrK1vtL9rVhDidbGvOsSQ,,Ingo,,Feldmann,,ingo.feldmann@hhi.fraunhofer.de,Vision & Imaging Technologies,Fraunhofer HHI,Berlin,,Germany,,,,,,utuLKbPEYPMgVHlt8kmzoIQ,Prof. Dr.,Patrick,,Harms,,patrick.harms@th-nuernberg.de,efi,Nuremberg Institute of Technology,Nuremberg,,Germany,,,,,,uLmt3c_O9B4xkMB7NXQ0ZDQ,,Hugo,,Kréber,,hugo.kreber@b-com.com,,IRT b<>com,Cesson Sévigné,,France,,,,,,uJfw4nOf3l749TBrKj0wxjQ,,Jérémy,,Lacoche,,jeremy.lacoche@orange.com,,Orange Labs,Rennes,,France,,,,,,uD3S4Cjw892U1Y5-dVlww0g,,Stéphane Louis Dit,,Picard,,stephane.louisditpicard@orange.com,,Orange,Rennes,,France,,,,,,u0gYze9DobGSXNPFP605XzQ,,Sylvain,,Renault,,sylvain.renault@hhi.fraunhofer.de,,Fraunhofer Heinrich-Hertz-Institut,Berlin,,Germany,,,,,,uSp4Fv0Ys--6QrYBOt_jXwg,,Jérôme,,Royan,,jerome.royan@b-com.com,,IRT b<>com,Rennes,,France,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Sylvain Buche: Orange Labs; Ingo Feldmann: Fraunhofer HHI; Patrick Harms: Nuremberg Institute of Technology; Hugo Kréber: IRT b<>com; Jérémy Lacoche: Orange Labs; Stéphane Louis Dit Picard: Orange; Sylvain Renault: Fraunhofer Heinrich-Hertz-Institut; Jérôme Royan: IRT b<>com,buche.sylvain@gmail.com; ingo.feldmann@hhi.fraunhofer.de; patrick.harms@th-nuernberg.de; hugo.kreber@b-com.com; stephane.louisditpicard@orange.com; sylvain.renault@hhi.fraunhofer.de; jerome.royan@b-com.com
PO1137,complete,Focus360: Guiding User Attention in Immersive Videos for VR,Paulo Vitor Santana da Silva,paulovitor_pe@hotmail.com,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1137-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=c2c86c2959742d5ae0572303fe656a28ae0a5623966a5fa6a23abc38a8c6d0ad,2,letter,2025-01-27 22:03,,Paulo Vitor Santana da Silva,"This demo introduces Focus360, a system designed to enhance user engagement in 360º VR videos by guiding attention to key elements within the scene. Using natural language descriptions, the system identifies important elements and applies a combination of visual effects to guide attention seamlessly. At the demonstration venue, participants can experience a 360º Safari Tour, showcasing the system's ability to improve user focus while maintaining an immersive experience.",https://youtu.be/PSNaqcoIgDY,,ukVTlhlFTODLtdsH8lgbfzA,,Paulo Vitor,,Santana da Silva,,paulovitor_pe@hotmail.com,,Advanced Knowledge Center in Immersive Technologies (AKCIT),Goiânia,Goiás,Brazil,,,,,,uWGtZE_TKgW_Vn-aUqDBY3w,,Lucas Lima,,Neves,,lucas.neves@discente.ufg.br,,Advanced Knowledge Center in Immersive Technologies (AKCIT),Goiânia,Goiás,Brazil,,,,,,ufXJ7uCNKl1NSPc1BgzGGNw,,Rafael Alves,,Goiás,,rafael_goias@discente.ufg.br,,Advanced Knowledge Center in Immersive Technologies (AKCIT),Goiânia,Goiás,Brazil,,,,,,ukdSB1FXjwVc0OIL7WeHpOA,,Diogo,,Fernandes,,diiogofernands@gmail.com,,Advanced Knowledge Center in Immersive Technologies (AKCIT),Goiânia,Goiás,Brazil,,,,,,u49Ukvu1BblSXSBCnoUiigA,Dr.,Rafael,Teixeira,Sousa,,rafaelsousa@ufmt.br,,Advanced Knowledge Center in Immersive Technologies (AKCIT),Goiânia,Goiás,Brazil,,,,,,uHgKg503BXHgmjEr4uXNl_A,,ARLINDO,,GALVÃO,,arlindogalvao@ufg.br,,Advanced Knowledge Center in Immersive Technologies (AKCIT),Goiânia,Goiás,Brazil,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Paulo Vitor Santana da Silva: Advanced Knowledge Center in Immersive Technologies (AKCIT); Lucas Lima Neves: Advanced Knowledge Center in Immersive Technologies (AKCIT); Rafael Alves Goiás: Advanced Knowledge Center in Immersive Technologies (AKCIT); Diogo Fernandes: Advanced Knowledge Center in Immersive Technologies (AKCIT); Rafael Teixeira Sousa: Advanced Knowledge Center in Immersive Technologies (AKCIT); ARLINDO GALVÃO: Advanced Knowledge Center in Immersive Technologies (AKCIT),lucas.neves@discente.ufg.br; rafael_goias@discente.ufg.br; diiogofernands@gmail.com; rafaelsousa@ufmt.br; arlindogalvao@ufg.br
PO1093,complete,Multi-resolution audiovisual representation of sound fields recorded with a 7th-order ambisonic microphone array.,Francois Salmon,francois.salmon@noisemakers.fr,,A,5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1093-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=7e7bc1f982b92f93ba6baa36266ac20da1409665305f3840033b5b952885c1b5,2,letter,2025-01-28 9:43,,François Salmon,"As part of the development of an ambisonic microphone array, it is of interest to determine the spatial accuracy required to capture and reproduce a sound field over headphones. A 7th order ambisonic microphone array consisting of 480 MEMs has been developed to capture sound fields with high resolution. This research demonstration allows us to experience the drawbacks of reducing the spatial accuracy of an ambisonic representation obtained with such a prototype. It allows to listen to the captured sound field at different resolutions and to visualise the resulting accuracy in terms of energy over the sphere. The visual information is overlaid on 360 videos to help identify the sound sources around the listener. Such development can find applications in the context of remote monitoring and will enable the study of interactions between auditory and visual cues in the context of Virtual Reality experiences.",https://www.youtube.com/watch?v=lcConBLXJDc,,u_qSr3nuOf5fYXn-FWtAdxA,,Francois,,Salmon,,francois.salmon@noisemakers.fr,,Noise Makers,Rennes,,France,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Francois Salmon: Noise Makers,
PO1012,complete,Vision Language Model-Based Solution for Obstruction Attack in AR: A Meta Quest 3 Implementation,Yanming Xiu,yanming.xiu@duke.edu,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1012-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=348659ca6b3f0e3ae4f98d1ea9119cde12796199e6837b70b54e2df259073d45,2,letter,2025-01-28 17:02,,Yanming Xiu,"Obstruction attacks in Augmented Reality (AR) pose significant challenges by obscuring critical real-world objects. This work demonstrates the first implementation of obstruction detection on a video see-through head-mounted display (HMD), the Meta Quest 3. Leveraging a vision language models (VLM) and a multi-modal object detection model, our system detects obstructions by analyzing both raw and augmented images. Due to limited access to raw camera feeds, the system employs an image-capturing approach using Oculus casting, capturing a sequence of images and finding the raw image from them. Our implementation showcases the feasibility of effective obstruction detection in AR environments and highlights future opportunities for improving real-time detection through enhanced camera access.",https://youtu.be/ll1N261nVVA?si=RTftB5cHC6--xtvf,,uZ0apIE5oFaB-AO9yLMdvtg,,Yanming,,Xiu,,yanming.xiu@duke.edu,Department of Electrical and Computer Engineering,Duke University,Durham,North Carolina,United States,,,,,,u9adB1yG_0DQqUvt8UxcNPA,,Maria,,Gorlatova,,maria.gorlatova@duke.edu,Electrical and Computer Engineering,Duke University,DURHAM,North Carolina,United States,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yanming Xiu: Duke University; Maria Gorlatova: Duke University,maria.gorlatova@duke.edu
PO1096,complete,Using Virtual Reality to Raise Awareness of Communication Challenges Faced by Individuals with Hearing Loss,Joanna Luberadzka,joanna.luberadzka@eurecat.org,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1096-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=363946c72681fc4954b3b18a41d7134f68e9cd18f24746b3901af01c5b7c13e5,2,letter,2025-01-28 18:14,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1096-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=8778be3a1c02ee553537e00c3bbd15f8fe3dc8d6f18f3df602fbbab5d9b95652,Joanna Luberadzka,"Hearing loss is typically managed with hearing aids, which amplify sound based on the user's hearing profile. However, unlike glasses for vision, hearing aids cannot address the reduced time-frequency resolution of the auditory system. To raise awareness of the challenges faced by hearing aid users, particularly in complex acoustic environments, we use virtual reality (VR). We integrate hearing loss and hearing aid simulators into a VR application, allowing users to experience the altered soundscape in an immersive way.",https://www.youtube.com/watch?v=NTBqjj3_SLY,,uFGSd0jc8yU7hXueOLja7dA,,Joanna,,Luberadzka,,joanna.luberadzka@eurecat.org,Multimedia Technology,Eurecat,Barcelona,,Spain,,,,,,uvs6g95Ir62jRGRFegW__vg,,Enric,,Guso,,enric.guso@eurecat.org,Multimedia Technology,Eurecat,Barcelona,Barcelona,Spain,,University Pompeu Fabra,Barcelona,Barcelona,Spain,un2lPviJGUZ4elYEL9ROr4g,,Umut,,Sayin,,umut.sayin@eurecat.org,Multimedia Technology,Eurecat,Barcelona,Barcelona,Spain,,,,,,uzsbasVhlKbLo3K4i_kFWYQ,,Adan,,Garriga,,adan.garriga@eurecat.org,Multimedia Technology,Eurecat,Barcelona,Barcelona,Spain,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Joanna Luberadzka: Eurecat; Enric Guso: Eurecat; Umut Sayin: Eurecat; Adan Garriga: Eurecat,enric.guso@eurecat.org; umut.sayin@eurecat.org; adan.garriga@eurecat.org
PO1139,complete,Designing Fractal Expressions for Immersive Aesthetic Experiences,Christian Geiger,geiger@hs-duesseldorf.de,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1139-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=30a893ef9870f3d58b99913b3aa08fee033eb994a94834e8511de39c33e18353,2,letter,2025-01-28 21:01,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1139-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=904dbcaa3f8654a47d38675525a3c4e49f23f5d148baf5e21e70ec04688ce384,Christian Geiger / Emil Gerhardt,"Aesthetic experiences are closely related to human emotions and experiences as well as the perception of aesthetic objects and phenomena. We consider interaction with generated immersive worlds to be an immersive aesthetic experience if it is designed independently of any functional use and can be experienced in an aesthetically pleasing way. The possibilities of generative techniques such as AI and other algorithms and visualization through the integration of virtual reality open up new aesthetic possibilities. We present the results of a collaboration between scientists and designers/artists in the development of a framework for three-dimensional fractals [5] and its application in various scenarios in the field of festivals, performances and exhibitions.",https://vimeo.com/1046353499,,uEtkCFakxEierJ2kUM6luqA,,Christian,,Geiger,,geiger@hs-duesseldorf.de,MIREVI Lab,University of Applied Sciences Duesseldorf,Düsseldorf,Bitte Auswählen,Germany,,,,,,uFeBwgOI8gVO7eowSQhonSA,,Emil,,Gerhardt,,emil.gerhardt@hs-duesseldorf.de,MIREVI Lab,University of Applied Sciences Duesseldorf,Düsseldorf,,Germany,,,,,,ujKRDznUDkSYbctTtxNE8cg,,Mitja,,Säger,,mitja.saeger@hs-duesseldorf.de,MIREVI Lab,University of Applied Sciences Duesseldorf,Düsseldorf,Bitte Auswählen,Germany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Christian Geiger: University of Applied Sciences Duesseldorf; Emil Gerhardt: University of Applied Sciences Duesseldorf; Mitja Säger: University of Applied Sciences Duesseldorf,emil.gerhardt@hs-duesseldorf.de; mitja.saeger@hs-duesseldorf.de
PO1135,complete,XiloVR: Simulation for Teaching and Technique Preservation,Alyson Souza,alysonmatheus@gmail.com,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1135-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=465fe81d056253e8b152dcea967be640fab4493dca6614b3b99e85d92798da58,2,letter,2025-01-29 2:48,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1135-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=3a2171bfd35751e60b5d9de19850019d8e7b97e5fc9b690f8017f56982d8549f,Alyson Souza,"This demonstration introduces a novel approach to exploring the art of woodcut printing through an interactive Virtual Reality (VR) environment, leveraging the educational potential of immersive technologies to promote art and culture. In this context, we developed a physical prototype designed to replace the primary functionalities of hand-based user interaction typically performed with VR controllers. Instead, the system utilizes representations of woodcut production tools, tracked by a sensor, to enable interaction within the immersive environment. The system aims to provide a practical, educational, and immersive experience in artistic creation, innovating teaching methodologies and ensuring the preservation of woodcut printing knowledge for future generations. By combining physical and digital elements, this solution bridges technological accessibility with cultural heritage promotion, offering an engaging and transformative learning platform.",https://youtu.be/p5fJbtrTVnU,,uvCsSRPAzyKl6_2HxlgQCkA,,Samuel,,Costa,,samuel.costa.705@ufrn.edu.br,Digital Metropolis Institute,Federal University of Rio Grande do Norte,Natal,RN,Brazil,,,,,,udb9DIxw3nztghhbsA6XRxQ,,Bianca,,Miranda,,miranda.bianca41@gmail.com,Digital Metropolis Institute,Federal University of Rio Grande do Norte,Natal,RN,Brazil,,,,,,uDGI480yxaOMshRftKec7QA,,Stefane,,de Assis Orichuela,,stefaneassisori@gmail.com,Digital Metropolis Institute,Federal University of Rio Grande do Norte,Natal,,Brazil,,,,,,upAWo6OBdyGmPYBYRBCI9cw,,Alyson,,Souza,,alysonmatheus@gmail.com,Digital Metropolis Institute,Federal University of Rio Grande do Norte,Natal,RN,Brazil,AKCIT/IMD,Federal University of Rio Grande do Norte,Natal,,Brazil,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Samuel Costa: Federal University of Rio Grande do Norte; Bianca Miranda: Federal University of Rio Grande do Norte; Stefane de Assis Orichuela: Federal University of Rio Grande do Norte; Alyson Souza: Federal University of Rio Grande do Norte,samuel.costa.705@ufrn.edu.br; miranda.bianca41@gmail.com; stefaneassisori@gmail.com
PO1090,complete,My Co-worker ChatGPT: Development of an XR Application for Embodied Artificial Intelligence in Work Environments,Philipp Krop,philipp.krop@uni-wuerzburg.de,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1090-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=b1b593e329a8f0cc422520fee2810aba3fcc8d85c4ac76d2b4217efea51f41c1,2,letter,2025-01-27 10:03,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1090-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=aae20746722460ae7901a29f7381d88358b73df2482606652fab5ad5f34f7747,Philipp Krop,"With recent developments in spatial computing, work contexts might shift to augmented reality. Embodied AI - virtual conversational agents backed by AI systems - have the potential to enhance these contexts and open up more communication channels than just text. To support knowledge transfer from virtual agent research to the general populace, we developed My CoWorker ChatGPT - an interactive demo where employees can try out various embodied AIs in a virtual office or their own using augmented reality. We use state-of-the-art speech synthesis and body-scanning technology to create believable and trustworthy AI assistants. The demo was shown at multiple events throughout Germany, where it was well received and sparked fruitful conversations about the possibilities of embodied AI in work contexts.",https://youtu.be/BKt5kxQQuk4,,uWHpoeN5DZ38gW6lQBMKsUQ,,Philipp,,Krop,,philipp.krop@uni-wuerzburg.de,Human-Computer Interaction Group,University of Würzburg,Würzburg,,Germany,,,,,,uSz2t_W43c92lD-jaapKohg,,David,,Obremski,,david.obremski@uni-wuerzburg.de,Psychology of Intelligent Interactive Systems,University of Würzburg,Würzburg,,Germany,,,,,,uP2zz8XS2JcQ-X4Cj54li8Q,Dr.,Astrid,,Carolus,,astrid.carolus@uni-wuerzburg.de,Media Psychology,University of Würzburg,Würzburg,,Germany,,,,,,u4oBuwJeSvYLJK98A4nE8fg,,Marc,Erich,Latoschik,,marc.latoschik@uni-wuerzburg.de,Human-Computer Interaction Group,University of Würzburg,Würzburg,,Germany,,,,,,ulFZoqTpdEz9MZ8cgvEfRyQ,Prof. Dr.,Carolin,,Wienrich,,carolin.wienrich@uni-wuerzburg.de,Psychology of Intelligent Interactive Systems,University of Würzburg,Würzburg,,Germany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Philipp Krop: University of Würzburg; David Obremski: University of Würzburg; Astrid Carolus: University of Würzburg; Marc Erich Latoschik: University of Würzburg; Carolin Wienrich: University of Würzburg,david.obremski@uni-wuerzburg.de; astrid.carolus@uni-wuerzburg.de; marc.latoschik@uni-wuerzburg.de; carolin.wienrich@uni-wuerzburg.de
PO1053,complete,"I hear, see, speak & do: Bringing Multimodal Information Processing to Intelligent Virtual Agents for Natural Human-AI Communication",Ke Li,ke.li@uni-hamburg.de,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1053-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=b3be90f90085c79f02508ac7ea49d9056a9800549d08b19f5b43d15fe76b3422,2,letter,2025-01-23 13:15,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1053-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=636af44950b1bc8d19de7d360e71d66a6d1c624b62687ccc83b595da17245e28,Ke Li,"We present an XR framework with a streamlined workflow for creating and interacting with intelligent virtual agents (IVAs) with multimodal information processing capabilities using commercially available AI tools and cloud services such as large language and vision models. The system supports: (i) the integration of high-quality, customizable virtual 3D human models for visual representations of IVAs and (ii) multimodal communication with generative AI-driven IVAs in immersive XR.",https://youtu.be/BTKCyC0GgXg,,uDxYcrlPoZ-OSZ8SY34sZcA,,Ke,,Li,,ke.li@uni-hamburg.de,Human Computer Interaction,University of Hamburg,Hamburg,,Germany,,,,,,u6aMD1xoVoVa85Yi0arz5tQ,,Fariba,,Mostajeran,,fariba.mostajeran.gourtani@uni-hamburg.de,Human-Computer Interaction,University of Hamburg,Hamburg,,Germany,,,,,,uPgaTwBVE3hfAwAmGZqIs9g,,Sebastian,,Rings,,sebastian.rings@uni-hamburg.de,,Universität Hamburg,Hamburg,,Germany,,,,,,uFwLoSUf2YGHZ7RIXOY_QtQ,,Lucie,,Kruse,,lucie.kruse@uni-hamburg.de,Human-Computer Interaction,Universität Hamburg,Hamburg,,Germany,,,,,,uhmHE0jVZlN3zRj7Se2aibw,,Susanne,,Schmidt,,susanne.schmidt@canterbury.ac.nz,HIT Lab NZ,University of Canterbury,Christchurch,,New Zealand,,,,,,uHFqk3YCOGp9b3WSy6QlIVQ,,Michael,,Arz,,michael.arz@uni-hamburg.de,Human-Computer Interaction,University of Hamburg,Hamburg,,Germany,,,,,,ueMfcyN8VLT_Gt48XDY_YEQ,,Erik,,Wolf,,erik.wolf.29@gmail.com,Human-Computer Interaction,University of Hamburg,Hamburg,,Germany,,,,,,uXDOKlYfEv06c6v_WE20g7Q,Prof. Dr.,Frank,,Steinicke,,frank.steinicke@uni-hamburg.de,Human-Computer Interaction,Universität Hamburg,Hamburg,,Germany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Ke Li: University of Hamburg; Fariba Mostajeran: University of Hamburg; Sebastian Rings: Universität Hamburg; Lucie Kruse: Universität Hamburg; Susanne Schmidt: University of Canterbury; Michael Arz: University of Hamburg; Erik Wolf: University of Hamburg; Frank Steinicke: Universität Hamburg,fariba.mostajeran.gourtani@uni-hamburg.de; sebastian.rings@uni-hamburg.de; lucie.kruse@uni-hamburg.de; susanne.schmidt@canterbury.ac.nz; michael.arz@uni-hamburg.de; erik.wolf.29@gmail.com; frank.steinicke@uni-hamburg.de
PO1094,complete,Fashion Beneath the Skin - a Fashion Exhibition Experience in Social Virtual Reality,Karolina Wylężek,karolina@cwi.nl,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1094-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=981542d82882bb312b1a93b01465ca4fbe738049901754aa16b97d0be43f9efe,2,letter,2025-01-23 14:53,,Karolina Wylężek,"Social VR allows users to interact with each other and explore virtual spaces together. This demo presents a social VR fashion museum, where visitors engage with fashion artefacts. The experience spans across three different spaces designed for various goals. This application, created following a human-centred approach, explores how the visitors interact with each other and the exhibits, considering their 3D volumetric representation and changing environmental context throughout the experience.",https://www.youtube.com/watch?v=nEcP7pUq2xw,,uxHY8oeaBHWy_iUYXa0G6ig,,Karolina,,Wylężek,,karolina@cwi.nl,,CWI,Amsterdam,,Netherlands,,,,,,uKnDL-E9LKF6BudOlooaRgg,,Irene,,Viola,,irene@cwi.nl,,Centrum Wiskunde en Informatica (CWI),Amsterdam,,Netherlands,,,,,,uua0ejuZqiZgnG-VDypQ2IA,,Pablo,,Cesar,,p.s.cesar@cwi.nl,,Centrum Wiskunde & Informatica (CWI),Amsterdam,,Netherlands,,Delft University of Technology (TU Delft),Delft,,Netherlands,uVlb547vlnGy4vOFft9JZ1w,,Jack,,Jansen,,jack.jansen@cwi.nl,,Centrum Wiskunde & Informatica,Amsterdam,,Netherlands,,,,,,uYYwPXfnYTRnX14eSmBJuvw,,Suzanne,,Mulder,,smulder@centraalmuseum.nl,,Centraal Museum Utrecht,Utrecht,,Netherlands,,,,,,uw5wE0P6WVaSUyVZjRnOn6A,,Dylan,,Eno,,info@dylaneno.com,,Dylan Eno,Almere,,Netherlands,,,,,,ufKjyl0pgkZP3QuoFraODsw,,Wytze,,Koppelman,,wkoppelman@beeldengeluid.nl,,Netherlands Institute for Sound and Vision,Hilversum,,Netherlands,,,,,,uXDjmnMp3DRByDfAN8pYULA,,Marta,,Franceschini,,m.franceschini@fashionheritage.eu,,European Fashion Heritage Association,Florence,,Italy,,,,,,uE8Z_HyAilDeIztPED9Pymg,,Marco,,Rendina,,m.rendina@fashionheritage.eu,,European Fashion Heritage Association,Florence,,Netherlands,,,,,,uwCSz0H-jb8L2agVgItzLbA,,Ninke,,Bloemberg,,nbloemberg@centraalmuseum.nl,,Centraal Museum Utrecht,Utrecht,,Netherlands,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Karolina Wylężek: CWI; Irene Viola: Centrum Wiskunde en Informatica (CWI); Pablo Cesar: Centrum Wiskunde & Informatica (CWI); Jack Jansen: Centrum Wiskunde & Informatica; Suzanne Mulder: Centraal Museum Utrecht; Dylan Eno: Dylan Eno; Wytze Koppelman: Netherlands Institute for Sound and Vision; Marta Franceschini: European Fashion Heritage Association; Marco Rendina: European Fashion Heritage Association; Ninke Bloemberg: Centraal Museum Utrecht,irene@cwi.nl; p.s.cesar@cwi.nl; jack.jansen@cwi.nl; smulder@centraalmuseum.nl; info@dylaneno.com; wkoppelman@beeldengeluid.nl; m.franceschini@fashionheritage.eu; m.rendina@fashionheritage.eu; nbloemberg@centraalmuseum.nl
PO1069,complete,Demonstrating WAVY: a hand wearable with force and vibrotactile feedback for multimodal interaction in Virtual Reality,Marion Pontreau,marion.pontreau@cea.fr,,A,4.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1069-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=a180835067cd5d43fc7a80de7d85ece6042eb69565a93e1fd9c8316286d58bf5,2,letter,2025-01-27 15:25,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1069-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=34e6ff48b93cbf2c9cfbd3fdc06bfeeffbd0420c19197e5b3878f694214953a9,Marion Pontreau,"While the public has access to audio and visual stimuli in virtual reality (VR) thanks to affordable and light headsets, the haptic sense (i.e. the sense of touch) is often lacking or restricted to controllers’ vibrations. Besides, commercial haptic wearables remain too expensive for the mass market. Thus, we designed an affordable and light hand wearable that combines tracking, multi-point vibrations and force feedback for the palm and the fingers. The wearable is demonstrated in a VR scenario.",https://www.youtube.com/watch?v=mhNQnxDkD5Q,,uf7UwaKxUhSbVxuiyk2562A,,Marion,,Pontreau,,marion.pontreau@cea.fr,,"Université Paris-Saclay, CEA, List",Palaiseau,,France,Sorbonne Université,Institut des Systèmes Intelligents et de Robotique,Paris,,France,uPrnqwUmunND13DfE6z7ggA,,Céphise,,Louison,,cephise.louison@cea.fr,"Universite Paris-Saclay,","CEA, List",Palaiseau,,France,,,,,,uQq5A-rPbvhmU2Jw4DwfDiw,,Pierre-Henri,,Oréfice,,pierre-henri.orefice@cea.fr,Universite Paris-Saclay,"CEA, List",Palaiseau,,France,,,,,,ug-laFI-7_rxv99IURlIcPA,PhD,Sylvain,,Bouchigny,,sylvain.bouchigny@cea.fr,"Université Paris-Saclay, CEA, List","CEA, List",Palaiseau,,France,,,,,,u8P0EWNJIltxjCxs4D-N7qg,,Thanh-loan Sarah,,LE,,le@isir.upmc.fr,"Sorbonne Université, CNRS",Institut des Systèmes Intelligents et de Robotique,Paris,,France,,,,,,ue3AFATfR-Dul4OX1S69JQg,,David,,Gueorguiev,,david.gueorguiev@uclouvain.be,Université catholique de Louvain,Institute of Neuroscience,Brussels,,Belgium,,,,,,uPnEg0OUcxOGezoGtnQbidw,,Sabrina,,Panëels,,sabrina.paneels@cea.fr,Université Paris-Saclay,"CEA, List",Palaiseau,,France,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Marion Pontreau: Université Paris-Saclay, CEA, List; Céphise Louison: CEA, List; Pierre-Henri Oréfice: CEA, List; Sylvain Bouchigny: CEA, List; Thanh-loan Sarah LE: Institut des Systèmes Intelligents et de Robotique; David Gueorguiev: Institute of Neuroscience; Sabrina Panëels: CEA, List",cephise.louison@cea.fr; pierre-henri.orefice@cea.fr; sylvain.bouchigny@cea.fr; le@isir.upmc.fr; david.gueorguiev@uclouvain.be; sabrina.paneels@cea.fr
PO1056,complete,LLM-powered Gaussian Splatting in VR interactions,Haotian Mao,404748294@qq.com,,A,4.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1056-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=97fa09a1d5f587897a8a826ac7facd2ae6ca4ea3a148b16f6779c45b5e3ab6ad,2,letter,2025-01-27 12:22,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1056-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=b492dd051fad80956689169807c76edd554dc61549c70b4a777025855db0b164,Haotian Mao,"Recent advances in radiance field rendering, particularly 3D Gaussian Splatting (3DGS), have demonstrated significant potential for VR content creation, offering both high-quality rendering and an efficient production pipeline. However, current physics-based interaction systems for 3DGS are limited to either simplistic, unrealistic simulations or require substantial user input for complex scenes, largely due to the lack of scene comprehension. In this demonstration, we present a highly realistic interactive VR system powered by large language models (LLMs). After object-aware GS reconstruction, we prompt GPT-4o to analyze the physical properties of objects in the scene, which then guide physical simulations that adhere to real-world phenomena. Additionally, We design a GPT-assisted GS inpainting module to complete the areas occluded by manipulated objects. To facilitate rich interaction, we introduce a computationally efficient physical simulation framework through a PBD-based unified interpolation method, which supports various forms of physical interactions. In our research demonstrations, we reconstruct varieties of scenes enhanced by LLM's understanding, showcasing how our VR system can support complex, realistic interactions without additional manual design or annotation.",https://youtu.be/nFCFhJd6p60,,uQ5FAdPx1LIsRi_KkZoGW_A,,Haotian,,Mao,,404748294@qq.com,,Shanghai Jiao Tong University,Shanghai,,China,,,,,,ual0ivQzbt7ztJcGhWEfseQ,,Zhuoxiong,,Xu,,vector-02@sjtu.edu.cn,Shanghai Jiao Tong University,Shanghai Jiao Tong University,Shanghai,,China,,,,,,uKTwo37TKR2Z5Ex3Di2p54g,,Siyue,,Wei,,weisiyue071024@sjtu.edu.cn,Shanghai Jiao Tong University,Shanghai Jiao Tong University,Shanghai,,China,,,,,,uE-krPFmqkFFT4GWSbpqqtg,,Yule,,Quan,,qyl728@sjtu.edu.cn,Shanghai Jiao Tong University,Shanghai Jiao Tong University,Shanghai,,China,,,,,,uW1sLGrnC6XdIMlz9xS7Igw,,Nianchen,,Deng,,dengnianchen@pjlab.org.cn,,Shanghai AI Lab,Shanghai,,China,,,,,,uoEzQSEsbRUWtNwf9KadUFQ,,Xubo,,Yang,,yangxubo@sjtu.edu.cn,,SHANGHAI JIAO TONG UNIVERSITY,SHANGHAI,,China,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Haotian Mao: Shanghai Jiao Tong University; Zhuoxiong Xu: Shanghai Jiao Tong University; Siyue Wei: Shanghai Jiao Tong University; Yule Quan: Shanghai Jiao Tong University; Nianchen Deng: Shanghai AI Lab; Xubo Yang: SHANGHAI JIAO TONG UNIVERSITY,maohaotian@sjtu.edu.cn; vector-02@sjtu.edu.cn; weisiyue071024@sjtu.edu.cn; qyl728@sjtu.edu.cn; dengnianchen@pjlab.org.cn; yangxubo@sjtu.edu.cn
PO1100,complete,GRIPPY: A VR Grip Controller for Combating Sarcopenia in Elderly,Dr. Jiang WU,jiang.wu@nottingham.edu.cn,,A,4.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1100-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=785899d5bd1b94f6842a2888dec334b75da2d93bbb039aeb5d23ac14b1a22a11,2,letter,2025-01-27 14:13,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1100-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=2f08e28677cf61debf3464eef671ddb74906e8783805023465e09f5a2210440c,Hoi Lam Leong,"As the global population ages, sarcopenia—age-related muscle decline—demands innovative solutions. This paper introduces GRIPPY, a VR grip controller that transforms basic handgrip exercises into immersive, gamified tasks. By integrating sensor-based interaction and VR gameplay, older adults can strengthen grip while maintaining higher motivation. A preliminary test with three participants (ages 68–80) revealed key usability insights, underscoring GRIPPY’s potential for enhanced rehabilitation. Future work will refine its design and validate long-term efficacy.",https://youtu.be/bgRUFUP1zbM,,uUHMprG1IMabIxiGH5BYiWw,,Hoi Lam,,Leong,,suyhl1@nottingham.edu.cn,"Department of Mechanical, Materials and Manufacturing Engineering",University of Nottingham Ningbo China,Ningbo,,China,,,,,,u1n9DqUQ_k_QDvAgBZQFh5A,Dr.,Jiang,,WU,,jiang.wu@nottingham.edu.cn,"Department of Mechanical, Materials, and Manufacturing Engineering","University of Nottingham, Ningbo, China ",Ningbo,,China,,,,,,u1KlSpY7Iz6Na4pdFoDYWzw,,Dr. Yoke Chin,,Lai,,yoke-chin.lai@nottingham.edu.cn,"Department of Mechanical, Materials and Manufacturing Engineering",University of Nottingham Ningbo China,Ningbo,,China,,,,,,uaZUL_X3i17s-g-6mrrKXmw,,Loïc,,Faulon,,loic.faulon@nottingham.edu.cn,"Department of Mechanical, Materials and Manufacturing Engineering",University of Nottingham Ningbo China,Ningbo,,China,,,,,,u1VELhWzWPqcyTVYEzNI5Vg,,Xu,,Sun,,xu.sun@nottingham.edu.cn,"Department of Mechanical, Materials and Manufacturing Engineering",University of Nottingham Ningbo China,Ningbo,,China,,,,,,u9gwp_IWUXru7uuhWpBwJAA,Dr,Boon Giin,,Lee,,boon-giin.lee@nottingham.edu.cn,School of Computer Science,University of Nottingham Ningbo China,Ningbo,Zhejiang,China,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Hoi Lam Leong: University of Nottingham Ningbo China; Jiang WU: University of Nottingham, Ningbo, China ; Dr. Yoke Chin Lai: University of Nottingham Ningbo China; Loïc Faulon: University of Nottingham Ningbo China; Xu Sun: University of Nottingham Ningbo China; Boon Giin Lee: University of Nottingham Ningbo China",suyhl1@nottingham.edu.cn; yoke-chin.lai@nottingham.edu.cn; loic.faulon@nottingham.edu.cn; xu.sun@nottingham.edu.cn; boon-giin.lee@nottingham.edu.cn
PO1042,complete,Xareus: a Framework to Create Interactive Applications without Coding,Lysa Gramoli,lysa.gramoli@irisa.fr,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1042-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=aa307599c6f59f0daaf413cb1c735eede4ef2f3043c024602390e01ddb0ecb6d,2,letter,2025-01-27 17:49,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1042-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=8ec2993f80c7fabf04a993afb81d19df2748f484b55c6762d0ef79313a08e82d,Lysa Gramoli,"Creating interactive XR applications is a complex task. It implies people with different backgrounds which can lead to communication problems and a lot of coding, rarely formalized, that leads to a lack of reusability. Furthermore, the domain expert can not be directly involved in the creation process. Therefore, we propose Xareus, a framework designed to simplify and accelerate the creation of interactive applications with little coding. To help domain experts and developers, Xareus includes several features to make the virtual objects interactive, manage virtual humans, and create a scenario using a graphical interface or VR interaction. Our framework is compatible with Unity Engine and suitable for various fields such as training, video games, or industry. During the demo, the participants will have the opportunity to test these features. A video can be found here: https://youtu.be/iqdU3-202As",https://youtu.be/iqdU3-202As,,uLzVQjnNypDdAuPXIPAxxhg,,Lysa,,Gramoli,,lysa.gramoli@irisa.fr,,"Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,uDxgbFhO_Jw8el1AhFN2Crw,,Florian,,Nouviale,,florian.nouviale@inria.fr,,"Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,u2Y6e8pTGbTOF27KDlcXwyQ,,Adrien,,Reuzeau,,adrien.reuzeau@irisa.fr,,"Univ. Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,uV6NwBdlLtHkjDtwvbahzfA,,Alexandre,,Audinot,,alexandre.audinot@irisa.fr,,"Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,uDHTUfQhFJw42Sc34Di5FrQ,,Mathieu,,Risy,,mathieu.risy@irisa.fr,,"Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,uDqQTfF7jX7tc5V_6MrJlpw,,Tangui,,Marchand-Guerniou,,tangui.marchand-guerniou@inria.fr,,"Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,uU5TrPp0og6lxSgcM0Mj04Q,,Maé,,Mavromatis,,mae.mavromatis@inria.fr,,"Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,u-REajvbjwTF6h4KPQ6XjKA,,Bruno,,Arnaldi,,bruno.arnaldi@irisa.fr,,"Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,uWQUyzA3KLqhWLurIVHWrLw,,Valérie,,Gouranton,,valerie.gouranton@irisa.fr,,"Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",Rennes,,France,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Lysa Gramoli: Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA; Florian Nouviale: Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA; Adrien Reuzeau: Univ. Rennes, Inria, CNRS, IRISA; Alexandre Audinot: Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA; Mathieu Risy: Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA; Tangui Marchand-Guerniou: Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA; Maé Mavromatis: Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA; Bruno Arnaldi: Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA; Valérie Gouranton: Univ. Rennes, INSA Rennes, Inria, CNRS, IRISA",florian.nouviale@irisa.fr; adrien.reuzeau@irisa.fr; alexandre.audinot@irisa.fr; mathieu.risy@irisa.fr; tangui.marchand-guerniou@irisa.fr; mae.mavromatis@irisa.fr; bruno.arnaldi@irisa.fr; valerie.gouranton@irisa.fr
PO1079,complete,Advancing Critical Care Skills: Immersive VR Training Powered by Real-World Patient Data,Luisa Theelke,luisa.theelke@tum.de,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1079-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=cd4ffbfc6d765e3accba769d17310b843dd887be56fa0484b938c99cb98e79cd,2,letter,2025-01-28 15:01,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1079-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=c6c8849e0ea5b2f6e7721804e587f2f3742ea00d1a8a35f0ce5bdbeb5a033709,Luisa Theelke,"VR simulations are becoming essential for staff training in clinical care, specifically in environments that cannot be trained well during regular operations, such as critical care. This paper presents a novel system that aims at further closing the gap between simulation and reality by integrating real patient data into immersive training scenarios in the context of acute care. Focused on sepsis recognition, the VR simulation introduces trainees to clinical routines and to make informed decisions while observing the evolving patient conditions. By engaging with dynamic disease progression, it fosters understanding of critical conditions in a time-sensitive context. Preliminary feedback from a pilot assessment with nursing professionals highlighted its value for trainees and potential to enhance preparedness and decision-making skills in real-world scenarios.",https://youtu.be/Wei4QCzCGDY,,uTATIItNxlZwV4sCdtdxGJA,,Luisa,,Theelke,,luisa.theelke@tum.de,Clinic for Orthopedics and Sports Orthopedics,"TUM University Hospital,Technical University Munich",Munich,,Germany,,,,,,unS3xRyuK04XA62oZfkWVeA,,Diana,,Beksultanow,,diana.bek.ow@gmail.com,,Technical University of Munich,Munich,,Germany,,,,,,uKtPwvbLzgLTA6UZi7cbNiQ,,Lydia,,Marquardt,,lydia.marquardt@tum.de,,Technical University of Munich,Munich,,Germany,,,,,,uHXvvaBJpjhv15nXRianCbw,,Philipp,,Gulde,,philipp.gulde@tum.de,Chair of Human Movement Science,Technical University of Munich,Munich,,Germany,,,,,,uY_7aPF_wYW24R5xNQEFbsA,,Lisa,,Vallines,,lisa.vallines@gmx.de,,Siemens Healthineers,Forchheim ,,Germany,,,,,,uTephgSNlpj43GucK6eMBYQ,Prof. Dr.,Daniel,,Roth,,daniel.roth@tum.de,Human-Centered Computing and Extended Reality Lab,Technical University of Munich,Munich,Bavaria,Germany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Luisa Theelke: TUM University Hospital,Technical University Munich; Diana Beksultanow: Technical University of Munich; Lydia Marquardt: Technical University of Munich; Philipp Gulde: Technical University of Munich; Lisa Vallines: Siemens Healthineers; Daniel Roth: Technical University of Munich",diana.bek.ow@gmail.com; lydia.marquardt@tum.de; philipp.gulde@tum.de; Lisa.vallines@siemens-healthineers.com; daniel.roth@tum.de
PO1110,complete,Digital Time Machine: A Virtual Reality Reconstruction of the Southwestern Zeitgeist Through the Lens of Clark Hulings' Artistic Legacy,Hamida Khatri,hamida.khatri@utdallas.edu,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1110-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=c38ca7bdf369e1f2c721d3202d4ce0331c242506a86046b1a38b6e3aea025d09,2,letter,2025-01-27 21:49,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1110-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=29d9cc04d7f601fbac8f32f0d63637135eba79faa4f95be6aa573f40eaf4abb4,Jeffrey Price,"This research demo showcases the “Digital Time Machine,” a virtual reality (VR) experience designed to transport users to 1974 Chimayo, New Mexico, as captured through the artistry of Clark Hulings. By integrating photorealistic VR environments, artistic stylization, and user-centered design, the project demonstrates the potential of immersive technology to deepen cultural appreciation, historical understanding, and artistic engagement. Developed in collaboration with the New Mexico Museum of Art Vladem Contemporary, this project exemplifies how VR can bridge temporal and spatial divides, allowing museum audiences to step into the world of Hulings’ iconic painting.",https://vimeo.com/1046656410,,uSPF2OqReAklFDXW4Wf4ypw,,Jeffrey,,Price,,jeffrey.price@utdallas.edu,"Harry W. Bass Jr. School of Art, Humanities, and Technology",The University of Texas at Dallas,Richardson,Texas,United States,,,,,,uHVdj37PMnLfzkW5zcfV1QQ,,Hamida,,Khatri,,hamida.khatri@utdallas.edu,"Harry W. Bass Jr. School of Art, Humanities, and Technology",The University of Texas at Dallas,Richardson,Texas,United States,,,,,,uvBHlKkwJdkAJaCUQEgFy0g,,Brandon,,Coffey,,brandon.coffey@utdallas.edu,"Harry W. Bass Jr. School of Art, Humanities, and Technology",The University of Texas at Dallas,Richardson,Texas,United States,,,,,,u8OGxqkD4vQP8L4Xh3yTVIg,,Chris,,Gauthier,,chris.gauthier@utdallas.edu,"Harry W. Bass Jr. School of Art, Humanities, and Technology",The University of Texas at Dallas,Richardson,Texas,United States,,,,,,uhI-ixy0pg4gsUTx29_yFfw,,Jacqueline,,Garza,,jackie.garza@utdallas.edu,"Harry W. Bass Jr. School of Art, Humanities, and Technology",The University of Texas at Dallas,Richardson,Texas,United States,,,,,,u-lyOGQTtEBg30aizzK-1jA,,Evan,,Barreiro,,evanrjbarreiro@gmail.com,Evan Barreiro Designs,Evan Barreiro Designs,Denver,Colorado,United States,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Jeffrey Price: The University of Texas at Dallas; Hamida Khatri: The University of Texas at Dallas; Brandon Coffey: The University of Texas at Dallas; Chris Gauthier: The University of Texas at Dallas; Jacqueline Garza: The University of Texas at Dallas; Evan Barreiro: Evan Barreiro Designs,jeffrey.price@utdallas.edu; brandon.coffey@utdallas.edu; chris.gauthier@utdallas.edu; jackie.garza@utdallas.edu; evanrjbarreiro@gmail.com
PO1105,complete,Virtual Exhibition as a Portal to Authentic Art Experiences: Exploring the Immersive Reproduction of Exhibition in Practice,Dr Xiao Wei,xiao.wei@soton.ac.uk,,A,4,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1105-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=736cfe6d67708a36bcfc5e0438e034292b948853473ba41119f9e99f007447ce,2,letter,2025-01-27 22:47,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1105-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201551Z&X-Amz-Signature=c360236119affb5eaea95a60d140caa1440e521092ecd80322dbbdc19f10a2d5,Yuanyuan Yin,"Exhibitions are traditionally constrained by fixed times and locations, limiting access for a wider audience. Immersive reproduction, leveraging 3D reconstruction and virtual reality technologies, offers a way to transcend these temporal and spatial limitations. While previous research has largely focused on integrating mixed-reality elements within physical museum spaces, treating VR as a supplementary tool, our research positions VR as the primary “portal” to authentic artistic experiences. This demo showcases the complete process of immersive reproduction for Following the Fish, an exhibition featured at the 18th Venice International Architecture Biennale in 2023, offering valuable insights and references for future digital archiving and immersive reproduction of exhibitions. The reproduced immersive exhibition was constructed at a 1:1 original scale of the physical exhibition. When the available space permits (i.e., when the space is equal to or larger than the original venue), visitors can walk through the virtual environment, recreating an authentic artistic experience.",https://www.youtube.com/watch?v=ku_HTQo0ruI,,us5PzoyXyOJFNy1bQo8DX0w,Professor,Yuanyuan,,Yin,,y.yin@soton.ac.uk,"Winchester School of Art,",University of Southampton,Winchester,Hampshire,United Kingdom,,,,,,uQqTjkLzwk4hG38VkMlCB8g,,Lian,,Pan,,lian.pan@soton.ac.uk,Winchester School of Art,University of Southampton,Winchester,,United Kingdom,,,,,,ucZTXGQgKWUHnTitH7-V45Q,Dr,Xiao,,Wei,,xiao.wei@soton.ac.uk,Winchester School of Art,University of Southampton,Southampton,,United Kingdom,,Guangxi Normal University,Guilin,,China,u3-zuP202mWYLbuy9Pgp_JA,Dr,Ruohan,,Tang,,ruohan.tang@soton.ac.uk,Winchester School of Art,University of Southampton,Southampton,,United Kingdom,,,,,,uTm6VKOC4fXjnk9JHtzo6MQ,Mr,Christopher,Shuan,O'Connor,,c.s.oconnor@soton.ac.uk,Winchester School of Art,University of Southampton,Southampton,,United Kingdom,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yuanyuan Yin: University of Southampton; Lian Pan: University of Southampton; Xiao Wei: University of Southampton; Ruohan Tang: University of Southampton; Christopher Shuan O'Connor: University of Southampton,y.yin@soton.ac.uk; lian.pan@soton.ac.uk; ruohan.tang@soton.ac.uk; c.s.oconnor@soton.ac.uk
PO1060,complete,Demonstration of VirtuEleDent: A Compact XR Tooth-Cutting Training System Using a Physical EMR-based Dental Handpiece and Teeth Model,Yuhui Wang,wang.yuhui.r1@dc.tohoku.ac.jp,,A,3.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1060-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201552Z&X-Amz-Signature=35d4336e65adc74ab4ce8b44f906dc0238a6deb997f8fbd5953821444f1eb91a,2,letter,2025-01-28 9:05,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1060-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201552Z&X-Amz-Signature=0e8822f996b5656ba55ad55e916fbf067a19a7e3b6d2d03bd1b388a1180a3683,Yuhui Wang,"Dental cutting is a crucial skill for dental students. However, current VR dental cutting training systems rely on bulky and costly haptic devices, which reduce opportunities for individual practice. Moreover, the limitations imposed by the maximum reaction force of an active haptic device would impact the range of tooth hardness that can be reproduced. We propose a compact XR tooth-cutting training system, VirtuEleDent, that employs a passive haptic approach using a 3D-printed physical teeth model and a three-dimensionally tracked handpiece. Their spatial relationship is accurately rendered in the virtual environment of a mobile head-mounted display (HMD), providing users with realistic haptic sensations during virtual tooth-cutting exercises. Our tracking platform is operated using electromagnetic resonance (EMR) stylus technology and consists of a digitizer (i.e., tracking board) and a handpiece device. A customized EMR stylus unit (i.e., resonance coil) and an inertial measurement unit (IMU) sensor are installed inside the handpiece, allowing for precise measurement of its tip's 3D position and orientation. This setup enables the learner to physically manipulate dexterous handpieces on the teeth model while experiencing virtual tooth-cutting in the HMD. This is a companion demo to the IEEE VR 2025 Conference paper: ``VirtuEleDent: A Compact XR Tooth-Cutting Training System Using a Physical EMR-based Dental Handpiece and Teeth Model.'' To watch a video about VirtuEleDent, please visit \url{https://youtu.be/ZvHZ6IEAhyM}.",https://www.youtube.com/watch?v=ZvHZ6IEAhyM,,uJPBOszh8kz3dLjLx6xbuMA,,Yuhui,,Wang,,wang.yuhui.r1@dc.tohoku.ac.jp,,Tohoku University,Sendai,Miyagi,Japan,,,,,,uM_MuHYv41f4KFWdMFrKd-A,,Kazuki,,Takashima,,takashim@shibaura-it.ac.jp,,Shibaura Institute of Technology,Saitama,,Japan,,,,,,ulXSNr1zlylmMTtN93Z1q6A,,Masamitsu,,Ito,,masamitsu.ito@wacom.com,EMR tech.1,"Wacom Co.,Ltd.",Kazo city,Saitama Pref.,Japan,,,,,,uAoJBs3wjxDgh5CiNBgfhLg,,Takeshi,,Kobori,,takeshi.kobori@wacom.com,,"Wacom Co., Ltd. EMR Technology",Saitama,,Japan,,,,,,up8XdxNt0vsKMwIBY9kYvcw,,Tomo,,Asakura,,tomo.asakura@wacom.com,EMR Technology,"Wacom Co., Ltd.",Saitama,,Japan,,,,,,uZTNWViAdZf2THAxOa6b2mg,,Kazuyuki,,Fujita,,k-fujita@riec.tohoku.ac.jp,Research Institute of Electrical Communication,Tohoku University,Sendai,Miyagi,Japan,,,,,,umFlMWFSE6yK2YZZlIH4njQ,Prof.,Hong,,Guang,,hong.guang.d6@tohoku.ac.jp,Graduate School of Dentistry,Tohoku University,Sendai,,Japan,,,,,,upUd0k0BebX4Lqo3JXAoc7g,,Yoshifumi,,Kitamura,,kitamura@riec.tohoku.ac.jp,Research Institute of Electrical Communication,Tohoku University,Sendai,,Japan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Yuhui Wang: Tohoku University; Kazuki Takashima: Shibaura Institute of Technology; Masamitsu Ito: Wacom Co.,Ltd.; Takeshi Kobori: Wacom Co., Ltd. EMR Technology; Tomo Asakura: Wacom Co., Ltd.; Kazuyuki Fujita: Tohoku University; Hong Guang: Tohoku University; Yoshifumi Kitamura: Tohoku University",takashim@shibaura-it.ac.jp; masamitsu.ito@wacom.com; takeshi.kobori@wacom.com; tomo.asakura@wacom.com; k-fujita@riec.tohoku.ac.jp; hong.guang.d6@tohoku.ac.jp; kitamura@riec.tohoku.ac.jp
PO1107,complete,Flexible Virtual Lenses to Magnify Virtual Environments Locally Without Losing Context Information,Doctor Julien Jean Ducrocq,julien.ducrocq07@gmail.com,,A,5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1107-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201552Z&X-Amz-Signature=abc09bcfa5690cc332b9613ef9ad8ee2926a5688c8a5ac05ea2ffeeea82eade6,2,letter,2025-01-29 11:47,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1107-cam-i18.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201552Z&X-Amz-Signature=0200da774fb7bf90e7a996b06a0ba2efcdcc9ed3bdf157de535f6d94a3712052,Doctor Julien Jean Ducrocq,"We introduce virtual lenses that magnify image regions locally without losing context elements. We developed a unified formalism to design virtual lenses of any closed shape, that can be moved interactively on a screen and within a virtual reality (VR) application in real-time. Moreover, our lenses are versatile: the user can change their parameters to modify the appearance of the magnified image region dynamically. These lenses are suitable for several applications, including virtual tourism and video-surveillance. Our demo showcases an implementation of a lens changing of shape in real-time on a non-VR monitor, followed by a proof-of-concept VR version where the user can move a lens with a VR controller to deform remote textures at different distances.",https://youtu.be/mMMdJj67vb4,,uUWE1ZWAutF4Pgmp_6ZtZAA,Doctor,Julien,Jean,Ducrocq,,julien.ducrocq07@gmail.com,Cybernetics and Reality Engineering Laboratory,Nara Institute of Science and Technology,Ikoma-shi,Nara-ken,Japan,,,,,,u9cqERCaW0UxkFkNGlwdtrg,,Yutaro,,Hirao,,yutarohirao@gmail.com,Cybernetics and Reality Engineering Laboratory,Nara Institute of Science and Technology,Ikoma-shi,Nara-Ken,Japan,,,,,,uJYHEHho6iPwfiQ9XCnUe9w,,Monica,,Perusquia-Hernandez,,perusquia@ieee.org,Cybernetics and Reality Engineering Laboratory,Nara Institute of Science and Technology,Ikoma-shi,Nara,Japan,,,,,,uby9VA0hlKumS0D6a1_Sd3g,,Hideaki,,Uchiyama,,hideaki.uchiyama@is.naist.jp,Cybernetics and Reality Engineering Laboratory,Nara Institute of Science and Technology,Nara,Nara,Japan,,,,,,uGyxIF4x868dvGUlGer_-cg,,Kiyoshi,,Kiyokawa,,kiyo@is.naist.jp,Cybernetics and Reality Engineering Laboratory,Nara Institute of Science and Technology,Ikoma,Nara,Japan,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Julien Jean Ducrocq: Nara Institute of Science and Technology; Yutaro Hirao: Nara Institute of Science and Technology; Monica Perusquia-Hernandez: Nara Institute of Science and Technology; Hideaki Uchiyama: Nara Institute of Science and Technology; Kiyoshi Kiyokawa: Nara Institute of Science and Technology,yutarohirao@gmail.com; m.perusquia@is.naist.jp; hideaki.uchiyama@is.naist.jp; kiyo@is.naist.jp
PO1141,complete,ARES: Augmented Reality and AI Assistance Technologies for Safety and Efficiency Optimization in Explosive Ordnance Exploration ,Paul Chojecki,paul.chojecki@hhi.fraunhofer.de,,A,4.5,,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1141-cam-i5.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201552Z&X-Amz-Signature=d63f60e810db575db4efe827e77af045716eba5b7fb1f9d0ab89b3c7a6093989,2,letter,2025-01-28 16:51,https://0d2f0bc53ec40041bef323f40496ed3c.r2.cloudflarestorage.com/pcs/vr25c/vr25c-sub1141-cam-i18.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=7200&X-Amz-Credential=8c3c5bf11286f4699c7019eaeac51dfe%2F20250203%2Fenam%2Fs3%2Faws4_request&X-Amz-SignedHeaders=host&X-Amz-Date=20250203T201552Z&X-Amz-Signature=696443932a0eeb8087b8ba0969d160e82082feffd30e83b8f8bf942a7ab75b61,Paul Chojecki,"Unexploded ordnance (UXO) detection remains a critical challenge in past and present conflict zones. Magnetometer surveys are a key method for identifying UXO, but require precise, systematic scanning and expert interpretation. The ARES project leverages Augmented Reality (AR) and Artificial Intelligence (AI) to enhance UXO exploration by improving quality, efficiency, and safety. Using AR glasses, the system guides users through survey areas, assisting with lane alignment, walking speed, and maintaining magnetometer stability. AI-driven processing transforms sparse magnetometer data into dense magnetic maps, while suspected UXO points are directly visualized in the AR display. These features streamline on-site navigation and analysis, offering an intuitive decision-support system for field experts while maintaining reliance on human expertise.",https://youtu.be/XwrrVjPg-a4,,uqfZc0FRpOLmOST9z5X4ALQ,,Paul,,Chojecki,,paul.chojecki@hhi.fraunhofer.de,Vision & Imaging Technologies,Fraunhofer Heinrich Hertz Institute HHI,Berlin,,Germany,,,,,,uUG3dMWMkuqloUFH0s36cuA,,David,,Przewozny,,david.przewozny@hhi.fraunhofer.de,Vision & Imaging Technologies,Fraunhofer Heinrich Hertz Institute HHI,Berlin,,Germany,,,,,,u-RTcwNFWUj4KbcAGhaeewA,,Mustafa,,Lafci,,mustafatevfik.lafci@hhi.fraunhofer.de,Vision & Imaging Technologies,Fraunhofer Institute for Telecommunications,Berlin,,Germany,,,,,,uiQ05OEo5-oDhtRH_8e8JXA,Dr.,Mykyta,,Kovalenko,,mykyta.kovalenko@hhi.fraunhofer.de,Vision & Imaging Technologies,Fraunhofer Heinrich Hertz Institute HHI,Berlin,,Germany,,,,,,u2PdojmP4VBjSyUewUjIWtw,,Pia,,Packmohr,,info@usetree.com,,UseTree GmbH,Berlin,,Germany,,,,,,uKBYMxu3hD_VEyizaV3DG8w,,Hoa,,van Thanh,,hoa.van.thanh@usetree.com,,UseTree GmbH,Berlin,,Germany,,,,,,u7d0iVWarrCu_UNqAR0N3nw,,Laura,,Dreßler-Pasenau,,laura.dressler@usetree.com,,UseTree GmbH,Berlin,,Germany,,,,,,u9EmnAwp7tYJcMIbFl1P0kA,,Wolfgang,,Süß,,wsuess@sensys.de,,SENSYS GmbH,Bad Sarow,,Germany,,,,,,ujAXK4v7-846qhW22ToQnDQ,,Stefan,,Häber,,stefan.haeber@usetree.com,,UseTree GmbH,Berlin,,Germany,,,,,,umcxQ2y2V3--WTYD56wLNcA,Dr.,Sebastian,,Bosse,,sebastian.bosse@hhi.fraunhofer.de,,Fraunhofer HHI,Berlin,,Germany,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Paul Chojecki: Fraunhofer Heinrich Hertz Institute HHI; David Przewozny: Fraunhofer Heinrich Hertz Institute HHI; Mustafa Lafci: Fraunhofer Institute for Telecommunications; Mykyta Kovalenko: Fraunhofer Heinrich Hertz Institute HHI; Pia Packmohr: UseTree GmbH; Hoa van Thanh: UseTree GmbH; Laura Dreßler-Pasenau: UseTree GmbH; Wolfgang Süß: SENSYS GmbH; Stefan Häber: UseTree GmbH; Sebastian Bosse: Fraunhofer HHI,david.przewozny@hhi.fraunhofer.de; mustafatevfik.lafci@hhi.fraunhofer.de; mykyta.kovalenko@hhi.fraunhofer.de; info@usetree.com; hoa.van.thanh@usetree.com; laura.dressler@usetree.com; wsuess@sensys.de; stefan.haeber@usetree.com; sebastian.bosse@hhi.fraunhofer.de