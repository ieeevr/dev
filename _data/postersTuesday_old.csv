"BoothID","authors","abstract","title","PosterCategory","VideoLink"
TBD,"Gal Hadad: University of Haifa; Amber Maimon: University of Haifa; Ofer Arazy: University of Haifa; Joel Lanir: The University of Haifa","By merging digital content with the physical environment, AR offers unique social interaction opportunities alongside distinct risks. This study explores perceived benefits and risks of sharing personal info in AR social contexts. Analysis of participant interviews, conducted after presenting three AR scenarios, revealed benefits like targeted communication, networking opportunities, and fostering shared values, varying by scenario. Participants also identified risks like prejudgement, harassment, and diminished emotional connection, also shown to be context-dependent. These findings demonstrate the dynamic interplay between advantages and vulnerabilities of self-disclosure in AR, highlighting the need for systems addressing these concerns.","Perceived benefits and risks of information disclosure in augmented reality","Ethical and Psychological Aspects",njvFx6s3asM
TBD,"Yuyang Jiang: Computational Media and Art; Dehan JIA: The Hong Kong University of Science and Technology (Guangzhou); Zeyu Yang: HKUST(Guangzhou); Ling Li: The Hong Kong University of Science and Technology (Guangzhou); Yuyang Wang: The Hong Kong University of Science and Technology (Guangzhou); Pan Hui: The Hong Kong University of Science and Technology","With the rapid advancement of Virtual Reality (VR) technology, immersive meditation experiences have become a promising tool for enhancing mental well-being. However, many existing VR meditation environments lack personalization and realistic integration, limiting their effectiveness. This study evaluated personalized virtual relaxation environments using a comparative research design. Results showed that the experimental group, using generative virtual meditation spaces, experienced significantly more positive emotional states. Future work will explore the impact of VR meditation through fNIRS measurements of prefrontal cortex activity, aiming to understand how personalized virtual environments influence psychological and neural responses.","Mindfulness Anywhere: Mediating in the Virtual World","Ethical and Psychological Aspects",G6pccd4UFFc
TBD,"Aleshia Hayes: University of North Texas; John Quarles: University of Texas at San Antonio; Greg Welch: University of Central Florida; Dylan Fox: Cornell Tech","This study explores perspectives on DEIA from researchers from IEEE VR. Fourteen participants expressed sustained commitment to DEIA, noting underrepresentation of women, BIPOC, individuals with disabilities, and researchers from developing countries or low socioeconomic backgrounds. Participants perceived high costs, lack of accessibility features (e.g., subtitles, mobility support), and insufficient family resources (e.g., childcare) as barriers. Among factors that could deter support of DEIA listed were fear of retaliation, financial constraints, structural challenges, and difficulties identifying diverse representatives. Participants supported reporting demographic statistics, strategic planning, and promoting DEIA in speakers.","Does DEI Still Matter?: A Survey of VR Researchers at IEEE VR","Ethical and Psychological Aspects",u54E2LTogww
TBD,"Ripan Kumar Kundu: University of Missouri-Columbia; Khaza Anuarul Hoque: University of Missouri","The convergence of AI and VR technologies (AI VR) offers innovative applications but raises privacy concerns due to the sensitive nature of data. This work demonstrates that AI VR models are vulnerable to membership inference attacks (MIA) and leak users' information, with a high success rate. To address this, we propose the SecretVR framework, which uses a differential privacy (DP)-enabled privacy-preserving mechanism to defend against MIA. Evaluated on seven AI VR models and three different datasets, our approach reduces the MIA success rates by up to $32\%$ while maintaining high model utility with classification accuracies.","SecretVR: Differential Privacy Defense Against Membership Inference Privacy Attacks in Virtual Reality","Ethical and Psychological Aspects",aJHdTWt_Umg
TBD,"Jayasri Sai Nikitha Guthula: University of Arkansas at Little Rock; Hadi Rashid: University of Arkansas at Little Rock; Jan P Springer: University of Arkansas at Little Rock; Aryabrata Basu: University of Arkansas at Little Rock","Telemetry data is essential for optimizing VR systems but poses privacy risks due to re-identification vulnerabilities. This study introduces a privacy-preserving framework using Wasserstein GANs with Gradient Penalty (WGAN-GP) to generate synthetic datasets that retain the statistical integrity of real data while mitigating re-identification risks. Differentially Private Stochastic Gradient Descent (DP-SGD) enhances privacy by introducing controlled noise during model training. The proposed approach effectively balances data utility and privacy, enabling secure analysis of VR telemetry data for performance optimization and user experience improvement, paving the way for safer and more ethical VR data practices.","Preserving Privacy in VR Telemetry Data","Ethical and Psychological Aspects",_Ootv4ay7nc?si=dXXMSWYeE-QDOCAw
TBD,"Iresh Jayasundara Mudiyanselage: University of Oulu; Eemeli Häyrynen: University of Oulu; Severi Pitkänen: University of Oulu; Paula Alavesa: University of Oulu; Sirpa Kekäläinen: University of Oulu; Katherine J. Mimnaugh: University of Oulu; Tarja Pölkki: Research Unit of Health Sciences and Technology, University of Oulu","Children often experience anxiety and fear when undergoing Magnetic Resonance Imaging (MRI), leading to challenges in completing the procedure. This study presents a Virtual Reality application designed to simulate the MRI experience, aimed at reducing anxiety and preparing children for the procedure. The VR application was evaluated through a pilot study with parents and medical experts, as ethical constraints prevented testing with children. The results indicated high usability, and positive feedback regarding the realism of the MRI sounds and environments. Participants emphasized the potential for the application to prepare both children and their parents for the MRI process.","A Serious Immersive VR Game Designed for a Better Magnetic Resonance Imaging Experience for Children","Ethical and Psychological Aspects",GGLNGQyhJJQ?si=02G5E8jrfbMgeZRp
TBD,"Hiroki Terashima: Hamamatsu; Koji Kanda: Hamamatsu; Aozora Shimao: Hamamatsu; Kenichiro Fujita: Yokohama; Takuhiro Mizuno: Alpha Code.Inc; Shogo Ishikawa: Shizuoka University; Shinya Kiriyama: Shizuoka University","In this study, we developed an exercise intervention program in an XR environment that is customized for each individual and enables self-training of gait and posture for the promotion of health, and had 17 subjects practice the program. Expert evaluated the gait videos before and after the training and confirmed that all subjects improved their gait. The experts' evaluations provided useful suggestions for information presentation control during the XR experience, and experts’ comments provided new insights, such as differences in the improvement effect depending on the physical characteristics of the subjects.","Development of Exercise Intervention Program for Gait and Posture  Improvement in Extended-Reality Environment","Training and Education",6gbwnVj0FFY
TBD,"Alberto Carvalho: Fraunhofer Portugal AICOS; Waldir Moreira PhD: Fraunhofer Portugal AICOS; Filipe Sousa: Fraunhofer Portugal AICOS; Isabel Alexandre: Instituto Universitário de Lisboa (ISCTE-IUL)","Operating hazardous machinery often requires comprehensive training, which can be costly, time-consuming, and lead to delays. To address these challenges, we introduce VR Trainee, a Virtual Reality-based tool designed for electrical substation workers. VR Trainee allows users to interact with objects in a safe, controlled environment, enhancing training effectiveness for new maintenance employees. Equipped with inertial sensors, it gathers data to provide real-time feedback related to users’ actions. Initial validation shows significant skill improvements, thanks to trial-and-error opportunities and clear instructions. Our work demonstrates VR’s potential to streamline learning and boost user motivation.","VR Trainee: a Virtual Reality Training Tool for the Energy Industry","Training and Education",dWvJwmKRAMA?si=ORz2V7hdJh60IkdU
TBD,"Mengyao Guo: Harbin Institute of Technology, Shenzhen; Shunan Zhang: School of Architecture and Design; Zhenran Xu: Harbin Institute of Technology; Yuyang Jiang: Computational Media and Art; Yikun Fang: Royal college of art","We introduce \""Folding Reality\"" for conducting research on training spatial computing in virtual reality scenarios. It is designed for children and Large Multimodal Models (LMMs). We aim to understand how creativity emerges during the 2D to 3D folding process through interactive data gathered from children's engagement with the game. We will then use this data to train LMMs, providing them an opportunity to enhance their spatial computing abilities through interactive paper folding. Our goal is to create a learning environment where both children and LMM can explore and understand spatial relationships, advancing research in this field.","Folding Reality: Learning Spatial Computing through VR Interactive Paper Folding Game","Training and Education",npzzC-1VYsE
TBD,"Ryudai Inoue: Waseda University; Qi Feng: Waseda Research Institute for Science and Engineering; Shigeo Morishima: Waseda Research Institute for Science and Engineering","Acquiring fine motor skills for the non-dominant hand is challenging yet crucial, particularly when the dominant hand is injured. While traditional mirror therapy has proven effective, it often requires extended practice and can impose significant cognitive demands. This paper presents a novel augmented reality system that leverages inverted visual feedback from the dominant hand's real-time movements, coupled with a synchronized instructional video, to facilitate efficient training for the non-dominant hand. Experimental results demonstrate that this approach significantly enhances non-dominant hand skills in a short period while maintaining a low cognitive load.","SynchroDexterity: Rapid Non-Dominant Hand Skill Acquisition with Synchronized Guidance in Mixed Reality","Training and Education",S5EYdD4_Epo
TBD,"Aran Aharoni: Ben Gurion University; Guy Lavy: Ben Gurion University; Ilan Vol: Ben Gurion University; Shachar Maidenbaum: Ben Gurion University","Diagnosing medical conditions is critical for medical personnel. Current training tools include textbooks or descriptive scenarios that lack interactivity and offer limited hands-on experience or expensive scenarios with actors. Interactive virtual simulations hold great promise, but are limited by a lack of tangibleness and realism. We suggest that augmented reality may be a key addition to the training toolbox, specifically augmenting the user’s body, thus providing a tangible platform for interaction. We developed such a self-diagnosis training platform and performed basic usability testing. We found that users could successfully use the platform, with performance correlated with self-reported medical knowledge.","An Augmented reality platform for medical self-diagnosis training","Training and Education",https://youtube.com/shorts/u1EMofIxG_Q?feature=share
TBD,"Forouzan Farzinnejad: Coburg University of applied sciences and arts; Navid Khezrian: Coburg University of Applied Sciences and Arts; Seyedmasih Tabaei: Coburg University of applied sciences and arts; Jens Grubert: Coburg University of Applied Sciences and Arts","This study presents a Virtual Reality vocational training system for bakery sales, offering a potentially cost-effective and immersive solution to traditional training methods. The VR platform is designed to simulate realistic customer interactions, product handling, and transactions, which are believed to support trainees in developing skills, building confidence, and preparing for real-world tasks. A study with ten participants yielded a System Usability Scale score of 72.5, indicating positive usability feedback. This work explores VR's potential for vocational training through immersive simulations that support skill development, confidence-building, and real-world readiness.","Immersive Virtual Reality for Vocational Training: A Case Study in Bakery Sales Training","Training and Education",geaYb4vxF3I
TBD,"Jos Deforges: University of Rennes; Alexandre Vu: University of Rennes; Virginie Gandemer: University Hospital of Rennes; Jacinthe Bonneau-Lagacherie: University Hospital of Rennes; Fanny Drouadenne: University Hospital of Rennes; Steven Gastinger: University of Rennes; Benoit Bideau: University of Rennes; Catherine Soladie: CentraleSupelec; Amélie Rebillard: University of Rennes","Exercise improves health outcomes in hospitalized children with cancer but is often limited by various barriers. Virtual Reality (VR)-based exergames offer a promising solution. This study evaluated the acceptance, compliance, and intensity of a custom VR-based exergame program for pediatric cancer patients in a hospital setting. Thirteen children participated, achieving a compliance rate of 68\% and an average intensity of 4.92 METs, meeting recommended moderate-to-vigorous physical activity (PA) levels. The findings suggest that this VR-based exergame is a promising and engaging intervention to promote exercise in children with cancer during treatment, with minimal risk of cybersickness.","Evaluating Compliance, Acceptance, and Exercise Intensity of a Custom Virtual Reality Exergame for Hospitalized Children with Cancer: A Pilot Study","Training and Education",3VB9FWBxsZY?si=o5-hrU1_QzH8_-H2
TBD,"Kelly Minotti: Université Paris Saclay; Guillaume Loup: Paris-Saclay; Amine Chellali: Université d'Evry Paris Saclay; Marie-helene Ferrer: The French Armed Forces Biomedical Research Institute; Samir Otmane: Université d'Evry , Université Paris Saclay","In VR training, debriefing is as crucial as the simulation phase. With the growing adoption of these pedagogical tools, defining optimal educational approaches to maximize benefits for trainers and learners becomes essential. However, despite their benefits, VR-adapted debriefing methods still need to be explored. This paper presents an adaptable, all-in-one immersive debriefing module. It includes a complete system for recording, reviewing, and redoing actions. An ongoing study explores the redo module's effect in dynamic training scenarios. This module could enhance learning and reinforce immersive debriefing systems' interest and relevance."," Virtual Reality Learning Optimization: Immersive Debriefing with Review and Redo for Effective, Targeted Training","Training and Education",dsOkaf-LnTQ
TBD,"Brady Phelps: Ohio University; Chang Liu: Ohio University; Chad Mourning: Ohio University","Schrödinger's Beat aims to make quantum education intuitive, fun, and active. This research iterates on existing rhythm game concepts and introduces quantum computing principles. Users will follow a brief tutorial, before engaging in the main application, where they use their hands to smash a series quantum gates in time with the rhythm, and purposefully dodge gates to apply them to a qubit. The users aim to smash gates while dodging correct gates to match their qubit state with a goal state. Users gain familiarity with quantum concepts while staying active and interacting with intuitive 3D representations of quantum computing concepts.","Schrödinger's Beat","Training and Education",Bjf4BKjGW1U
TBD,"Mario Lorenz: Chemnitz University of Technology; Martin Okoniewski: Chemnitz University of Technology; Arwa Own: Chemnitz University of Technology; Sebastian Knopp: Chemnitz University of Technology","Using Augmented Reality in the production of home appliance is an understudied field, even more its use in circular economy. Further, also the application of Artificial Intelligence for validating that an AR instructed task was actually carried out correctly is an underexplored area. In this work we present the novel concept for using AR to recover parts from returned washing machines in a circular economy approach, validating that the disassembly is carried out correctly using the YOLO-AI-model. A last challenge is the adaptability of the AR instructions that need to change depending on the varying conditions of the recovered parts.","Industrial Augmented Reality – Concept for an AR-AI-Station for Component Recovery from Washing Machines for Circular Economy","Training and Education",qIe7_sg9D8k
TBD,"Navid Khezrian: Coburg University of Applied Sciences and Arts; Forouzan Farzinnejad: Coburg University of applied sciences and arts; Jens Grubert: Coburg University of Applied Sciences and Arts","We present a Virtual Reality (VR) educational system for teaching single-layer perceptron concepts, offering an immersive and interactive approach to enhance traditional learning methods. The VR platform gamifies neural network training by simulating a logical OR gate in a factory-inspired environment, aiming at bridging abstract theories with practical applications. In a user study with eight participants, the system received positive but also critical feedback for its interactivity and usability, achieving a System Usability Scale score of 64.69. As an initial study on teaching machine learning in VR, this work highlights VR’s potential to enhance comprehension and engagement through experiences.","Towards a Virtual Reality-Based Educational System for Teaching Single-Layer Perceptron Concepts","Training and Education",J6C7hIXRtpI
TBD,"Pierre Raimbaud: Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE; Matthieu Blanchard: Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE; Eliott Zimmermann: Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE; Sophie Villenave: Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE; Guillaume Lavoué: Ecole Centrale de Lyon, CNRS, INSA Lyon, Universite Claude Bernard Lyon 1, Université Lumière Lyon 2, LIRIS, UMR5205, ENISE; Janine Jongbloed: Laboratoire ECP, Université Lumière Lyon 2, 86 rue Pasteur, F-69365; Rawad Chaker: Laboratoire ECP, Université Lumière Lyon 2, 86 rue Pasteur, F-69365; Matthieu Mesnage: INSA Lyon, Ecole Centrale Lyon, Universite Claude Bernard Lyon 1, CPE Lyon, CNRS, INL UMR 5270, 69100; Bertrand Massot: INSA Lyon, Ecole Centrale Lyon, Universite Claude Bernard Lyon 1, CPE Lyon, CNRS, INL UMR 5270; Jean-Pierre Cloarec: Ecole Centrale Lyon, Universite Claude Bernard Lyon 1, CPE Lyon, CNRS, INL UMR 5270, 69100; Jean-Louis Leclercq: Ecole Centrale Lyon, Universite Claude Bernard Lyon 1, CPE Lyon, CNRS, INL UMR 5270, 69100; Valentin Midez: Univ Lyon, INSA Lyon, CNRS, LIRIS, UMR5205, F-69621; Audrey Serna: Univ Lyon, INSA Lyon, CNRS, LIRIS, UMR5205, F-69621; Élise Lavoué: Université Jean Moulin Lyon 3, iaelyon school of Management, INSA Lyon, CNRS, LIRIS, UMR5205, F-69621","Our project proposes to use Virtual Reality (VR) to train chemists to react to incidents. It explores the effects of multisensoriality on learner VR sense of presence and immersion, and the effects of visualising (in/out of VR) behavioural and physiological indicators on learner reflexivity. Multisensoriality implementation, robust capture of behavioural and physiological data, and the design of relevant indicators are our main challenges. Three situations involving chemical incidents have been developed, engaging the learner to react accordingly. We present the first implementations of this VR training environment and the results of our first user studies.","How Should I React? Learning to Face Chemical Risks with Virtual Reality","Training and Education",qPlL5yJVf1U
TBD,"Francisco Díaz-Barrancas: University of Extremadura; Daniel Flores-Martin: Extremadura Supercomputing Center; Dr. Javier Berrocal: University of Extremadura; Dr. Juan C. Peguero: University of Extremadura; Pedro J. Pardo: University of Extremadura","Healthcare trainees often encounter challenges such as high-pressure scenarios, risks to patient safety, limited exposure to specific cases, and restricted access to advanced tools. Virtual Reality (VR) addresses these issues by offering a controlled, immersive environment for repeated, risk-free practice. This work presents a VR training system that allows trainees to engage with real-time ECG data, observe live procedures remotely, and provide feedback. This approach ensures patient anonymity with encrypted data, the system connects theoretical learning with practical application, demonstrating its effectiveness in improving clinical skills and providing a flexible, secure training option for settings with limited patient access.","Integrating Real-Time ECG Data into Virtual Reality for Enhanced Medical Training","Training and Education",sFhw4DRD0RY
TBD,"Dale Button: Durham College; Alvaro Quevedo: Ontario Tech University; Adam Dubrowski: Ontario Tech University","Consumer-level extended reality (XR) devices and available software development tools have sparked content creation in training and education. Current research highlights the benefits of using XR for learning, and the gaps pertaining to motor skills, since consumer-level devices lack proper task and instrument representation that is essential for developing transferable skills. Our paper, presents a preliminary study on usability, cognitive load, and presence using an off-the-shelf XR device to better understand the user experience effects when combining virtual and mixed reality with hand tracking and controller inputs that will inform future work for designing effective properly represented interactions.","XR Cricothyroidotomy and Intraosseous Access: A Preliminary Study on Usability and Presence between VR/MR and Hand Tracking/Controller Interactions","Training and Education",z9A6hXFtvJU
TBD,"Bill Ko: Ontario Tech University; Alvaro Quevedo: Ontario Tech University; David Rojas: University of Toronto; Bill Kapralos: Ontario Tech University; Rory Windrim: University of Toronto","Recent advances in immersive technologies have facilitated the development of highly realistic and cost-effective computer-based simulations (CBS) and this has greatly influenced health professions training. Unlike high-end simulators that require specialized devices, consumerl-level, virtual reality (VR) controllers, and 3D-printed custom interfaces facilitate interactions with CBSs. However, given the lack of proper task representation, many questions remain regarding their effects on the user experience. This paper presents usability, cognitive load and presence preliminary study comparing a virtual laparoscope manipulation using a keyboard and mouse, gamepad, VR controllers, and a 3D-printed laparoscopic controller.","User Experience Impact of various User Interfaces on VR Laparoscopy Tasks: A Preliminary Study","Training and Education",nB631NItlGo
TBD,"Gabrielle Hollaender: Ontario Tech University; Alvaro Quevedo: Ontario Tech University; Jennifer Abbass-Dick: Ontario Tech University; Adam Dubrowski: Ontario Tech University","Breastfeeding is an essential activity for newborns and mothers, with low rates becoming a major health concern. While various breastfeeding programs aim to increase the success and the desire to breastfeed using electronic health (eHealth) resources, only in-person classes provide hands-on experience with mock-up models. Such resources lack immersion and proper representation achievable using virtual reality (VR) This paper focuses on better understand the perceived educational and user experience value of a VR breastfeeding latching prototype and better understand how user interactions leveraging eye and head tracking impact usability and cognitive load.","VR Breastfeeding: A Preliminary User Experience Study comparing Head and Eye Tracking Interactions","Training and Education",zCFBl_t7zwg
TBD,"Lucia Tallero: Nokia; Ester Gonzalez-Sosa: Nokia; Baldomero Rodríguez Árbol: Nokia; Alvaro Villegas: Nokia","We developed an immersive training environment for mastering the use of a fire extinguisher, with the possibility of receiving feedback from a remote expert. To facilitate communication and knowledge sharing, we provide bidirectional audio and event synchronization. As additional novel features, we allow the user to see and interact with their own body and real fire extinguisher using deep learning and color-based semantic segmentation. We also allow the expert to monitor the trainee by rendering a 2D video of their egocentric view. Preliminary results show the benefit of receiving live feedback and the potential of using a real fire extinguisher.","Immersive Fire Training with Live Expert Support and Embodied Interaction with Real Extintor","Training and Education",fGendILemc4
TBD,"Ruyun Dai: Hanyang University; Jimoon Kim: Hanyang University; Kibum Kim: Hanyang University","One of the techniques used in trauma stabilization stage is ‘safe place’ which aims to establish a sense of safety by guiding patients to create a vivid mental imagery. Existing research has highlighted both the advantages and potential of using VR for trauma intervention, as well as some limitations. In this study, we present the ‘Safe Place VR’. Specifically, we provide three pre-set virtual environments, three different time-of-day lighting settings, and serval comfort items representing various senses that may be linked to positive emotions or memories, guiding patients to create their own safe place within the VR environment.","Safe Place VR:  A Guided Imagery-Based Virtual Reality Trauma Stabilization Technique","Training and Education",VPdH5i2lyVM
TBD,"Tony Donegan: IDIBAPS","Virtual embodiment and virtual exercise are promising adjuncts to treatment for orthopedic patients, who face physical and psychological barriers during rehabilitation. This randomized controlled trial evaluated the impact of VR on post-surgical knee recovery. Patients (n=47) were assigned to either conventional rehabilitation or conventional plus daily 20-minute VR training, which utilized embodied avatars for movement visualization. The VR group demonstrated a substantial reduction in kinesiophobia scores at 4 weeks post-surgery (p=0.043). No significant differences were observed in quadriceps strength, knee range of motion, and disability. These findings support VR's potential for addressing psychological barriers in rehabilitation.","Virtual embodiment reduces fear of movement after knee surgery","Training and Education",xaRUUAKcaWo
TBD,"Ruya Ilkin SULUTAS: Bournemouth University; Antoine RICHEROL: Saint Cyr Écoles de Coëtquidan; Eloi de GARIDEL-THORON: Saint Cyr Écoles de Coëtquidan; Fred Charles: Bournemouth University; Ellen Seiss: Bournemouth University","This paper provides an overview of a fully implemented Virtual Reality (VR) application which aims to support the assessment of the most common subtypes of Obsessive Compulsive Disorder (OCD): cleaning and checking behaviours. The VR application consists of a tool for the therapist to select differing levels of tasks for the participants to fulfil within an interactive 3D virtual kitchen. Participants’ assessment will be taking place at tasks completion level whilst their behaviour will be analysed through continuous recording of physiological measures and self-reporting questionnaires.","Virtual Reality Application for OCD Assessment","Training and Education",VunOw-MRvzA
TBD,"Nour Boulahcen: Trinity College Dublin; Yifan Chen: Trinity College Dublin","The public’s growing awareness of sustainability and plant diversity makes teaching plant evolution a fascinating and emergent challenge for learners at every level. Roots of Evolution is an immersive Virtual Reality museum using digital storytelling to explore plant evolution interactively. Inspired by the “Map of Plants” by Dominic Walliman, this project aims to simplify complex concepts and foster curiosity through interactive multi-modal content, an intelligent AI agent, and a narrative-driven approach to 3D immersive media. Future expansions aim to include broader botanical topics and user testing to refine its educational impact, showcasing the potential of immersive technology and digital storytelling in science education.","Roots of Evolution: An Immersive VR Journey Through Plant Evolution Using Digital Storytelling in Botany","Training and Education",4kRObu9ni1k
TBD,"Ali Adjorlu: Aalborg University Copenhagen; August Brandt Juul: Aalborg University; Malte Bach Hansen: Aalborg University; Mikkel Julius Hansen: Aalborg University; Peter Ousager Andersen: Aalborg University; Sophie Vindal Larsen: Aalborg University","Noise-induced hearing loss is a growing concern among young adults attending concerts and festivals, where prolonged exposure to high-decibel environments can cause irreversible damage. DecibelDefender is a multiplayer VR experience designed to promote sustainable hearing habits by immersing users in a simulated concert environment. Participants experience progressive hearing loss and engage in interactive activities emphasizing the importance of hearing protection during concerts. Initial results shows an impact on behavioral intentions, with participants demonstrating greater preference for protective measures after trying the VR experience. This study highlights VR's potential to foster empathy and encourage preventive health behaviors.","DecibelDefender: Using Virtual Reality for Promoting Sustainable Hearing Habits at Concerts and Festivals","Training and Education",ahVonqqh79Y&ab_channel=AliAdjorlu
TBD,"Alexander Klippel: Wageningen University and Research; Jeroen Hubert: Wageningen University and Research; Jan Oliver Wallgrün: Independent Researcher; Joseph Henry: Triton Oceanic Exploration Society; Thomas Bruhn: Wageningen University and Research; Timon Verduijn: Wageningen University and Research; Tinka Murk: Wageningen University and Research","Ocean literacy--the understanding of how oceans influence the Earth’s ecosystems, their  critical role in sustaining life on Earth, and the impact of human activities on the ocean--is essential for for making informed decisions for addressing fundamental environmental problems. However, the inaccessibility of oceans brings about special challenges for educators and decision makers. We describe our work on V-CURRENTS, a platform for creating underwater virtual reality field trips as an approach to address some of these challenges and promote ocean literacy through immersive technologies and immersive experiences. We sketch key components of the platform as well as exemplary application scenarios.","V-CURRENTS: Virtual Collaborative Underwater Realities for Engagement and Novel Teaching Spaces","Training and Education",eypjEpZ-qeI
TBD,"Yibo WANG: The Hong Kong University of Science and Technology(Guangzhou)); Yuanyuan MAO: The Hong Kong university of science and technology (Guangzhou); Shi-Ting Ni: Computational Media and Arts, The Hong Kong University of Science and Technology (Guangzhou),; Zeyu Wang: The Hong Kong University of Science and Technology (Guangzhou); Pan Hui: The Hong Kong University of Science and Technology(Guangzhou))","We propose Metabook, a system to automatically generate interactive AR storybooks to improve children’s reading interest. Metabook introduces a story-to-3D-book generation scheme and a 3D avatar that combines multiple AI models as a reading companion. Our user study shows that Metabook can significantly increase children’s interest in reading. Teachers acknowledged Metabook’s effectiveness in enhancing reading enthusiasm by connecting verbal and visual thinking, expressing high expectations for its future potential in education.","Metabook: A System to Automatically Generate Interactive AR Storybooks to Improve Children’s Reading Interest","Training and Education",L5Hl8dTUSGA
TBD,"Brody Wells: University of Calgary; Nanjia Wang: University of Calgary; Samuel Wiebe: University of Calgary; Colin Bruce Josephson: University of Calgary; Farnaz Sinaei: University of Calgary; Frank Maurer: University of Calgary","We present our prototype system, developed via a participatory design process with neurologists, demonstrating how Cross Reality technology can integrate the immersive, stereoscopic visualization and interaction benefits of eXtended Reality tools with traditional desktop medical imaging software. Our system enables clinicians to work simultaneously with both systems, with changes to the data synchronized between them. To address the clinical use-case, we adapted interaction techniques to make cross-sectional analysis more intuitive than on a flat screen. Feedback from the neurologists indicate a Cross Reality system has potential to enhance their current workflows.","NeuroCR: Integrating Mixed Reality with Desktop Medical Imaging Software for Neurologists Performing Pre-surgical Evaluations of Epilepsy Patients","Training and Education",swnOachzdS4
TBD,"Hua Ma: Beijing United-Imaging Research Institute of Intelligent Imaging; Chongyan Sun: Beijing United-Imaging Research Institute of Intelligent Imaging; Zhenyu Li: Beijing United-Imaging Research Institute of Intelligent Imaging; Jiahao Chen: Beijing United-Imaging Research Institute of Intelligent Imaging; Runting Li: Peking University Third Hospital; Ziyuan Wang: Peking University Third Hospital; Yun Tian: Peking University Third Hospital; Tengjiao Zhu: Peking University Third Hospital; Zhen Qian: Beijing United-Imaging Research Institute of Intelligent Imaging","We propose an AR system using Apple Vision Pro (AVP) to assess the accuracy of guide plate positioning in lumbar surgery. It leverages preoperative CT data and integrates fiducial marker tracking to automate the initial alignment of a virtual vertebra with the intraoperative anatomy. Additionally, we developed a graphical interface for the AVP platform, which allows manual adjustment of the pose and visualization of the virtual vertebra. The system was tested on 3D-printed lumbar phantoms, an ex vivo pig lumbar specimen, and two in vivo pig surgeries. Results demonstrated accurate guide plate alignment and superior visualization, validating the potential of AR systems in improving surgical precision in lumbar procedures.","Augmented Reality-Assisted Guide Plate Positioning in Lumbar Surgery Using Apple Vision Pro","Training and Education",hQ8M3V6EQG0
TBD,"Johanna Delachambre: Université Côte d'Azur, Inria; Hui-Yin Wu: Université Côte d'Azur, Inria; Monica Di Meo: CHU Pasteur; Frédérique Lagniez: CHU Pasteur; christine morfin bourlat: CHU Pasteur; Stéphanie Baillif: CHU Pasteur; Eric Castet: Aix Marseille Univ, CNRS, CRPN; Pierre Kornprobst: Université Côte d'Azur, Inria","Patients with visual impairment often rely on low-vision aids (LVAs) such as magnifiers to perform near-vision tasks, with rehabilitation programs traditionally focusing on these activities. XR technologies offer opportunities to address broader needs, including social interactions, which require also guidance and training. We present a system leveraging VR to enable realistic testing and training of LVAs within immersive scenarios. Through an observational study involving patients and orthoptists, we illustrate how this approach expands traditional care practices, integrating emerging technologies, facilitating personalization, and enabling efficient training of LVAs under conditions otherwise challenging to replicate in clinical settings.","An asymmetric VR system to configure and practice low-vision aids for social interactions in clinical settings","Training and Education",SsPOAJx3nPk?feature=shared
TBD,"Chan In Devin SIO: The Hong Kong Polytechnic University; Yao Yao: Xi'an Jiaotong University; Rui Xie: Beijing Foreign Studies University; Xian Wang: The Hong Kong Polytechnic University; Chi Sun: The Hong Kong Polytechnic University; Yu Hin TANG: The Hong Kong Polytechnic University; Choi Chun Ifan CHEUNG: The Hong Kong Polytechnic University; Andrew K.F. Cheung: Hong Kong Polytechnic University; Lik-Hang Lee: Hong Kong Polytechnic University","Court interpreting is vital for justice, yet traditional training methods often lack hands-on engagement and rely on uninspiring trial-and-error techniques. We developed MetaCourt, an immersive virtual environment for court interpreting education to address this. Through participatory design, we created a system evaluated by 21 interpreting students using the PENS model based on self-determination theory. Results showed high autonomy, intuitive controls, and presence, with improved fluency in VR compared to traditional methods. Surveys (NASA-TLX, IPQ) indicated reduced mental workload and strong usability. This study pioneers integrating VR with PENS for court interpreting, offering significant advantages in training effectiveness.","MetaCourt: Leveraging the Metaverse for Immersive Court Interpreting Education with Self-Determination Theory","Training and Education",HNk3X7ncgxg
TBD,"Abdullah Iskandar: Telkom University; Hala Aburajouh: qatar university; Kodai Fuchino: Waseda University; Osama Halabi: Qatar University; Faisal Al-jaber: qatar university; Mohammed Al-Sada: Qatar University; Tatsuo Nakajima: Waseda University","Physical interaction plays a vital role in various skill-transfer scenarios. Despite its importance, the majority of systems focus on visual and auditory in immersive environments for training contexts. Therefore, we present LinkForm, a novel VR-based robotic skill-transfer system comprises a VR environment and a robotic system. LinkForm enables a coach to remotely train a user, with the ability to convey visual, verbal, and physical guidance and interactions to the remote trainee. The preliminary evaluation result shows statistically significant improvements in the participants performance after using LinkForm. Participants also showed strong interest in training using LinkForm, suggesting various remote-training scenarios.","LinkForm: a Multipurpose VR-based Remote Skill-transfer Robotic System","Training and Education",JJ6Tdo1gpqQ
TBD,"Eoghan Paul Hynes: Technological University of the Shannon, Midlands and Midwest; Ronan Flynn: Athlone Institute of Technology; Niall Murray: Athlone Institute of Technology","Augmented reality (AR) exhibits potential for delivering training instructions. Trainee learning and transfer can be influenced by the different extraneous cognitive loads implicit in text and graphical instruction formats. Our research evaluated this influence using a GoCube™ training procedure delivered in AR. Learning, transfer and user experience were evaluated using mental rotations, physiological ratings, eye gaze, facial expressions, memory recall and questionnaire responses. Results showed that trainees using text-only instruction were significantly faster in training and recall than their counterparts using a combined text and 3D-model instruction format. This correlated to mental rotation baselines, gaze shifts and cognitive load.","A Gender-Based Evaluation of Text-Only Versus Text-3D Model Instructions in Augmented Reality Training","Training and Education",dASXAHp9Ny0
TBD,"Mathias DELAHAYE: Hôpitaux Universitaires de Genève; Andrea Nathaly Neher: Universität Bern; Tanja BIRRENBACH: Inselspital; Florian B. NEUBAUER: Institut für Medizinische Lehre; Christoph BERENDONK: Institut für Medizinische Lehre; Thomas SAUTER: Inselspital; Oliver KANNAPE: Hôpitaux Universitaires de Genève","We here present both a technical description of the platform we developed to reproduce the gold-standard assessment of practical clinical skill Objective Structured Clinical Examination (OSCE) as well as the results of a feasibility study conducted with 5th-year medical students (N=33) in a virtual twin of their official examen. The results indicate that participants appreciated the simulation’s functionality and its ease of use and highlighted the platform’s potential as a training resource.","A Virtual Objective Structured Clinical Examination (OSCE) platform: Implementation and Feasibility Testing","Training and Education",QKROekZE1HQ
TBD,"Xiaonuo Dongye: Beijing Institute of Technology; Hanzhi Guo: Beijing Institute of Technology; Yihua Bao: Beijing Institute of Technology; Haiyan Jiang: Singapore Institute of Technology; Dongdong Weng: Beijing Institute of Technology","3D Gaussian Splatting can create virtual models with captured real-world images using a camera mounted on a mobile robotic arm. However, the Gaussian model quality deteriorates when parts of the object that have not been previously captured are exposed in VR interaction. This poster presents a human-in-the-loop Gaussian model enhancement method, comprising pre-training, viewpoint labeling, robotic image re-capture, and Gaussian model enhancement. By incorporating newly re-captured images, the enhanced models achieve improved image similarity metrics compared to the pre-trained ones, with minimal optimization time. This method facilitates continuous quality improvement, making Gaussian models more adaptable for VR applications.","Human-in-the-Loop Gaussian Model Enhancement with Mobile Robotic Re-Capture","Visualization and Rendering",1DN1iX1J8Eo
TBD,"Yue Qiu: The Chinese University of Hong Kong; Yuqi Tong: The Chinese University of Hong Kong; Yu Zhang: The Chinese University of Hong Kong; Qixuan Liu: The Chinese University of Hong Kong; Jialun Pei: The Chinese University of Hong Kong; Shi Qiu: The Chinese University of Hong Kong; Pheng Ann Heng: The Chinese University of Hong Kong; Chi-Wing Fu: The Chinese University of Hong Kong","The study of human anatomy through advanced visualization techniques is crucial for medical research and education. In this work, we introduce CvhSlicer 2.0, an innovative XR system designed for immersive and interactive visualization of the Chinese Visible Human (CVH) dataset. Particularly, our proposed system operates entirely on a commercial XR headset, offering a range of visualization and interaction tools for dynamic 2D and 3D data exploration. By conducting comprehensive evaluations, our CvhSlicer 2.0 demonstrates strong capabilities in visualizing anatomical data, enhancing user engagement and improving educational effectiveness. A demo video is available at CfR72S_0N-4.","CvhSlicer 2.0: Immersive and Interactive Visualization of Chinese Visible Human Data in XR Environments","Visualization and Rendering",CfR72S_0N-4
TBD,"Kristoffer Waldow: TH Köln; Jonas Scholz: TH Köln; Arnulph Fuhrmann: TH Köln","Diminished Reality (DR) allows for the selective removal or transformation of real-world objects from a user’s field of view. In certain cases, it becomes essential to revisit environments and observe them in their original state. While Smartphone and Web-based approaches provide intuitive and convenient AR platforms, it also faces challenges like limited resources. This work introduces a DR system using Gaussian splats for real-time object removal on WebXR-enabled devices. We achieve up to 60 FPS while maintaining high visual fidelity, validated with different image quality metrics, offering a scalable solution for revisiting and manipulating temporally altered environments.","DimSplat: A Real-Time Diminished Reality System for Revisiting Environments Using Gaussian Splats in Mobile WebXR","Visualization and Rendering",FgRtNsRKDBI
TBD,"Sarshar Dorosti: Ulster University; Xiaosong Yang: Bournemouth University","ImmersiveDepth is a hybrid framework designed to tackle challenges in Monocular Depth Estimation (MDE) from 360-degree images, specifically spherical distortions, occlusions, and texture inconsistencies. By integrating tangent image projection, a combination of convolutional neural networks (CNNs) and transformer models, and a novel multi-scale alignment process, ImmersiveDepth achieves seamless and precise depth predictions. Evaluations on diverse datasets, show an average 37% reduction in RMSE compared to Depth Anything V2 and a 25% accuracy boost in low-light conditions over MiDaS v3.1. ImmersiveDepth thus establishes a robust solution for immersive technologies, autonomous systems, and 3D reconstruction.","ImmersiveDepth: A Hybrid Approach for Monocular Depth Estimation from 360-Degree Images Using Tangent Projection and Multi-Model Integration Abstract","Visualization and Rendering",DFouCO2XcLU
TBD,"Maxim Spur: Ecole Nationale d'Ingénieurs de Brest; Philippe DEVERCHERE: ScotopicLabs; Olivier Augereau: ENIB; Edna Hernández González: UBO","We present a Virtual Reality application that immersively visualizes nighttime skyglow and its sources of light pollution. Utilizing Unity with Cesium and OpenStreetMap geospatial data, the system integrates calibrated all-sky images processed with the Sky Quality Camera software to provide natural and luminance views of the night sky. By projecting road maps and location markers onto a surrounding sphere using inverse stereographic projection, users can intuitively explore the correlation between observed skyglow and its sources. This tool offers educational and exploratory potential, highlighting the impact of artificial light pollution on the night sky in an immersive and realistic context.","Night Sky Explorer VR","Visualization and Rendering",MP45zVhgp50
TBD,"Jia Li: Lenovo Research; Yan Liu: Lenovo Research; Nan Gao: Institute of Automation, Chinese Academy of Sciences; Ke Shang: Lenovo Research","Human-centered immersive computing is catching on within VR and AR. We establish a real-time immersive presence system called AvatarMirror that enables arbitrary characters to look at themselves instantly in novel stereo views. First, stereo matching is implemented to acquire multi-view depth priors, based on which the human topology is reconstructed through raycasting from a novel perspective. Then, the color information from the referenced views is adaptively blended to perform the human rendering. Furthermore, we propose an RR-Net to conduct rendering restoration. AvatarMirror realizes real-time high-fidelity immersive presence with multi-threaded scheduling and CUDA acceleration.","AvatarMirror: Rendering Restoration for Real-time Immersive Presence System","Visualization and Rendering",qJq_masA6aI
TBD,"Bruno Rodriguez-Garcia: University of Burgos; Giuseppe Ceraudo: University of Salento; Laura Corchia: University of Salento; Lucio Tommaso De Paolis: University of Salento","This study presents an optimized 3D modeling procedure for the development of immersive Virtual Reality (iVR) experiences. It has been tested by conducting the virtual reconstruction of the Roman city of Aquinum (Italy), a key archaeological site. The resulting 3D model demonstrates a high Level of Detail (LoD) across a total area of 17,570 m² (2,470 m² of which are explorable) with a file size of only 46.2 MB, incorporating just six unique textures. This research not only delivers an accurate reconstruction of the city of Aquinum but also introduces an effective optimization method based on open-source tools.","Optimization Strategies for Standalone Virtual Reality Experiences: the virtual reconstruction of the city of Aquinum","Visualization and Rendering",dxkP6_kGviY?si=OHdMl2cUHidfQRgd
TBD,"Or Butbul: Coastal Carolina University; Oyewole Oyekoya: City University of New York - Hunter College","Recent advancements in real-time rendering technology have significantly improved the detail of virtual humans. Higher resolution textures, physically-based hair and skin materials, and other innovations have increased their likeness. However, this has also raised render time and complexity. While hardware improvements alleviate some issues, limited access to high-performance hardware restricts creators on lower-performance systems from using advanced rendering techniques. This study explores the relationship between render times at different levels of detail and the perceived realism of avatars. By comparing these levels, we establish a relative realism scale and identify suitable levels of detail for specific virtual experiences.","Rendering Reality: Measuring Time Efficiency in Virtual Human Creation","Visualization and Rendering",arAuNXYdICg
TBD,"Arisa Kohtani: Institute of Science Tokyo; Shio Miyafuji: Institute of Science Tokyo; Hideki Koike: Institute of Science Tokyo","We propose a method to display target colors along the trajectories of moving objects using high-speed projection. This is achieved by leveraging the selective disruption of the afterimage effect, ensuring the target color appears prominently along motion trajectories. In our method, a high-speed projector is used to display multiple frames, consisting of target color frames and a single complementary color frame.  This ensures that the target color appears prominently along the motion trajectories of the objects, where the afterimage effect is selectively disrupted, while maintaining color perception when the objects stop. This method enables novel interactions by dynamically adapting visual effects to the motion of objects.","Color Display on Moving Object Trajectories Using High-Speed Projection","Visualization and Rendering",k0rq9JwPju4?feature=shared
TBD,"Boyu Xu: Utrecht University; Lynda Hardman: CWI; Wolfgang Hürst: Utrecht University","Neuroscientists analyse publications to inform experiment design. Exploring direct relations between topics, such as brain diseases and regions, aids this process. Brain diseases may also connect indirectly to regions through topics such as mental processes. We aim to establish whether exploring indirect relations helps design experiments. Using a user-centred design approach, we interview neuroscientists to establish the usefulness of exploring indirect relations, specify functionality, and design a corresponding visualisation. Nine neuroscientists indicated the visualisation is suitable to present the functionality, the functionality is useful to explore indirect relations, and exploring indirect relations is useful to design experiments.","Exploring Indirect Relations between Topics in Augmented Reality to Inform the Design of a Neuroscience Experiment","Visualization and Rendering",qd3aKs2pVbE
TBD,"Isaac Ngui: University of Illinois Urbana-Champaign; Courtney McBeth: University of Illinois Urbana-Champaign; Grace He: University of Illinois Urbana-Champaign; André Corrêa Santos: Insper; Luciano P Soares: Insper; Marco Morales: University of Illinois Urbana-Champaign; Nancy Amato: University of Illinois Urbana-Champaign","Many tasks are intuitive for humans but difficult to encode algorithmically when utilizing a robot. Robotic systems often benefit from learning from expert demonstrations, wherein operators move the robot along trajectories. Often, using a physical robot to provide these demonstrations may be difficult or unsafe. Extended reality provides a natural setting for demonstrating trajectories while bypassing safety concerns or modifying existing solution trajectories. We propose the Robot Action Demonstration in Extended Reality (RADER) system for learning from demonstration approaches. We additionally present its application to a state-of-the-art approach and show comparable results between using a physical robot and our system.","Extended Reality System for Robotic Learning from Human Demonstration","Visualization and Rendering",BpScfuUEmaA
TBD,"Brendan Kelley: Colorado State University; Ryan P. McMahan: Virginia Tech; Christopher Wickens: Colorado State University; Benjamin A. Clegg: Montana State University; Francisco Raul Ortega: Colorado State University","Visual search is a common task, especially given the high amount of spatial information we process visually. To aid in searching an environment for targets, various cues have been developed and implemented for augmented reality (AR) and virtual reality (VR) head-mounted displays (HMDs). A variety of different designs have emerged from prior literature including the gaze line, 2D wedge, and 3D arrow, each with unique and different design characteristics. However, many of these designs are not evaluated beyond their initial design proposals. Results favored the gaze line cue for search time, accuracy, and reported metnal effort, potentially highlighting the benefit of having both direction and location information embedded into the cue.","Cuing Multiple-Targets for Visual Search in Virtual Reality","Visualization and Rendering",MMzRouRMA20
TBD,"Thi Thanh Hoa TRAN: IMT Atlantique; Bruce H Thomas: University of South Australia; Guillaume Moreau: IMT Atlantique; James A. Walsh: University of South Australia; Etienne Peillard: IMT Atlantique","Integrating Autonomous Vehicles (AVs) into daily life requires enhancing user trust and acceptance. While prior research demonstrated that Augmented Reality (AR) visualizations improve trust by adding driving-related information, the effects of removing or modifying unrelated information remain unclear. This study examines six AR visualization strategies within AVs, including the addition, modification, and removal of information related or unrelated to driving tasks. Using a custom-developed driving simulator that emulates AR, we evaluated their impact on trust, technology acceptance, and situational awareness. Results indicate that AR visualizations can significantly enhance trust in AVs, whether adding, modifying, or removing information","Impact of Adding, Removing and Modifying Driving and Non-Driving Related Information on Trust in Autonomous Vehicles","Visualization and Rendering",UihYvuZ-XtQ
TBD,"Yulin Shen: The Hong Kong University of Science and Technology (Guangzhou); Boyu Li: The Hong Kong University of Science and Technology (Guangzhou); Jiayang Huang: The Hong Kong University of Science and Technology (Guangzhou); Zeyu Wang: The Hong Kong University of Science and Technology (Guangzhou)","3D Gaussian Splatting has attracted much attention for its ability to quickly create digital replicas of real-life scenes and its compatibility with traditional rendering pipelines. However, it remains a challenge to edit 3DGS in a flexible and controllable manner. We propose GaussianShopVR, a system that leverages VR user interfaces to specify target areas to achieve flexible and controllable editing of reconstructed 3DGS. In addition, selected areas can provide 3D information to generative AI models to facilitate the editing. GaussianShopVR integrates object hierarchy management while keeping the backpropagated gradient flow to allow local editing with context information.","GaussianShopVR: Facilitating Immersive 3D Authoring using Gaussian Splatting in VR","Visualization and Rendering",BckdHd1FwpE
TBD,"Huadong Zhang: Rochester Institute of Technology; Chao Peng: Rochester Institute of Technology","This paper presents a novel virtual reality (VR) system for real-time foveated rendering of large-scale 3D meshes comprising 100 million triangles. As VR demands high frame rates and stereo rendering, existing desktop-based approaches face computational challenges. We incorporate foveal focus into the level-of-detail (LOD) selection, preserving high geometric detail in the foveal region and reducing detail in peripheral areas. A hierarchical patch-based mesh structure enables precise rendering load estimation and adaptive LOD adjustments. Constrained optimization with a fixed total load budget runs in parallel on the GPU. Evaluations show our VR system outperforms state-of-the-art solutions in visual fidelity and performance.","Foveated VR Rendering System for Large 3D Meshes","Visualization and Rendering",wAZX5YHViLc
TBD,"Wenjie Chang: University of Science and Technology of China; Hao Ai: The Hong Kong University of Science and Technology (Guangzhou Campus); Tianzhu Zhang: University of Science and Technology of China; Lin Wang: HKUST","Panoramic images provide comprehensive scene information and are suitable for VR applications. Obtaining corresponding depth maps is essential for achieving immersive and interactive experiences. We propose a novel method that learns a cubic field composed of multiple MPIs from a single panoramic image for depth estimation. The entire pipeline is trained using photometric loss calculated from rendered views within a self-supervised learning approach. Experiments demonstrate the superior performance of CUBE360 and highlight its effectiveness in downstream applications.","Learning Cubic Field Representation from A Single Panorama for Virtual Reality","Visualization and Rendering",ylPW9EOXp8k
TBD,"Haotian Mao: Shanghai Jiao Tong University; Zhuoxiong Xu: Shanghai Jiao Tong University; Siyue Wei: Shanghai Jiao Tong University; Yule Quan: Shanghai Jiao Tong University; Nianchen Deng: Shanghai AI Lab; Xubo Yang: SHANGHAI JIAO TONG UNIVERSITY","We propose LIVE-GS, a highly realistic interactive Gaussian splatting system in VR setting powered by LLM. Our pipeline supports reconstructions and physically-based interactions in VR, integrating object-aware reconstruction, GPT-assisted inpainting, and a computationally efficient simulation framework. To improve the scene understanding, we prompt GPT-4o to analyze the physical properties of objects in the scene, thereby guiding physical simulations to align with real-world phenomena. Our experimental results demonstrate that with the assistance of LLM's understanding and enhancement of scenes, our VR system can support complex and realistic interactions without requiring additional manual design or annotation.","LIVE-GS: LLM Powers Interactive VR by Enhancing Gaussian Splatting","Visualization and Rendering",HmnbJnoXBVg
TBD,"Xinxing Xia: Shanghai University; Zheye Yu: Shanghai University; Dongyu Qiu: Singapore Institute of Technology; Andrei State: University of North Carolina at Chapel Hill; Tat-Jen Cham: Nanyang Technological University; Frank Guan: Singapore Institute of Technology; Henry Fuchs: University of North Carolina at Chapel Hill","A head-worn optical-see-through near-eye display (NED) is crucial for augmented reality (AR), enabling simultaneous perception of virtual and real imagery. Current AR NEDs face trade-offs among field of view (FOV), eyebox size, and form factor. We designed an enhanced pinlight AR NED using a novel approach to capture the pupil’s 3D location and compute a modulation pattern on the display. In our design, an eye-tracking camera rig captures stereoscopic views to calculate a display pattern, modulating light beams for precise imagery. Our compact prototype achieves wide FOV, large eyebox, and experimental results confirm its spatial and temporal consistency.","Towards an Expanded Eyebox for a Wide-Field-of-View Augmented Reality Near-eye Pinlight Display with 3D Pupil Localization","Visualization and Rendering",HDxQWpj1WMM
TBD,"Weichao Song: College of Computer and Information Science, Southwest University; Bingyao Huang: Southwest University","Virtual reality (VR) and augmented reality (AR) demand real-time and high-quality egocentric viewing. Neural rendering can generate extremely high-quality novel views but requires expensive training time and renders too slow. To address these challenges, this paper proposes a method named multi-scale spherical tensor decomposition (MSTD). Its ability to represent egocentric neural 3D scenes also enables potential further applications in relevant domains such as data storage, VR, and AR. Our method can reconstruct scenes from multi-view images or omnidirectional images, outperforming baseline methods in training and rendering time as well as rendering quality.","Ray-based Multiscale Spherical Grid for Egocentric Viewing","Visualization and Rendering",hu6PfG6ZAHQ
TBD,"Wenqing Yan: Tsinghua University; Haowei Li: Tsinghua University; Shiye Huang: Beijing Tsinghua Changgung Hospital; Long Qian: Medivis. Inc.; Hui Ding: Tsinghua University; Guangzhi WANG: Tsinghua University; Zhe Zhao: Tsinghua University","Closed Reduction and Internal Fixation (CRIF) is the preferred treatment for closed long bone shaft fractures, where frequent X-rays imaging reduce efficiency and increase radiation exposure. Intra-operative ultrasound offers real-time, radiation-free bone imaging, but challenges orthopedic surgeons. To address this, we developed an Augmented Reality (AR) navigation system with in-situ ultrasound visualization, combining on-device infrared tool tracking via an AR headset’s depth sensor with remote rendering for accurate, low-latency images. A standard operating procedure for surgical application was also proposed. Clinical trials with six patients showed significant reduction in fluoroscopy dose and operation time.","In-situ Ultrasound Guided Closed Long Bone Shaft Fracture Treatments","Visualization and Rendering",GaQ6y4C3Rs0